{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/airangers/anaconda3/envs/e/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-02-25 10:59:36,372 - INFO - Saved code attempt 1 to code_generation/generation_20250225_105919/attempt_1_initial/code.py\n",
      "2025-02-25 10:59:41,047 - ERROR - Error in validator node: Expecting value: line 1 column 1 (char 0)\n",
      "2025-02-25 10:59:53,282 - ERROR - Error in validator node: Expecting value: line 1 column 1 (char 0)\n",
      "2025-02-25 10:59:54,090 - INFO - Saved code attempt 2 to code_generation/generation_20250225_105919/attempt_2_correction/code.py\n",
      "2025-02-25 10:59:54,602 - ERROR - Error in validator node: 422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct/v1/chat/completions (Request ID: Root=1-67bd5552-4744621d53260827380c11b8;a0428927-c577-4ed3-a652-aa0d0ea1fadb)\n",
      "\n",
      "Input validation error: `inputs` tokens + `max_new_tokens` must be <= 8192. Given: 9689 `inputs` tokens and 0 `max_new_tokens`\n",
      "2025-02-25 10:59:55,148 - ERROR - Error in validator node: 422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct/v1/chat/completions (Request ID: Root=1-67bd5552-2e04d9c938012bb272cee63d;82ec2719-4fb3-45b6-bd6d-604f7337d4d9)\n",
      "\n",
      "Input validation error: `inputs` tokens + `max_new_tokens` must be <= 8192. Given: 19635 `inputs` tokens and 0 `max_new_tokens`\n",
      "2025-02-25 10:59:55,753 - ERROR - Error in correction node: 422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct/v1/chat/completions (Request ID: Root=1-67bd5553-6e247cee7d2fa1a0583c2285;7c72b9bd-f812-4f90-8973-a0c3a3295828)\n",
      "\n",
      "Input validation error: `inputs` tokens + `max_new_tokens` must be <= 8192. Given: 19580 `inputs` tokens and 0 `max_new_tokens`\n",
      "2025-02-25 10:59:56,510 - ERROR - Error in validator node: 422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct/v1/chat/completions (Request ID: Root=1-67bd5553-4600aceb7be085be2b7df6d7;88466bfd-559b-4338-b88e-0e6099e01ddc)\n",
      "\n",
      "Input validation error: `inputs` tokens + `max_new_tokens` must be <= 8192. Given: 39417 `inputs` tokens and 0 `max_new_tokens`\n",
      "2025-02-25 10:59:57,600 - ERROR - Error in validator node: 422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct/v1/chat/completions (Request ID: Root=1-67bd5554-25b5522c5776918c79b714f1;ffdb10d5-d3f3-4158-a9da-7aafff002d59)\n",
      "\n",
      "Input validation error: `inputs` tokens + `max_new_tokens` must be <= 8192. Given: 79091 `inputs` tokens and 0 `max_new_tokens`\n",
      "2025-02-25 10:59:58,650 - ERROR - Error in correction node: 422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct/v1/chat/completions (Request ID: Root=1-67bd5555-194353341ce4f4052a4afe72;db3263f7-10d2-4f72-9368-3f18ca71e516)\n",
      "\n",
      "Input validation error: `inputs` tokens + `max_new_tokens` must be <= 8192. Given: 79040 `inputs` tokens and 0 `max_new_tokens`\n",
      "2025-02-25 10:59:59,533 - ERROR - Error in validator node: 422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct/v1/chat/completions (Request ID: Root=1-67bd5556-053aa3934f219ac2127be752;815dc9df-ea07-4c7b-8c93-8fb5e7a11a61)\n",
      "\n",
      "Input validation error: `inputs` tokens + `max_new_tokens` must be <= 8192. Given: 158337 `inputs` tokens and 0 `max_new_tokens`\n",
      "2025-02-25 11:00:00,926 - ERROR - Error in validator node: 422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct/v1/chat/completions (Request ID: Root=1-67bd5557-71b4c95f055067af1f53a048;3013f1c0-719b-4f25-9ed8-5e297df09f18)\n",
      "\n",
      "Input validation error: `inputs` tokens + `max_new_tokens` must be <= 8192. Given: 316931 `inputs` tokens and 0 `max_new_tokens`\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Annotated, Optional, List, Dict, Any\n",
    "import operator\n",
    "from pathlib import Path\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class CodeGenerationState(TypedDict):\n",
    "    \"\"\"State management for code generation process\"\"\"\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "    current_code: Optional[str]\n",
    "    validation_status: Optional[bool]\n",
    "    error_messages: Optional[list[str]]\n",
    "    attempt_number: int\n",
    "\n",
    "class CodeGenerator:\n",
    "    \"\"\"Main class for generating, validating, and correcting code\"\"\"\n",
    "    \n",
    "    def __init__(self, model, checkpointer, base_output_dir: str):\n",
    "        self.model = model\n",
    "        self.base_output_dir = base_output_dir\n",
    "        self.current_attempt = 0\n",
    "        self.max_attempts = 15\n",
    "        \n",
    "        # Create base output directory with timestamp\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        self.base_output_dir = os.path.join(base_output_dir, f\"generation_{timestamp}\")\n",
    "        os.makedirs(self.base_output_dir, exist_ok=True)\n",
    "        \n",
    "        # Initialize graph\n",
    "        graph = StateGraph(CodeGenerationState)\n",
    "        \n",
    "        # Add nodes\n",
    "        graph.add_node(\"developer\", self.developer)\n",
    "        graph.add_node(\"validator\", self.validator)\n",
    "        graph.add_node(\"correction\", self.correction)\n",
    "        \n",
    "        # Add edges\n",
    "        graph.add_edge(\"developer\", \"validator\")\n",
    "        graph.add_conditional_edges(\n",
    "            \"validator\",\n",
    "            lambda state: self.validator(state)[\"validation_status\"],\n",
    "            {\n",
    "                True: END,\n",
    "                False: \"correction\"\n",
    "            }\n",
    "        )\n",
    "        graph.add_edge(\"correction\", \"validator\")\n",
    "        \n",
    "        # Set entry point\n",
    "        graph.set_entry_point(\"developer\")\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "\n",
    "    def format_requirements_prompt(self, requirements: Dict[str, Any]) -> str:\n",
    "        \"\"\"Format requirements into a development prompt\"\"\"\n",
    "        title = requirements.get('Title', 'Code Generation Task')\n",
    "        description = requirements.get('Description', '')\n",
    "        acceptance_criteria = requirements.get('AcceptanceCriteria', [])\n",
    "        \n",
    "        return f\"\"\"\n",
    "You are an expert Python developer. Generate production-ready Python code based on these requirements.\n",
    "\n",
    "REQUIREMENTS SPECIFICATION:\n",
    "Title: {title}\n",
    "Description: {description}\n",
    "\n",
    "Acceptance Criteria:\n",
    "{chr(10).join(f'- {criterion}' for criterion in acceptance_criteria)}\n",
    "\n",
    "CODE GENERATION GUIDELINES:\n",
    "\n",
    "1. Code Structure:\n",
    "   - Create a complete, self-contained Python script\n",
    "   - Use proper class and function organization\n",
    "   - Implement all specified functionality\n",
    "   - Include all necessary imports\n",
    "   - Create appropriate classes with clear responsibilities\n",
    "   - Use dataclasses for configuration management\n",
    "   - Implement utility functions as needed\n",
    "\n",
    "2. Code Quality Requirements:\n",
    "   - Follow PEP 8 standards strictly\n",
    "   - Use type hints for all functions and methods\n",
    "   - Include detailed docstrings (Google style)\n",
    "   - Implement comprehensive error handling\n",
    "   - Add proper logging throughout\n",
    "   - Make code modular and maintainable\n",
    "\n",
    "3. Implementation Requirements:\n",
    "   - Create robust classes and methods\n",
    "   - Include all necessary validation\n",
    "   - Handle edge cases properly\n",
    "   - Implement batch processing if needed\n",
    "   - Add progress tracking\n",
    "   - Save or return results appropriately\n",
    "   - Use appropriate design patterns\n",
    "\n",
    "4. Documentation:\n",
    "   - Add detailed docstrings for all components\n",
    "   - Include usage examples in docstrings\n",
    "   - Document assumptions and limitations\n",
    "   - Add inline comments for complex logic\n",
    "   - Include type hints for clarity\n",
    "\n",
    "5. Error Handling:\n",
    "   - Validate all inputs thoroughly\n",
    "   - Handle expected error cases\n",
    "   - Provide clear error messages\n",
    "   - Implement proper logging\n",
    "   - Use custom exceptions if needed\n",
    "\n",
    "Return ONLY the complete, runnable Python code without any markdown or explanations.\n",
    "\"\"\"\n",
    "\n",
    "    def save_code_attempt(self, code: str, attempt_number: int, status: str = \"initial\") -> str:\n",
    "        \"\"\"Save code attempt to file and return the directory path\"\"\"\n",
    "        attempt_dir = os.path.join(self.base_output_dir, f\"attempt_{attempt_number}_{status}\")\n",
    "        os.makedirs(attempt_dir, exist_ok=True)\n",
    "        \n",
    "        code_file = os.path.join(attempt_dir, \"code.py\")\n",
    "        with open(code_file, 'w') as f:\n",
    "            f.write(code)\n",
    "        \n",
    "        logger.info(f\"Saved code attempt {attempt_number} to {code_file}\")\n",
    "        return attempt_dir\n",
    "\n",
    "    def save_validation_results(self, validation_result: Dict[str, Any], attempt_number: int) -> None:\n",
    "        \"\"\"Save validation results to file\"\"\"\n",
    "        validation_file = os.path.join(\n",
    "            self.base_output_dir, \n",
    "            f\"attempt_{attempt_number}_validation.json\"\n",
    "        )\n",
    "        with open(validation_file, 'w') as f:\n",
    "            json.dump(validation_result, f, indent=2)\n",
    "        \n",
    "        logger.info(f\"Saved validation results to {validation_file}\")\n",
    "\n",
    "    def developer(self, state: CodeGenerationState) -> Dict[str, Any]:\n",
    "        \"\"\"Generate initial code or process corrections\"\"\"\n",
    "        try:\n",
    "            messages = state['messages']\n",
    "            requirements = json.loads(messages[0].content)\n",
    "            \n",
    "            # Format prompt with requirements\n",
    "            prompt = self.format_requirements_prompt(requirements)\n",
    "            messages.append(SystemMessage(content=prompt))\n",
    "            \n",
    "            # Generate code\n",
    "            response = self.model.invoke(messages)\n",
    "            generated_code = response.content\n",
    "            \n",
    "            # Save initial code\n",
    "            self.current_attempt += 1\n",
    "            attempt_dir = self.save_code_attempt(generated_code, self.current_attempt)\n",
    "            \n",
    "            return {\n",
    "                'messages': messages,\n",
    "                'current_code': generated_code,\n",
    "                'validation_status': None,\n",
    "                'error_messages': [],\n",
    "                'attempt_number': self.current_attempt\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in developer node: {str(e)}\")\n",
    "            return {\n",
    "                'messages': messages,\n",
    "                'error_messages': [str(e)],\n",
    "                'attempt_number': self.current_attempt\n",
    "            }\n",
    "\n",
    "    def validator(self, state: CodeGenerationState) -> Dict[str, Any]:\n",
    "        \"\"\"Validate generated code\"\"\"\n",
    "        try:\n",
    "            messages = state.get(\"messages\", [])\n",
    "            current_code = state.get(\"current_code\", \"\")\n",
    "            \n",
    "            # Validation prompt\n",
    "            validation_prompt = \"\"\"\n",
    "You are an expert code reviewer. Validate the provided Python code thoroughly.\n",
    "\n",
    "VALIDATION CRITERIA:\n",
    "1. Code Completeness:\n",
    "   - All required functionality implemented\n",
    "   - Proper error handling included\n",
    "   - Complete class/function implementations\n",
    "   - Necessary imports present\n",
    "\n",
    "2. Code Quality:\n",
    "   - PEP 8 compliance\n",
    "   - Proper type hints\n",
    "   - Comprehensive docstrings\n",
    "   - Clear organization\n",
    "   - Error handling\n",
    "   - Logging implementation\n",
    "\n",
    "3. Functionality Requirements:\n",
    "   - All acceptance criteria met\n",
    "   - Proper input validation\n",
    "   - Correct implementation logic\n",
    "   - Appropriate error handling\n",
    "   - Result handling\n",
    "\n",
    "Review the code and provide validation results in this JSON format:\n",
    "{\n",
    "    \"valid\": boolean,\n",
    "    \"errors\": [\n",
    "        {\n",
    "            \"category\": \"missing_feature|implementation_error|quality_issue\",\n",
    "            \"description\": \"Detailed description of the issue\",\n",
    "            \"severity\": \"high|medium|low\"\n",
    "        }\n",
    "    ],\n",
    "    \"suggestions\": [\n",
    "        {\n",
    "            \"category\": \"improvement|addition|modification\",\n",
    "            \"description\": \"Detailed suggestion for improvement\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "            \n",
    "            validation_message = SystemMessage(content=validation_prompt)\n",
    "            messages.append(validation_message)\n",
    "            messages.append(HumanMessage(content=current_code))\n",
    "            \n",
    "            # Get validation feedback\n",
    "            response = self.model.invoke(messages)\n",
    "            validation_result = json.loads(response.content)\n",
    "            \n",
    "            # Save validation results\n",
    "            self.save_validation_results(validation_result, state['attempt_number'])\n",
    "            \n",
    "            # Save validated code\n",
    "            self.save_code_attempt(\n",
    "                current_code, \n",
    "                state['attempt_number'],\n",
    "                f\"validated_{'pass' if validation_result['valid'] else 'fail'}\"\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                'messages': messages,\n",
    "                'current_code': current_code,\n",
    "                'validation_status': validation_result['valid'],\n",
    "                'error_messages': [e['description'] for e in validation_result.get('errors', [])],\n",
    "                'attempt_number': state['attempt_number']\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in validator node: {str(e)}\")\n",
    "            return {\n",
    "                'messages': messages,\n",
    "                'validation_status': False,\n",
    "                'error_messages': [str(e)],\n",
    "                'attempt_number': state['attempt_number']\n",
    "            }\n",
    "\n",
    "    def correction(self, state: CodeGenerationState) -> Dict[str, Any]:\n",
    "        \"\"\"Correct code based on validation feedback\"\"\"\n",
    "        try:\n",
    "            if self.current_attempt >= self.max_attempts:\n",
    "                logger.error(\"Maximum correction attempts reached\")\n",
    "                return {\n",
    "                    'messages': state['messages'],\n",
    "                    'validation_status': False,\n",
    "                    'error_messages': [\"Maximum correction attempts reached\"],\n",
    "                    'attempt_number': state['attempt_number']\n",
    "                }\n",
    "            \n",
    "            messages = state['messages']\n",
    "            error_messages = state.get('error_messages', [])\n",
    "            \n",
    "            correction_prompt = f\"\"\"\n",
    "You are an expert Python developer. Fix the provided code based on the validation feedback.\n",
    "\n",
    "VALIDATION ISSUES:\n",
    "{chr(10).join(f'- {error}' for error in error_messages)}\n",
    "\n",
    "REQUIREMENTS:\n",
    "1. Fix all reported issues\n",
    "2. Maintain code organization\n",
    "3. Keep existing functionality\n",
    "4. Follow best practices\n",
    "5. Ensure code is complete and runnable\n",
    "\n",
    "Return ONLY the complete, corrected Python code without any markdown or explanations.\n",
    "\"\"\"\n",
    "            \n",
    "            messages.append(SystemMessage(content=correction_prompt))\n",
    "            \n",
    "            # Generate corrected code\n",
    "            response = self.model.invoke(messages)\n",
    "            corrected_code = response.content\n",
    "            \n",
    "            # Save correction attempt\n",
    "            self.current_attempt += 1\n",
    "            self.save_code_attempt(corrected_code, self.current_attempt, \"correction\")\n",
    "            \n",
    "            return {\n",
    "                'messages': messages,\n",
    "                'current_code': corrected_code,\n",
    "                'validation_status': None,\n",
    "                'error_messages': [],\n",
    "                'attempt_number': self.current_attempt\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in correction node: {str(e)}\")\n",
    "            return {\n",
    "                'messages': state['messages'],\n",
    "                'error_messages': [str(e)],\n",
    "                'attempt_number': state['attempt_number']\n",
    "            }\n",
    "\n",
    "def generate_code(requirements: Dict[str, Any], output_dir: str = \"code_generation\"):\n",
    "    \"\"\"Main function to generate code based on requirements\"\"\"\n",
    "    from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "    from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "    \n",
    "    # Initialize the model\n",
    "    llm = HuggingFaceEndpoint(\n",
    "        repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "        task=\"text-generation\",\n",
    "        max_new_tokens=8000,\n",
    "        do_sample=False,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    model = ChatHuggingFace(llm=llm, verbose=True)\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Initialize code generator\n",
    "    with SqliteSaver.from_conn_string(\":memory:\") as checkpointer:\n",
    "        generator = CodeGenerator(model, checkpointer, output_dir)\n",
    "        \n",
    "        # Create initial message with requirements\n",
    "        user_message = HumanMessage(content=json.dumps(requirements))\n",
    "        \n",
    "        # Generate and validate code\n",
    "        thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "        final_result = None\n",
    "        \n",
    "        for event in generator.graph.stream({\"messages\": [user_message]}, thread):\n",
    "            final_result = event\n",
    "            \n",
    "            # Log progress\n",
    "            if event.get('error_messages'):\n",
    "                logger.info(f\"Attempt {event['attempt_number']} - Issues found:\")\n",
    "                for error in event['error_messages']:\n",
    "                    logger.info(f\"- {error}\")\n",
    "            \n",
    "            if event.get('validation_status') == True:\n",
    "                logger.info(f\"Successfully generated valid code on attempt {event['attempt_number']}\")\n",
    "                break\n",
    "        \n",
    "        return final_result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example requirements\n",
    "    requirements = {\n",
    "        \"Title\": \"Image Preprocessing as per Model\",\n",
    "        \"Description\": \"As a user, I want the system to perform image preprocessing...\",\n",
    "        \"AcceptanceCriteria\": [\n",
    "            \"Pre-processing should successfully be implemented on images with the following bit representations: 1-bit, 8-bit,16-bit, 24-bit, 32-bit.\",\n",
    "            \"The pre-processing system shall be able to resize the input images into the resolution required by the AI model.\",\n",
    "            \"The pre-processing system shall be able to normalize the input image data into appropriate pixel datatype required by the AI model.\",\n",
    "            \"When pre-processing is successful for the training dataset, the data shall be sent further for batch creation.\",\n",
    "            \"When pre-processing is successful for inferencing (prediction) dataset, the data shall be sent for model inferencing.\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Generate code\n",
    "    result = generate_code(requirements)\n",
    "    \n",
    "    if result and result.get('validation_status'):\n",
    "        logger.info(\"Code generation successful!\")\n",
    "        logger.info(f\"Check the generated code in the output directory\")\n",
    "    else:\n",
    "        logger.error(\"Failed to generate valid code after maximum attempts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/airangers/anaconda3/envs/e/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-02-25 11:07:16,800 - INFO - Saved code attempt 1 to code_generation/generation_20250225_110716/attempt_1_initial/code.py\n",
      "2025-02-25 11:08:03,829 - ERROR - Error in validator node: Expecting value: line 1 column 5 (char 4)\n",
      "2025-02-25 11:08:14,431 - ERROR - Error in validator node: Expecting value: line 1 column 13 (char 12)\n",
      "2025-02-25 11:08:36,671 - INFO - Saved code attempt 2 to code_generation/generation_20250225_110716/attempt_2_correction/code.py\n",
      "2025-02-25 11:08:37,095 - ERROR - Error in validator node: 422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct/v1/chat/completions (Request ID: Root=1-67bd575c-46d4246a3679634d487b1808;9c80c6da-0fc4-453e-90b2-78f1c71224ba)\n",
      "\n",
      "Input validation error: `inputs` tokens + `max_new_tokens` must be <= 8192. Given: 10697 `inputs` tokens and 0 `max_new_tokens`\n",
      "2025-02-25 11:08:37,769 - ERROR - Error in validator node: 422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct/v1/chat/completions (Request ID: Root=1-67bd575d-3e6c377d5252851931b37c7c;8c6b1012-4d7f-4520-9336-472af750d4c0)\n",
      "\n",
      "Input validation error: `inputs` tokens + `max_new_tokens` must be <= 8192. Given: 22671 `inputs` tokens and 0 `max_new_tokens`\n",
      "2025-02-25 11:08:38,251 - ERROR - Error in correction node: 422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct/v1/chat/completions (Request ID: Root=1-67bd575d-20c1d54454bf960e5bff8005;de99654d-d3bc-4bdd-8157-5abe4a432ab8)\n",
      "\n",
      "Input validation error: `inputs` tokens + `max_new_tokens` must be <= 8192. Given: 21602 `inputs` tokens and 0 `max_new_tokens`\n",
      "2025-02-25 11:08:38,868 - ERROR - Error in validator node: 422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct/v1/chat/completions (Request ID: Root=1-67bd575e-50a1f88214cf52d35f6f0927;5b2a8425-bfe4-45e4-9136-f332bcd92bfc)\n",
      "\n",
      "Input validation error: `inputs` tokens + `max_new_tokens` must be <= 8192. Given: 44481 `inputs` tokens and 0 `max_new_tokens`\n",
      "2025-02-25 11:08:39,950 - ERROR - Error in validator node: 422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct/v1/chat/completions (Request ID: Root=1-67bd575f-56637c552cc2c59a7307e29d;2977dae2-7e8b-46dc-a956-b9490cbfbbae)\n",
      "\n",
      "Input validation error: `inputs` tokens + `max_new_tokens` must be <= 8192. Given: 90239 `inputs` tokens and 0 `max_new_tokens`\n",
      "2025-02-25 11:08:40,650 - ERROR - Error in correction node: 422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct/v1/chat/completions (Request ID: Root=1-67bd5760-5c2679855bf8a7802736e80f;2af4feba-5a90-4e33-b06a-61614d9990dd)\n",
      "\n",
      "Input validation error: `inputs` tokens + `max_new_tokens` must be <= 8192. Given: 89169 `inputs` tokens and 0 `max_new_tokens`\n",
      "2025-02-25 11:08:42,044 - ERROR - Error in validator node: 422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct/v1/chat/completions (Request ID: Root=1-67bd5760-67a40d5e762a8eeb6c385f0c;e01dd85d-7cb4-4e78-8e0d-38b2fa034275)\n",
      "\n",
      "Input validation error: `inputs` tokens + `max_new_tokens` must be <= 8192. Given: 179615 `inputs` tokens and 0 `max_new_tokens`\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Annotated, Optional, List, Dict, Any\n",
    "import operator\n",
    "from pathlib import Path\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class CodeGenerationState(TypedDict):\n",
    "    \"\"\"State management for code generation process\"\"\"\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "    current_code: Optional[str]\n",
    "    validation_status: Optional[bool]\n",
    "    error_messages: Optional[list[str]]\n",
    "    attempt_number: int\n",
    "\n",
    "class CodeGenerator:\n",
    "    \"\"\"Main class for generating, validating, and correcting code\"\"\"\n",
    "    \n",
    "    def __init__(self, model, checkpointer, base_output_dir: str):\n",
    "        self.model = model\n",
    "        self.base_output_dir = base_output_dir\n",
    "        self.current_attempt = 0\n",
    "        self.max_attempts = 15\n",
    "        \n",
    "        # Create base output directory with timestamp\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        self.base_output_dir = os.path.join(base_output_dir, f\"generation_{timestamp}\")\n",
    "        os.makedirs(self.base_output_dir, exist_ok=True)\n",
    "        \n",
    "        # Initialize graph\n",
    "        graph = StateGraph(CodeGenerationState)\n",
    "        \n",
    "        # Add nodes\n",
    "        graph.add_node(\"developer\", self.developer)\n",
    "        graph.add_node(\"validator\", self.validator)\n",
    "        graph.add_node(\"correction\", self.correction)\n",
    "        \n",
    "        # Add edges\n",
    "        graph.add_edge(\"developer\", \"validator\")\n",
    "        graph.add_conditional_edges(\n",
    "            \"validator\",\n",
    "            lambda state: self.validator(state)[\"validation_status\"],\n",
    "            {\n",
    "                True: END,\n",
    "                False: \"correction\"\n",
    "            }\n",
    "        )\n",
    "        graph.add_edge(\"correction\", \"validator\")\n",
    "        \n",
    "        # Set entry point\n",
    "        graph.set_entry_point(\"developer\")\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "\n",
    "    def strip_markdown_code_blocks(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Strip markdown code block formatting from text\n",
    "        Removes triple backticks and language identifiers that often surround code generated by LLMs\n",
    "        \"\"\"\n",
    "        # Check if the text starts with triple backticks and remove the first line if it does\n",
    "        if text.lstrip().startswith(\"```\"):\n",
    "            lines = text.split('\\n')\n",
    "            # Skip the first line (which has the opening backticks)\n",
    "            if len(lines) > 1:\n",
    "                text = '\\n'.join(lines[1:])\n",
    "        \n",
    "        # Check if the text ends with triple backticks and remove them\n",
    "        if text.rstrip().endswith(\"```\"):\n",
    "            lines = text.split('\\n')\n",
    "            # Remove the last line if it only contains backticks\n",
    "            if lines[-1].strip() == \"```\":\n",
    "                text = '\\n'.join(lines[:-1])\n",
    "                \n",
    "        return text\n",
    "\n",
    "    def format_requirements_prompt(self, requirements: Dict[str, Any]) -> str:\n",
    "        \"\"\"Format requirements into a development prompt\"\"\"\n",
    "        title = requirements.get('Title', 'Code Generation Task')\n",
    "        description = requirements.get('Description', '')\n",
    "        acceptance_criteria = requirements.get('AcceptanceCriteria', [])\n",
    "        \n",
    "        return f\"\"\"\n",
    "You are an expert Python developer. Generate production-ready Python code based on these requirements.\n",
    "\n",
    "REQUIREMENTS SPECIFICATION:\n",
    "Title: {title}\n",
    "Description: {description}\n",
    "\n",
    "Acceptance Criteria:\n",
    "{chr(10).join(f'- {criterion}' for criterion in acceptance_criteria)}\n",
    "\n",
    "CODE GENERATION GUIDELINES:\n",
    "\n",
    "1. Code Structure:\n",
    "   - Create a complete, self-contained Python script\n",
    "   - Use proper class and function organization\n",
    "   - Implement all specified functionality\n",
    "   - Include all necessary imports\n",
    "   - Create appropriate classes with clear responsibilities\n",
    "   - Use dataclasses for configuration management\n",
    "   - Implement utility functions as needed\n",
    "\n",
    "2. Code Quality Requirements:\n",
    "   - Follow PEP 8 standards strictly\n",
    "   - Use type hints for all functions and methods\n",
    "   - Include detailed docstrings (Google style)\n",
    "   - Implement comprehensive error handling\n",
    "   - Add proper logging throughout\n",
    "   - Make code modular and maintainable\n",
    "\n",
    "3. Implementation Requirements:\n",
    "   - Create robust classes and methods\n",
    "   - Include all necessary validation\n",
    "   - Handle edge cases properly\n",
    "   - Implement batch processing if needed\n",
    "   - Add progress tracking\n",
    "   - Save or return results appropriately\n",
    "   - Use appropriate design patterns\n",
    "\n",
    "4. Documentation:\n",
    "   - Add detailed docstrings for all components\n",
    "   - Include usage examples in docstrings\n",
    "   - Document assumptions and limitations\n",
    "   - Add inline comments for complex logic\n",
    "   - Include type hints for clarity\n",
    "\n",
    "5. Error Handling:\n",
    "   - Validate all inputs thoroughly\n",
    "   - Handle expected error cases\n",
    "   - Provide clear error messages\n",
    "   - Implement proper logging\n",
    "   - Use custom exceptions if needed\n",
    "\n",
    "Return ONLY the complete, runnable Python code without any markdown or explanations.\n",
    "\"\"\"\n",
    "\n",
    "    def save_code_attempt(self, code: str, attempt_number: int, status: str = \"initial\") -> str:\n",
    "        \"\"\"Save code attempt to file and return the directory path\"\"\"\n",
    "        attempt_dir = os.path.join(self.base_output_dir, f\"attempt_{attempt_number}_{status}\")\n",
    "        os.makedirs(attempt_dir, exist_ok=True)\n",
    "        \n",
    "        code_file = os.path.join(attempt_dir, \"code.py\")\n",
    "        with open(code_file, 'w') as f:\n",
    "            f.write(code)\n",
    "        \n",
    "        logger.info(f\"Saved code attempt {attempt_number} to {code_file}\")\n",
    "        return attempt_dir\n",
    "\n",
    "    def save_validation_results(self, validation_result: Dict[str, Any], attempt_number: int) -> None:\n",
    "        \"\"\"Save validation results to file\"\"\"\n",
    "        validation_file = os.path.join(\n",
    "            self.base_output_dir, \n",
    "            f\"attempt_{attempt_number}_validation.json\"\n",
    "        )\n",
    "        with open(validation_file, 'w') as f:\n",
    "            json.dump(validation_result, f, indent=2)\n",
    "        \n",
    "        logger.info(f\"Saved validation results to {validation_file}\")\n",
    "\n",
    "    def developer(self, state: CodeGenerationState) -> Dict[str, Any]:\n",
    "        \"\"\"Generate initial code or process corrections\"\"\"\n",
    "        try:\n",
    "            messages = state['messages']\n",
    "            requirements = json.loads(messages[0].content)\n",
    "            \n",
    "            # Format prompt with requirements\n",
    "            prompt = self.format_requirements_prompt(requirements)\n",
    "            messages.append(SystemMessage(content=prompt))\n",
    "            \n",
    "            # Generate code\n",
    "            response = self.model.invoke(messages)\n",
    "            generated_code = response.content\n",
    "            \n",
    "            # Strip markdown code blocks if present\n",
    "            generated_code = self.strip_markdown_code_blocks(generated_code)\n",
    "            \n",
    "            # Save initial code\n",
    "            self.current_attempt += 1\n",
    "            attempt_dir = self.save_code_attempt(generated_code, self.current_attempt)\n",
    "            \n",
    "            return {\n",
    "                'messages': messages,\n",
    "                'current_code': generated_code,\n",
    "                'validation_status': None,\n",
    "                'error_messages': [],\n",
    "                'attempt_number': self.current_attempt\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in developer node: {str(e)}\")\n",
    "            return {\n",
    "                'messages': messages,\n",
    "                'error_messages': [str(e)],\n",
    "                'attempt_number': self.current_attempt\n",
    "            }\n",
    "\n",
    "    def validator(self, state: CodeGenerationState) -> Dict[str, Any]:\n",
    "        \"\"\"Validate generated code\"\"\"\n",
    "        try:\n",
    "            messages = state.get(\"messages\", [])\n",
    "            current_code = state.get(\"current_code\", \"\")\n",
    "            \n",
    "            # Strip markdown code blocks if present\n",
    "            current_code = self.strip_markdown_code_blocks(current_code)\n",
    "            \n",
    "            # Validation prompt\n",
    "            validation_prompt = \"\"\"\n",
    "You are an expert code reviewer. Validate the provided Python code thoroughly.\n",
    "\n",
    "VALIDATION CRITERIA:\n",
    "1. Code Completeness:\n",
    "   - All required functionality implemented\n",
    "   - Proper error handling included\n",
    "   - Complete class/function implementations\n",
    "   - Necessary imports present\n",
    "\n",
    "2. Code Quality:\n",
    "   - PEP 8 compliance\n",
    "   - Proper type hints\n",
    "   - Comprehensive docstrings\n",
    "   - Clear organization\n",
    "   - Error handling\n",
    "   - Logging implementation\n",
    "\n",
    "3. Functionality Requirements:\n",
    "   - All acceptance criteria met\n",
    "   - Proper input validation\n",
    "   - Correct implementation logic\n",
    "   - Appropriate error handling\n",
    "   - Result handling\n",
    "\n",
    "Review the code and provide validation results in this JSON format:\n",
    "{\n",
    "    \"valid\": boolean,\n",
    "    \"errors\": [\n",
    "        {\n",
    "            \"category\": \"missing_feature|implementation_error|quality_issue\",\n",
    "            \"description\": \"Detailed description of the issue\",\n",
    "            \"severity\": \"high|medium|low\"\n",
    "        }\n",
    "    ],\n",
    "    \"suggestions\": [\n",
    "        {\n",
    "            \"category\": \"improvement|addition|modification\",\n",
    "            \"description\": \"Detailed suggestion for improvement\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "            \n",
    "            validation_message = SystemMessage(content=validation_prompt)\n",
    "            messages.append(validation_message)\n",
    "            messages.append(HumanMessage(content=current_code))\n",
    "            \n",
    "            # Get validation feedback\n",
    "            response = self.model.invoke(messages)\n",
    "            validation_result = json.loads(response.content)\n",
    "            \n",
    "            # Save validation results\n",
    "            self.save_validation_results(validation_result, state['attempt_number'])\n",
    "            \n",
    "            # Save validated code\n",
    "            self.save_code_attempt(\n",
    "                current_code, \n",
    "                state['attempt_number'],\n",
    "                f\"validated_{'pass' if validation_result['valid'] else 'fail'}\"\n",
    "            )\n",
    "            \n",
    "            # Update current_code in state with the stripped version\n",
    "            state['current_code'] = current_code\n",
    "            \n",
    "            return {\n",
    "                'messages': messages,\n",
    "                'current_code': current_code,\n",
    "                'validation_status': validation_result['valid'],\n",
    "                'error_messages': [e['description'] for e in validation_result.get('errors', [])],\n",
    "                'attempt_number': state['attempt_number']\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in validator node: {str(e)}\")\n",
    "            return {\n",
    "                'messages': messages,\n",
    "                'validation_status': False,\n",
    "                'error_messages': [str(e)],\n",
    "                'attempt_number': state['attempt_number']\n",
    "            }\n",
    "\n",
    "    def correction(self, state: CodeGenerationState) -> Dict[str, Any]:\n",
    "        \"\"\"Correct code based on validation feedback\"\"\"\n",
    "        try:\n",
    "            if self.current_attempt >= self.max_attempts:\n",
    "                logger.error(\"Maximum correction attempts reached\")\n",
    "                return {\n",
    "                    'messages': state['messages'],\n",
    "                    'validation_status': False,\n",
    "                    'error_messages': [\"Maximum correction attempts reached\"],\n",
    "                    'attempt_number': state['attempt_number']\n",
    "                }\n",
    "            \n",
    "            messages = state['messages']\n",
    "            error_messages = state.get('error_messages', [])\n",
    "            current_code = state.get('current_code', '')\n",
    "            \n",
    "            # Strip markdown code blocks if present\n",
    "            current_code = self.strip_markdown_code_blocks(current_code)\n",
    "            \n",
    "            correction_prompt = f\"\"\"\n",
    "You are an expert Python developer. Fix the provided code based on the validation feedback.\n",
    "\n",
    "VALIDATION ISSUES:\n",
    "{chr(10).join(f'- {error}' for error in error_messages)}\n",
    "\n",
    "REQUIREMENTS:\n",
    "1. Fix all reported issues\n",
    "2. Maintain code organization\n",
    "3. Keep existing functionality\n",
    "4. Follow best practices\n",
    "5. Ensure code is complete and runnable\n",
    "\n",
    "Return ONLY the complete, corrected Python code without any markdown or explanations.\n",
    "\"\"\"\n",
    "            \n",
    "            messages.append(SystemMessage(content=correction_prompt))\n",
    "            \n",
    "            # Generate corrected code\n",
    "            response = self.model.invoke(messages)\n",
    "            corrected_code = response.content\n",
    "            \n",
    "            # Strip markdown code blocks if present\n",
    "            corrected_code = self.strip_markdown_code_blocks(corrected_code)\n",
    "            \n",
    "            # Save correction attempt\n",
    "            self.current_attempt += 1\n",
    "            self.save_code_attempt(corrected_code, self.current_attempt, \"correction\")\n",
    "            \n",
    "            return {\n",
    "                'messages': messages,\n",
    "                'current_code': corrected_code,\n",
    "                'validation_status': None,\n",
    "                'error_messages': [],\n",
    "                'attempt_number': self.current_attempt\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in correction node: {str(e)}\")\n",
    "            return {\n",
    "                'messages': state['messages'],\n",
    "                'error_messages': [str(e)],\n",
    "                'attempt_number': state['attempt_number']\n",
    "            }\n",
    "\n",
    "def generate_code(requirements: Dict[str, Any], output_dir: str = \"code_generation\"):\n",
    "    \"\"\"Main function to generate code based on requirements\"\"\"\n",
    "    from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "    from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "    \n",
    "    # Initialize the model\n",
    "    llm = HuggingFaceEndpoint(\n",
    "        repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "        task=\"text-generation\",\n",
    "        max_new_tokens=8000,\n",
    "        do_sample=False,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    model = ChatHuggingFace(llm=llm, verbose=True)\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Initialize code generator\n",
    "    with SqliteSaver.from_conn_string(\":memory:\") as checkpointer:\n",
    "        generator = CodeGenerator(model, checkpointer, output_dir)\n",
    "        \n",
    "        # Create initial message with requirements\n",
    "        user_message = HumanMessage(content=json.dumps(requirements))\n",
    "        \n",
    "        # Generate and validate code\n",
    "        thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "        final_result = None\n",
    "        \n",
    "        for event in generator.graph.stream({\"messages\": [user_message]}, thread):\n",
    "            final_result = event\n",
    "            \n",
    "            # Log progress\n",
    "            if event.get('error_messages'):\n",
    "                logger.info(f\"Attempt {event['attempt_number']} - Issues found:\")\n",
    "                for error in event['error_messages']:\n",
    "                    logger.info(f\"- {error}\")\n",
    "            \n",
    "            if event.get('validation_status') == True:\n",
    "                logger.info(f\"Successfully generated valid code on attempt {event['attempt_number']}\")\n",
    "                break\n",
    "        \n",
    "        return final_result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example requirements\n",
    "    requirements = {\n",
    "        \"Title\": \"Image Preprocessing as per Model\",\n",
    "        \"Description\": \"As a user, I want the system to perform image preprocessing...\",\n",
    "        \"AcceptanceCriteria\": [\n",
    "            \"Pre-processing should successfully be implemented on images with the following bit representations: 1-bit, 8-bit,16-bit, 24-bit, 32-bit.\",\n",
    "            \"The pre-processing system shall be able to resize the input images into the resolution required by the AI model.\",\n",
    "            \"The pre-processing system shall be able to normalize the input image data into appropriate pixel datatype required by the AI model.\",\n",
    "            \"When pre-processing is successful for the training dataset, the data shall be sent further for batch creation.\",\n",
    "            \"When pre-processing is successful for inferencing (prediction) dataset, the data shall be sent for model inferencing.\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Generate code\n",
    "    result = generate_code(requirements)\n",
    "    \n",
    "    if result and result.get('validation_status'):\n",
    "        logger.info(\"Code generation successful!\")\n",
    "        logger.info(f\"Check the generated code in the output directory\")\n",
    "    else:\n",
    "        logger.error(\"Failed to generate valid code after maximum attempts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
