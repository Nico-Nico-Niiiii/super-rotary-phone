{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage\n",
    "from IPython.display import Image, display\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Azure OpenAI configuration\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"0bf3daeba1814d03b5d62e1da4077478\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://openaisk123.openai.azure.com/\"\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-08-01-preview\"\n",
    "os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"] = \"gpt-4o\"\n",
    "\n",
    "class CodeGenerationState(TypedDict):\n",
    "    \"\"\"State management for code generation process\"\"\"\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "    current_code: str\n",
    "    validation_status: bool\n",
    "    error_messages: list[str]\n",
    "    is_valid: bool  # Using is_valid to match the notebook's conditional edge structure\n",
    "    user_story_id: str  # Added to track user story ID for folder naming\n",
    "\n",
    "# Define prompts\n",
    "developer_prompt = \"\"\"\n",
    "Role: Python Developer\n",
    "Task: Generate complete, production-ready Python code based on the requirements specification.\n",
    "\n",
    "Requirements:\n",
    "{requirements}\n",
    "\n",
    "Your code must include:\n",
    "1. All necessary imports and dependencies\n",
    "2. Complete implementation with:\n",
    "   - Well-structured classes and functions\n",
    "   - Configuration management (using dataclasses or similar)\n",
    "   - Comprehensive error handling and validation\n",
    "   - Type hints throughout\n",
    "   - Logging with appropriate levels\n",
    "   - Unit tests where applicable\n",
    "3. Clear documentation:\n",
    "   - Module docstrings\n",
    "   - Function/method docstrings with parameters and return values\n",
    "   - Inline comments for complex logic\n",
    "\n",
    "Focus on implementing EVERY aspect mentioned in the requirements. Do not leave any required functionality unimplemented.\n",
    "\n",
    "## Output Format\n",
    "Your response should be the complete, production-ready Python code without surrounding explanations.\n",
    "DO NOT enclose your code in triple backticks (``` or ''').\n",
    "Simply output the pure Python code directly:\n",
    "\n",
    "# Your Python code here\n",
    "\"\"\"\n",
    "\n",
    "validator_prompt = \"\"\"\n",
    "Role: Senior Code Reviewer\n",
    "Task: Perform a thorough validation of the provided Python code against the requirements.\n",
    "\n",
    "Requirements:\n",
    "{Requirements}\n",
    "\n",
    "Validation Process:\n",
    "1. Carefully compare the code against EACH requirement in the specification\n",
    "2. For each requirement, determine if it has been fully, partially, or not implemented\n",
    "3. Identify any missing functionality, edge cases, or requirements\n",
    "4. Evaluate code quality, error handling, security, and performance\n",
    "\n",
    "Validation Checklist:\n",
    "1. Code Completeness:\n",
    "   - All imports and dependencies present\n",
    "   - Full implementation of required functionality (check EACH requirement)\n",
    "   - No placeholder code or TODOs\n",
    "\n",
    "2. Code Quality:\n",
    "   - Follows PEP 8 standards\n",
    "   - Clear variable/function naming\n",
    "   - Appropriate modularization\n",
    "   - Avoids code duplication\n",
    "   - Maintainable architecture\n",
    "\n",
    "3. Technical Implementation:\n",
    "   - Proper error handling with specific exceptions\n",
    "   - Complete type annotations\n",
    "   - Correct algorithm implementation\n",
    "   - Efficient resource usage\n",
    "   - Security considerations addressed\n",
    "\n",
    "4. Documentation:\n",
    "   - Comprehensive docstrings\n",
    "   - Clear inline comments where needed\n",
    "\n",
    "## Output Format\n",
    "Return your validation report as a structured JSON object with the following format:\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"validation_report\": {{\n",
    "    \"overall_assessment\": \"Pass/Fail\",\n",
    "    \"issues_found\": [\n",
    "      \"Issue 1 description\",\n",
    "      \"Issue 2 description\",\n",
    "      \"...\"\n",
    "    ],\n",
    "    \"suggested_improvements\": [\n",
    "      {{\n",
    "        \"description\": \"Improvement 1\",\n",
    "        \"priority\": \"high/medium/low\"\n",
    "      }},\n",
    "      \"...\"\n",
    "    ],\n",
    "    \"implementation_vs_requirements\": {{\n",
    "      \"match\": true/false,\n",
    "      \"details\": [\n",
    "        {{\n",
    "          \"requirement_section\": \"Requirement name/section\",\n",
    "          \"status\": \"Implemented/Partially Implemented/Not Implemented\",\n",
    "          \"notes\": \"Notes about implementation\"\n",
    "        }},\n",
    "        \"...\"\n",
    "      ]\n",
    "    }}\n",
    "  }}\n",
    "}}\n",
    "\n",
    "Be strict in your assessment. If ANY requirement is not fully implemented, the overall assessment should be \"Fail\".\n",
    "\"\"\"\n",
    "\n",
    "corrector_prompt = \"\"\"\n",
    "Role: Senior Python Developer\n",
    "Task: Refactor and fix the code based on the validation feedback.\n",
    "Original Requirements:\n",
    "{requirements}\n",
    "Validation Feedback:\n",
    "{ValidationFeedback}\n",
    "Correction Instructions:\n",
    "\n",
    "Address ALL issues identified in the validation feedback\n",
    "Pay particular attention to any requirements marked as \"Not Implemented\" or \"Partially Implemented\"\n",
    "Maintain the original architectural approach unless fundamentally flawed\n",
    "Ensure complete implementation of ALL requirements from the original specification\n",
    "Add or improve:\n",
    "\n",
    "Error handling for all edge cases\n",
    "Type hints throughout the codebase\n",
    "Documentation (docstrings and comments)\n",
    "Logging for important operations\n",
    "Performance optimizations where possible\n",
    "\n",
    "Important: Make sure you implement EVERY feature mentioned in the requirements that was flagged as missing or incomplete in the validation feedback.\n",
    "Output Format\n",
    "Your response should be the complete, corrected, production-ready Python code without explanations.\n",
    "DO NOT enclose your code in triple backticks (``` or ''').\n",
    "Simply output the pure Python code directly:\n",
    "Your corrected Python code here\n",
    "\"\"\"\n",
    "\n",
    "def extract_user_story_id(user_story_text):\n",
    "    \"\"\"\n",
    "    Extract user story ID from the text that contains 'User Story ID: XXX'\n",
    "    \n",
    "    Args:\n",
    "        user_story_text (str): The full user story text\n",
    "        \n",
    "    Returns:\n",
    "        str: The extracted user story ID or 'unknown_id' if not found\n",
    "    \"\"\"\n",
    "    # Look for \"User Story ID: XXX\" pattern\n",
    "    match = re.search(r'User\\s+Story\\s+ID\\s*:\\s*(\\d+)', user_story_text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return f\"US_{match.group(1)}\"\n",
    "    \n",
    "    # Alternative pattern - look for \"userstory1\" or similar patterns at the start of a line\n",
    "    match = re.search(r'^(?:(?:user)?story|us)(\\d+)', user_story_text, re.IGNORECASE | re.MULTILINE)\n",
    "    if match:\n",
    "        return f\"US_{match.group(1)}\"\n",
    "    \n",
    "    # If no ID is found, generate a fallback ID based on a hash of the content\n",
    "    logger.warning(\"No user story ID found in text, using fallback ID\")\n",
    "    import hashlib\n",
    "    hash_id = hashlib.md5(user_story_text.encode()).hexdigest()[:8]\n",
    "    return f\"Unknown_ID_{hash_id}\"\n",
    "\n",
    "def read_tech_specs_from_excel(excel_file_path):\n",
    "    \"\"\"\n",
    "    Read technical specifications from Excel file.\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries, each containing:\n",
    "        - 'user_story_id': ID of the user story\n",
    "        - 'tech_spec': Technical specification\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(excel_file_path)\n",
    "        \n",
    "        # Find the user story column and tech spec column\n",
    "        user_story_col = None\n",
    "        tech_spec_col = None\n",
    "        \n",
    "        # Determine column names - assuming first row has column headers\n",
    "        col_names = df.columns.tolist()\n",
    "        \n",
    "        # Find user story column\n",
    "        for col in col_names:\n",
    "            if 'user' in str(col).lower() and 'story' in str(col).lower():\n",
    "                user_story_col = col\n",
    "                break\n",
    "        \n",
    "        # Find tech spec column\n",
    "        for col in col_names:\n",
    "            if ('tech' in str(col).lower() and 'spec' in str(col).lower()) or 'requirement' in str(col).lower():\n",
    "                tech_spec_col = col\n",
    "                break\n",
    "        \n",
    "        # If we didn't find the right columns, default to the first two\n",
    "        if user_story_col is None and len(col_names) > 0:\n",
    "            user_story_col = col_names[0]\n",
    "        \n",
    "        if tech_spec_col is None and len(col_names) > 1:\n",
    "            tech_spec_col = col_names[1]\n",
    "        \n",
    "        logger.info(f\"Using columns: User Story = '{user_story_col}', Tech Spec = '{tech_spec_col}'\")\n",
    "        \n",
    "        # Extract tech specs\n",
    "        tech_specs = []\n",
    "        \n",
    "        # Skip the first row if it's empty (which appears to be the case)\n",
    "        start_row = 1 if df.iloc[0].isna().all() else 0\n",
    "        \n",
    "        for idx, row in df.iloc[start_row:].iterrows():\n",
    "            if pd.isna(row[user_story_col]) or pd.isna(row[tech_spec_col]):\n",
    "                logger.warning(f\"Skipping row {idx} due to missing data\")\n",
    "                continue\n",
    "                \n",
    "            user_story_text = str(row[user_story_col])\n",
    "            tech_spec_text = str(row[tech_spec_col])\n",
    "            \n",
    "            # Extract user story ID using the helper function\n",
    "            user_story_id = extract_user_story_id(user_story_text)\n",
    "            \n",
    "            tech_specs.append({\n",
    "                'user_story_id': user_story_id,\n",
    "                'tech_spec': tech_spec_text\n",
    "            })\n",
    "        \n",
    "        logger.info(f\"Successfully extracted {len(tech_specs)} tech specs from Excel file\")\n",
    "        return tech_specs\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error reading Excel file: {e}\")\n",
    "        raise\n",
    "\n",
    "class CodeGenerator:\n",
    "    \"\"\"Main class for generating, validating, and correcting code\"\"\"\n",
    "    \n",
    "    def __init__(self, model, base_output_dir=None, system_developer=\"\", system_validator=\"\", system_corrector=\"\"):\n",
    "        self.system_developer = system_developer\n",
    "        self.system_validator = system_validator\n",
    "        self.system_corrector = system_corrector\n",
    "        \n",
    "        # Create output base directory\n",
    "        self.base_output_dir = base_output_dir or f\"code_generation_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        os.makedirs(self.base_output_dir, exist_ok=True)\n",
    "        \n",
    "        # Initialize graph\n",
    "        graph = StateGraph(CodeGenerationState)\n",
    "        \n",
    "        # Add nodes\n",
    "        graph.add_node(\"developer\", self.developer)\n",
    "        graph.add_node(\"validator\", self.validator)\n",
    "        graph.add_node(\"correction\", self.correction)\n",
    "        \n",
    "        # Add edges\n",
    "        graph.add_edge(\"developer\", \"validator\")\n",
    "        \n",
    "        # Add conditional edges (matching notebook pattern)\n",
    "        graph.add_conditional_edges(\n",
    "            \"validator\", \n",
    "            lambda state: state[\"is_valid\"],\n",
    "            {\n",
    "                True: END,\n",
    "                False: \"correction\"\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        graph.add_edge(\"correction\", END)\n",
    "        \n",
    "        # Set entry point\n",
    "        graph.set_entry_point(\"developer\")\n",
    "        self.graph = graph.compile()\n",
    "        self.model = model\n",
    "        \n",
    "        # Try to display graph visualization if possible\n",
    "        try:\n",
    "            display(Image(self.graph.get_graph().draw_mermaid_png()))\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error displaying graph: {e}\")\n",
    "            pass\n",
    "\n",
    "    def get_output_dir(self, user_story_id):\n",
    "        \"\"\"Create and return a user story specific output directory\"\"\"\n",
    "        # Create user story specific directory if it doesn't exist\n",
    "        user_story_dir = os.path.join(self.base_output_dir, user_story_id)\n",
    "        os.makedirs(user_story_dir, exist_ok=True)\n",
    "        return user_story_dir\n",
    "\n",
    "    def extract_code(self, text):\n",
    "        \"\"\"Extract code from between triple backticks or triple single quotes\"\"\"\n",
    "        pattern = r\"```(?:python)?\\\\s*(.*?)```\"\n",
    "        matches = re.findall(pattern, text, re.DOTALL)\n",
    "        if matches:\n",
    "            return matches[0].strip()\n",
    "            \n",
    "        # Try with triple single quotes\n",
    "        pattern = r\"'''(?:python)?\\\\s*(.*?)'''\"\n",
    "        matches = re.findall(pattern, text, re.DOTALL)\n",
    "        if matches:\n",
    "            return matches[0].strip()\n",
    "            \n",
    "        return text  # Return original if no code blocks found\n",
    "\n",
    "    def save_code_attempt(self, code: str, user_story_id: str, status: str = \"initial\") -> str:\n",
    "        \"\"\"Save code attempt and return directory path\"\"\"\n",
    "        # Get user story specific output directory\n",
    "        output_dir = self.get_output_dir(user_story_id)\n",
    "        \n",
    "        attempt_dir = os.path.join(output_dir, f\"attempt_{status}\")\n",
    "        os.makedirs(attempt_dir, exist_ok=True)\n",
    "        \n",
    "        # Save code\n",
    "        code_file = os.path.join(attempt_dir, \"code.py\")\n",
    "        with open(code_file, 'w') as f:\n",
    "            f.write(code)\n",
    "        \n",
    "        logger.info(f\"Saved code attempt to {code_file}\")\n",
    "        return attempt_dir\n",
    "\n",
    "    def developer(self, state: CodeGenerationState):\n",
    "        \"\"\"Generate initial code\"\"\"\n",
    "        messages = state['messages']\n",
    "        user_story_id = state.get('user_story_id', 'default_id')\n",
    "        logger.info(f\"Processing user story ID: {user_story_id}\")\n",
    "        print(f\"developer - User Story ID: {user_story_id}\")\n",
    "        \n",
    "        if self.system_developer:\n",
    "            # Note: Using exact case from the prompt template\n",
    "            formatted_prompt = self.system_developer.format(\n",
    "                requirements=messages[0].content,  # Changed from Requirements to requirements\n",
    "                TechnicalSpecifications=messages[0].content\n",
    "            )\n",
    "            messages = [SystemMessage(content=formatted_prompt)] + messages\n",
    "        \n",
    "        message = self.model.invoke(messages)\n",
    "        \n",
    "        # Extract code from response\n",
    "        response_text = getattr(message, \"content\", \"\")\n",
    "        code_only = self.extract_code(response_text)\n",
    "        \n",
    "        # Save code\n",
    "        self.save_code_attempt(code_only, user_story_id)\n",
    "        \n",
    "        return {\n",
    "            'messages': [message],\n",
    "            'current_code': code_only,\n",
    "            'validation_status': None,\n",
    "            'error_messages': [],\n",
    "            'is_valid': False,\n",
    "            'user_story_id': user_story_id\n",
    "        }\n",
    "\n",
    "    def validator(self, state: CodeGenerationState):\n",
    "        \"\"\"Validate generated code\"\"\"\n",
    "        messages = state.get('messages', [])\n",
    "        current_code = state.get('current_code', '')\n",
    "        user_story_id = state.get('user_story_id', 'default_id')\n",
    "        \n",
    "        print(f\"validate - User Story ID: {user_story_id}\")\n",
    "        \n",
    "        if self.system_validator:\n",
    "            original_message = state[\"messages\"][0].content if state[\"messages\"] else \"\"\n",
    "            # Note: Using exact case from the prompt template\n",
    "            formatted_prompt = self.system_validator.format(\n",
    "                Requirements=original_message,\n",
    "                TechnicalSpecifications=original_message\n",
    "            )\n",
    "            messages = [SystemMessage(content=formatted_prompt)] + messages\n",
    "        \n",
    "        message = self.model.invoke(messages)\n",
    "        response_text = getattr(message, \"content\", \"\").lower()\n",
    "        \n",
    "        # Attempt to determine if validation passed by extracting JSON\n",
    "        is_valid = False\n",
    "        try:\n",
    "            # Try to extract JSON from the message\n",
    "            json_pattern = r\"```json\\s*(.*?)\\s*```\"\n",
    "            match = re.search(json_pattern, message.content, re.DOTALL)\n",
    "            if match:\n",
    "                validation_json = json.loads(match.group(1))\n",
    "                is_valid = (validation_json.get(\"validation_report\", {}).get(\"overall_assessment\", \"\").lower() == \"pass\")\n",
    "        except:\n",
    "            # Fallback to the original logic if JSON extraction fails\n",
    "            is_valid = \"pass\" in response_text and \"correctly implements\" in response_text\n",
    "        \n",
    "        # Save validation results to JSON if possible\n",
    "        try:\n",
    "            json_pattern = r\"```json\\s*(.*?)\\s*```\"\n",
    "            match = re.search(json_pattern, message.content, re.DOTALL)\n",
    "            if match:\n",
    "                validation_json = json.loads(match.group(1))\n",
    "                output_dir = self.get_output_dir(user_story_id)\n",
    "                json_path = os.path.join(output_dir, \"validation_results.json\")\n",
    "                with open(json_path, 'w') as f:\n",
    "                    json.dump(validation_json, f, indent=2)\n",
    "                logger.info(f\"Saved validation results to {json_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to save validation results: {e}\")\n",
    "        \n",
    "        if is_valid:\n",
    "            self.save_code_attempt(current_code, user_story_id, \"validated_pass\")\n",
    "        else:\n",
    "            self.save_code_attempt(current_code, user_story_id, \"validated_fail\")\n",
    "            \n",
    "        return {\n",
    "            'messages': [message],\n",
    "            'current_code': current_code,\n",
    "            'is_valid': is_valid,\n",
    "            'error_messages': [] if is_valid else [\"Validation failed\"],\n",
    "            'user_story_id': user_story_id\n",
    "        }\n",
    "\n",
    "    def correction(self, state: CodeGenerationState):\n",
    "        \"\"\"Correct code based on validation feedback\"\"\"\n",
    "        messages = state['messages']\n",
    "        user_story_id = state.get('user_story_id', 'default_id')\n",
    "        \n",
    "        print(f\"correction - User Story ID: {user_story_id}\")\n",
    "        \n",
    "        if self.system_corrector:\n",
    "            # Get original requirements from the first human message in the chain\n",
    "            original_requirements = \"\"\n",
    "            for msg in state['messages']:\n",
    "                if isinstance(msg, HumanMessage) and msg.content:\n",
    "                    original_requirements = msg.content\n",
    "                    break\n",
    "            \n",
    "            # Get validation feedback from the most recent message\n",
    "            validation_feedback = messages[0].content if messages else \"\"\n",
    "            \n",
    "            # Note: Using exact case from the prompt template\n",
    "            formatted_prompt = self.system_corrector.format(\n",
    "                requirements=original_requirements,  # Changed from Requirements to requirements\n",
    "                ValidationFeedback=validation_feedback\n",
    "            )\n",
    "            messages = [SystemMessage(content=formatted_prompt)] + messages\n",
    "        \n",
    "        message = self.model.invoke(messages)\n",
    "        response_text = getattr(message, \"content\", \"\")\n",
    "        code_only = self.extract_code(response_text)\n",
    "        \n",
    "        # Save corrected code\n",
    "        self.save_code_attempt(code_only, user_story_id, \"correction\")\n",
    "        \n",
    "        return {\n",
    "            'messages': [message],\n",
    "            'current_code': code_only,\n",
    "            'is_valid': False,\n",
    "            'error_messages': [],\n",
    "            'user_story_id': user_story_id\n",
    "        }\n",
    "\n",
    "def process_tech_specs(excel_file_path=\"tech.xlsx\"):\n",
    "    \"\"\"\n",
    "    Process tech specs from an Excel file\n",
    "    \n",
    "    Args:\n",
    "        excel_file_path: Path to Excel file with tech specs\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read tech specs from Excel\n",
    "        tech_specs = read_tech_specs_from_excel(excel_file_path)\n",
    "        \n",
    "        if not tech_specs:\n",
    "            logger.error(\"No tech specs found in Excel file\")\n",
    "            return\n",
    "        \n",
    "        # Model initialization\n",
    "        model = AzureChatOpenAI(\n",
    "            azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "            api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "            api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "            deployment_name=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"]\n",
    "        )\n",
    "        \n",
    "        # Create a base output directory\n",
    "        base_output_dir = f\"code_generation_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        \n",
    "        # Initialize code generator with the base directory\n",
    "        code_gen = CodeGenerator(\n",
    "            model=model, \n",
    "            base_output_dir=base_output_dir,\n",
    "            system_developer=developer_prompt,\n",
    "            system_validator=validator_prompt,\n",
    "            system_corrector=corrector_prompt\n",
    "        )\n",
    "        \n",
    "        # Process each tech spec\n",
    "        for idx, spec in enumerate(tech_specs):\n",
    "            user_story_id = spec['user_story_id']\n",
    "            tech_spec = spec['tech_spec']\n",
    "            \n",
    "            logger.info(f\"Processing tech spec for user story ID: {user_story_id} ({idx+1}/{len(tech_specs)})\")\n",
    "            \n",
    "            # Setup initial message\n",
    "            messages = [HumanMessage(content=tech_spec)]\n",
    "            \n",
    "            # Set up the input state\n",
    "            initial_state = {\n",
    "                \"messages\": messages,\n",
    "                \"current_code\": \"\",\n",
    "                \"validation_status\": None,\n",
    "                \"error_messages\": [],\n",
    "                \"is_valid\": False,\n",
    "                \"user_story_id\": user_story_id\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                # Run the graph\n",
    "                result = code_gen.graph.invoke(initial_state)\n",
    "                \n",
    "                # Log success\n",
    "                logger.info(f\"Successfully processed tech spec for user story ID: {user_story_id}\")\n",
    "                \n",
    "                # Extract final code\n",
    "                if 'current_code' in result and result['current_code']:\n",
    "                    final_status = \"final_corrected\" if not result.get('is_valid', False) else \"final_validated\"\n",
    "                    code_gen.save_code_attempt(result['current_code'], user_story_id, final_status)\n",
    "            \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing tech spec for user story ID {user_story_id}: {e}\")\n",
    "                continue\n",
    "            \n",
    "        logger.info(f\"Completed processing all tech specs. Output directory: {base_output_dir}\")\n",
    "        return base_output_dir\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in process_tech_specs: {e}\")\n",
    "        raise\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    output_dir = process_tech_specs(\"tech.xlsx\")\n",
    "    print(f\"All processing complete. Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fixed Relationship-Enhanced Code Integrator\n",
    "\n",
    "This script generates API documentation with detailed function and class relationships,\n",
    "with proper handling of missing docstrings and other edge cases.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import ast\n",
    "import re\n",
    "import logging\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Tuple, Optional, Set, Any\n",
    "import textwrap\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Ensure Azure OpenAI environment variables are set\n",
    "def check_openai_config():\n",
    "    \"\"\"Check if Azure OpenAI config is set in environment variables.\"\"\"\n",
    "    required_vars = [\n",
    "        \"AZURE_OPENAI_API_KEY\",\n",
    "        \"AZURE_OPENAI_ENDPOINT\",\n",
    "        \"AZURE_OPENAI_API_VERSION\",\n",
    "        \"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"\n",
    "    ]\n",
    "    \n",
    "    missing = [var for var in required_vars if not os.environ.get(var)]\n",
    "    if missing:\n",
    "        # Check if we can find them in the current file\n",
    "        logger.info(\"Looking for OpenAI configuration in current environment...\")\n",
    "        \n",
    "        # Try to use values that might be in the environment from previous execution\n",
    "        if \"AZURE_OPENAI_API_KEY\" not in os.environ and '0bf3daeba1814d03b5d62e1da4077478' not in os.environ.values():\n",
    "            os.environ[\"AZURE_OPENAI_API_KEY\"] = \"0bf3daeba1814d03b5d62e1da4077478\"\n",
    "        \n",
    "        if \"AZURE_OPENAI_ENDPOINT\" not in os.environ and 'https://openaisk123.openai.azure.com/' not in os.environ.values():\n",
    "            os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://openaisk123.openai.azure.com/\"\n",
    "        \n",
    "        if \"AZURE_OPENAI_API_VERSION\" not in os.environ and '2024-08-01-preview' not in os.environ.values():\n",
    "            os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-08-01-preview\"\n",
    "        \n",
    "        if \"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\" not in os.environ and 'gpt-4o' not in os.environ.values():\n",
    "            os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"] = \"gpt-4o\"\n",
    "    \n",
    "    # Verify all variables are set\n",
    "    missing = [var for var in required_vars if not os.environ.get(var)]\n",
    "    if missing:\n",
    "        raise EnvironmentError(f\"Missing Azure OpenAI configuration: {', '.join(missing)}\")\n",
    "    \n",
    "    logger.info(\"Azure OpenAI configuration verified\")\n",
    "\n",
    "def find_latest_code_generation_folder():\n",
    "    \"\"\"Find the latest code_generation folder based on creation time.\"\"\"\n",
    "    base_dir = os.getcwd()  # Current working directory\n",
    "    code_gen_folders = [d for d in os.listdir(base_dir) if d.startswith(\"code_generation_\") and os.path.isdir(os.path.join(base_dir, d))]\n",
    "    if not code_gen_folders:\n",
    "        raise FileNotFoundError(\"No code_generation folders found\")\n",
    "    \n",
    "    # Sort by creation time, most recent first\n",
    "    code_gen_folders.sort(key=lambda d: os.path.getctime(os.path.join(base_dir, d)), reverse=True)\n",
    "    return os.path.join(base_dir, code_gen_folders[0])\n",
    "\n",
    "def find_code_files(base_folder):\n",
    "    \"\"\"\n",
    "    Find all code files in subfolders.\n",
    "    Prioritize files in this order:\n",
    "    1. final_corrected\n",
    "    2. final_validated\n",
    "    3. correction\n",
    "    4. validated_pass\n",
    "    5. initial (fallback)\n",
    "    \"\"\"\n",
    "    code_files = []\n",
    "    \n",
    "    # Priority order for folder names\n",
    "    priority_folders = [\"final_corrected\", \"final_validated\", \"correction\", \"validated_pass\", \"initial\"]\n",
    "    \n",
    "    # First, get all user story folders\n",
    "    user_story_folders = [f for f in os.listdir(base_folder) \n",
    "                         if os.path.isdir(os.path.join(base_folder, f))]\n",
    "    \n",
    "    for user_folder in user_story_folders:\n",
    "        user_path = os.path.join(base_folder, user_folder)\n",
    "        \n",
    "        # Check each priority folder type\n",
    "        found = False\n",
    "        for priority in priority_folders:\n",
    "            attempt_path = os.path.join(user_path, f\"attempt_{priority}\")\n",
    "            code_file = os.path.join(attempt_path, \"code.py\")\n",
    "            \n",
    "            if os.path.exists(code_file):\n",
    "                code_files.append((user_folder, code_file))\n",
    "                found = True\n",
    "                logger.info(f\"Using '{priority}' code for {user_folder}\")\n",
    "                break\n",
    "        \n",
    "        if not found:\n",
    "            logger.warning(f\"No code files found at all for {user_folder}\")\n",
    "    \n",
    "    return code_files\n",
    "\n",
    "def read_code_files(code_files):\n",
    "    \"\"\"Read code files and return a dictionary mapping module names to code content.\"\"\"\n",
    "    code_contents = {}\n",
    "    \n",
    "    for module_name, file_path in code_files:\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                content = f.read()\n",
    "                code_contents[module_name] = content\n",
    "                logger.info(f\"Read {len(content)} bytes from {file_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading {file_path}: {e}\")\n",
    "    \n",
    "    return code_contents\n",
    "\n",
    "def get_docstring_summary(docstring):\n",
    "    \"\"\"Extract the first sentence of a docstring or return a default message.\"\"\"\n",
    "    if not docstring:\n",
    "        return \"No documentation available\"\n",
    "    \n",
    "    # Try to get the first sentence\n",
    "    if '.' in docstring:\n",
    "        return docstring.split('.')[0].strip()\n",
    "    \n",
    "    return docstring.strip()\n",
    "\n",
    "class RelationshipVisitor(ast.NodeVisitor):\n",
    "    \"\"\"AST visitor that extracts relationships between functions, classes, and variables.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.defined_names = set()  # All defined names in the module\n",
    "        self.function_calls = defaultdict(set)  # Mapping of function name to the set of function names it calls\n",
    "        self.class_instantiations = defaultdict(set)  # Mapping of function name to the set of class names it instantiates\n",
    "        self.attribute_accesses = defaultdict(set)  # Mapping of function/method name to the attributes it accesses\n",
    "        self.imports = []  # List of import statements\n",
    "        self.global_vars = []  # List of global variables\n",
    "        self.functions = []  # List of functions\n",
    "        self.classes = []  # List of classes\n",
    "        \n",
    "        # Track current context (function or class being processed)\n",
    "        self.current_function = None\n",
    "        self.current_class = None\n",
    "        self.current_method = None\n",
    "        \n",
    "        # Track known external names\n",
    "        self.external_modules = set()\n",
    "        \n",
    "    def visit_Import(self, node):\n",
    "        \"\"\"Process import statements.\"\"\"\n",
    "        for name in node.names:\n",
    "            import_name = name.name\n",
    "            alias = name.asname or import_name\n",
    "            self.imports.append({\n",
    "                \"module\": import_name,\n",
    "                \"alias\": name.asname\n",
    "            })\n",
    "            self.defined_names.add(alias)\n",
    "            self.external_modules.add(alias)\n",
    "        self.generic_visit(node)\n",
    "    \n",
    "    def visit_ImportFrom(self, node):\n",
    "        \"\"\"Process from ... import ... statements.\"\"\"\n",
    "        module = node.module or \"\"\n",
    "        for name in node.names:\n",
    "            import_name = name.name\n",
    "            alias = name.asname or import_name\n",
    "            self.imports.append({\n",
    "                \"module\": module,\n",
    "                \"name\": import_name,\n",
    "                \"alias\": name.asname\n",
    "            })\n",
    "            self.defined_names.add(alias)\n",
    "        self.generic_visit(node)\n",
    "    \n",
    "    def visit_ClassDef(self, node):\n",
    "        \"\"\"Process class definitions.\"\"\"\n",
    "        class_name = node.name\n",
    "        self.defined_names.add(class_name)\n",
    "        \n",
    "        # Extract base classes\n",
    "        bases = []\n",
    "        for base in node.bases:\n",
    "            if isinstance(base, ast.Name):\n",
    "                bases.append(base.id)\n",
    "            else:\n",
    "                try:\n",
    "                    bases.append(ast.unparse(base))\n",
    "                except:\n",
    "                    bases.append(str(base))\n",
    "        \n",
    "        # Extract docstring\n",
    "        docstring = None\n",
    "        if (node.body and isinstance(node.body[0], ast.Expr) and \n",
    "            isinstance(node.body[0].value, ast.Str)):\n",
    "            docstring = node.body[0].value.s.strip()\n",
    "        \n",
    "        # Save the current class context\n",
    "        prev_class = self.current_class\n",
    "        self.current_class = class_name\n",
    "        \n",
    "        # Process the class body\n",
    "        methods = []\n",
    "        for child in node.body:\n",
    "            if isinstance(child, ast.FunctionDef):\n",
    "                # This is a method\n",
    "                method_info = self.process_function(child, is_method=True)\n",
    "                if method_info:\n",
    "                    methods.append(method_info)\n",
    "        \n",
    "        # Add class info\n",
    "        self.classes.append({\n",
    "            \"name\": class_name,\n",
    "            \"docstring\": docstring or \"No documentation available.\",\n",
    "            \"bases\": bases,\n",
    "            \"methods\": methods,\n",
    "            \"relationships\": {\n",
    "                \"inherits_from\": bases,\n",
    "                \"used_by_functions\": [],  # Will be filled later\n",
    "                \"instantiated_by\": []  # Will be filled later\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        # Restore previous class context\n",
    "        self.current_class = prev_class\n",
    "    \n",
    "    def process_function(self, node, is_method=False):\n",
    "        \"\"\"Process function or method definition.\"\"\"\n",
    "        func_name = node.name\n",
    "        \n",
    "        # Skip if it's a special method (like __init__) - we'll still process its body though\n",
    "        skip_adding = False\n",
    "        if is_method and func_name.startswith('__') and func_name.endswith('__'):\n",
    "            skip_adding = True\n",
    "        \n",
    "        # For methods, the full name includes the class name\n",
    "        full_name = f\"{self.current_class}.{func_name}\" if is_method and self.current_class else func_name\n",
    "        \n",
    "        # Extract docstring\n",
    "        docstring = None\n",
    "        if (node.body and isinstance(node.body[0], ast.Expr) and \n",
    "            isinstance(node.body[0].value, ast.Str)):\n",
    "            docstring = node.body[0].value.s.strip()\n",
    "        \n",
    "        # Extract parameters\n",
    "        parameters = []\n",
    "        for arg in node.args.args:\n",
    "            param_name = arg.arg\n",
    "            param_type = None\n",
    "            if arg.annotation:\n",
    "                try:\n",
    "                    param_type = ast.unparse(arg.annotation)\n",
    "                except:\n",
    "                    param_type = str(arg.annotation)\n",
    "            \n",
    "            parameters.append({\n",
    "                \"name\": param_name,\n",
    "                \"type\": param_type,\n",
    "                \"description\": \"Parameter description not available.\"\n",
    "            })\n",
    "        \n",
    "        # Extract return type\n",
    "        returns = None\n",
    "        if node.returns:\n",
    "            try:\n",
    "                returns = ast.unparse(node.returns)\n",
    "            except:\n",
    "                returns = str(node.returns)\n",
    "        \n",
    "        # Save the current function context\n",
    "        prev_function = self.current_function\n",
    "        prev_method = self.current_method\n",
    "        \n",
    "        if is_method:\n",
    "            self.current_method = full_name\n",
    "        else:\n",
    "            self.current_function = full_name\n",
    "            self.defined_names.add(func_name)\n",
    "        \n",
    "        # Visit the function body to capture calls and relationships\n",
    "        self.generic_visit(node)\n",
    "        \n",
    "        # Create the function info object\n",
    "        func_info = {\n",
    "            \"name\": func_name,\n",
    "            \"docstring\": docstring or \"No documentation available.\",\n",
    "            \"parameters\": parameters,\n",
    "            \"returns\": returns,\n",
    "            \"relationships\": {\n",
    "                \"calls_functions\": list(self.function_calls.get(full_name, set())),\n",
    "                \"instantiates_classes\": list(self.class_instantiations.get(full_name, set())),\n",
    "                \"accesses_attributes\": list(self.attribute_accesses.get(full_name, set())),\n",
    "                \"called_by\": []  # Will be filled later\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Restore previous function context\n",
    "        self.current_function = prev_function\n",
    "        self.current_method = prev_method\n",
    "        \n",
    "        # Add to functions list if not a method or not a special method\n",
    "        if not skip_adding:\n",
    "            if not is_method:\n",
    "                self.functions.append(func_info)\n",
    "            return func_info\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def visit_FunctionDef(self, node):\n",
    "        \"\"\"Process function definitions.\"\"\"\n",
    "        self.process_function(node)\n",
    "    \n",
    "    def visit_Call(self, node):\n",
    "        \"\"\"Process function calls.\"\"\"\n",
    "        # Determine the current context\n",
    "        current_context = self.current_method if self.current_method else self.current_function\n",
    "        \n",
    "        if current_context:\n",
    "            # Function call\n",
    "            if isinstance(node.func, ast.Name):\n",
    "                func_name = node.func.id\n",
    "                self.function_calls[current_context].add(func_name)\n",
    "            \n",
    "            # Method call (obj.method())\n",
    "            elif isinstance(node.func, ast.Attribute) and isinstance(node.func.value, ast.Name):\n",
    "                obj_name = node.func.value.id\n",
    "                method_name = node.func.attr\n",
    "                \n",
    "                # Could be a module.function() call\n",
    "                if obj_name in self.external_modules:\n",
    "                    full_call = f\"{obj_name}.{method_name}\"\n",
    "                else:\n",
    "                    # Could be a class instantiation (ClassName())\n",
    "                    for cls in self.classes:\n",
    "                        if cls[\"name\"] == obj_name:\n",
    "                            self.class_instantiations[current_context].add(obj_name)\n",
    "                            break\n",
    "                    \n",
    "                    full_call = f\"{obj_name}.{method_name}\"\n",
    "                \n",
    "                self.function_calls[current_context].add(full_call)\n",
    "                self.attribute_accesses[current_context].add(f\"{obj_name}.{method_name}\")\n",
    "        \n",
    "        self.generic_visit(node)\n",
    "    \n",
    "    def visit_Assign(self, node):\n",
    "        \"\"\"Process assignments.\"\"\"\n",
    "        # Only process global assignments\n",
    "        if not self.current_function and not self.current_method:\n",
    "            for target in node.targets:\n",
    "                if isinstance(target, ast.Name):\n",
    "                    var_name = target.id\n",
    "                    try:\n",
    "                        var_value = ast.unparse(node.value)\n",
    "                    except:\n",
    "                        var_value = str(node.value)\n",
    "                    \n",
    "                    # Check if it's a class instantiation\n",
    "                    if isinstance(node.value, ast.Call) and isinstance(node.value.func, ast.Name):\n",
    "                        class_name = node.value.func.id\n",
    "                        # Check if it's one of our known classes\n",
    "                        for cls in self.classes:\n",
    "                            if cls[\"name\"] == class_name:\n",
    "                                self.class_instantiations[\"global\"].add(class_name)\n",
    "                                break\n",
    "                    \n",
    "                    self.global_vars.append({\n",
    "                        \"name\": var_name,\n",
    "                        \"value\": var_value\n",
    "                    })\n",
    "                    self.defined_names.add(var_name)\n",
    "        \n",
    "        self.generic_visit(node)\n",
    "    \n",
    "    def post_process(self):\n",
    "        \"\"\"Build reverse relationships after processing.\"\"\"\n",
    "        # For each function call, update the called_by relationship\n",
    "        for caller, callees in self.function_calls.items():\n",
    "            for callee in callees:\n",
    "                # Find the actual function record\n",
    "                for func in self.functions:\n",
    "                    if func[\"name\"] == callee:\n",
    "                        if caller not in func[\"relationships\"][\"called_by\"]:\n",
    "                            func[\"relationships\"][\"called_by\"].append(caller)\n",
    "        \n",
    "        # For each class instantiation, update the instantiated_by relationship\n",
    "        for instantiator, classes in self.class_instantiations.items():\n",
    "            for class_name in classes:\n",
    "                # Find the actual class record\n",
    "                for cls in self.classes:\n",
    "                    if cls[\"name\"] == class_name:\n",
    "                        if instantiator not in cls[\"relationships\"][\"instantiated_by\"]:\n",
    "                            cls[\"relationships\"][\"instantiated_by\"].append(instantiator)\n",
    "        \n",
    "        # For each class, update the used_by_functions relationship\n",
    "        for cls in self.classes:\n",
    "            class_name = cls[\"name\"]\n",
    "            for func in self.functions:\n",
    "                # If function instantiates this class\n",
    "                if class_name in func[\"relationships\"][\"instantiates_classes\"]:\n",
    "                    if func[\"name\"] not in cls[\"relationships\"][\"used_by_functions\"]:\n",
    "                        cls[\"relationships\"][\"used_by_functions\"].append(func[\"name\"])\n",
    "                \n",
    "                # If function accesses any attributes related to this class\n",
    "                for attr in func[\"relationships\"][\"accesses_attributes\"]:\n",
    "                    if attr.startswith(f\"{class_name}.\"):\n",
    "                        if func[\"name\"] not in cls[\"relationships\"][\"used_by_functions\"]:\n",
    "                            cls[\"relationships\"][\"used_by_functions\"].append(func[\"name\"])\n",
    "\n",
    "class EnhancedAPIDocGenerator:\n",
    "    \"\"\"Class to generate enhanced API documentation with relationship information.\"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def generate_module_api_doc(self, module_name, code):\n",
    "        \"\"\"Generate enhanced API documentation for a module.\"\"\"\n",
    "        try:\n",
    "            # Parse the AST\n",
    "            tree = ast.parse(code)\n",
    "            \n",
    "            # Visit the AST to extract entities and relationships\n",
    "            visitor = RelationshipVisitor()\n",
    "            visitor.visit(tree)\n",
    "            visitor.post_process()\n",
    "            \n",
    "            # Extract module docstring\n",
    "            module_docstring = None\n",
    "            if (tree.body and isinstance(tree.body[0], ast.Expr) and \n",
    "                isinstance(tree.body[0].value, ast.Str)):\n",
    "                module_docstring = tree.body[0].value.s.strip()\n",
    "            \n",
    "            # Create module doc\n",
    "            module_doc = {\n",
    "                \"name\": module_name,\n",
    "                \"docstring\": module_docstring or \"No module documentation available.\",\n",
    "                \"imports\": visitor.imports,\n",
    "                \"global_vars\": visitor.global_vars,\n",
    "                \"functions\": visitor.functions,\n",
    "                \"classes\": visitor.classes,\n",
    "                \"relationships\": {\n",
    "                    \"dependencies\": self._analyze_module_dependencies(visitor),\n",
    "                    \"entry_points\": self._identify_entry_points(visitor)\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            return module_doc\n",
    "            \n",
    "        except SyntaxError as e:\n",
    "            logger.error(f\"Syntax error in module {module_name}: {e}\")\n",
    "            return self._fallback_api_doc_generation(module_name, code)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error parsing module {module_name}: {e}\")\n",
    "            return self._fallback_api_doc_generation(module_name, code)\n",
    "    \n",
    "    def _analyze_module_dependencies(self, visitor):\n",
    "        \"\"\"Analyze module level dependencies.\"\"\"\n",
    "        dependencies = {\n",
    "            \"imports\": [imp.get(\"module\") for imp in visitor.imports if \"module\" in imp],\n",
    "            \"from_imports\": [f\"{imp.get('module')}.{imp.get('name')}\" for imp in visitor.imports if \"name\" in imp],\n",
    "        }\n",
    "        return dependencies\n",
    "    \n",
    "    def _identify_entry_points(self, visitor):\n",
    "        \"\"\"Identify potential entry points in the module.\"\"\"\n",
    "        # Entry points are functions that are not called by other functions\n",
    "        entry_points = []\n",
    "        \n",
    "        for func in visitor.functions:\n",
    "            if not func[\"relationships\"][\"called_by\"]:\n",
    "                # This function is not called by others\n",
    "                entry_points.append(func[\"name\"])\n",
    "        \n",
    "        # Also look for if __name__ == \"__main__\" block\n",
    "        # This is a simplification - in a real implementation, we'd need to parse the AST for this\n",
    "        \n",
    "        return entry_points\n",
    "    \n",
    "    def _fallback_api_doc_generation(self, module_name, code):\n",
    "        \"\"\"Use the LLM as a fallback for API doc generation when parsing fails.\"\"\"\n",
    "        logger.info(f\"Using LLM to extract enhanced API documentation for {module_name}\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "Generate a detailed API documentation for the following Python code module.\n",
    "Extract all functions, classes, methods, and their parameters, return types, and docstrings.\n",
    "MOST IMPORTANTLY, also extract the relationships between functions and classes:\n",
    "- What functions call other functions\n",
    "- What functions instantiate classes\n",
    "- What classes inherit from other classes\n",
    "- What functions are entry points (not called by others)\n",
    "\n",
    "Format the response as a JSON object with the structure shown in the example.\n",
    "\n",
    "Example structure:\n",
    "```json\n",
    "{{\n",
    "  \"name\": \"module_name\",\n",
    "  \"docstring\": \"Module docstring\",\n",
    "  \"imports\": [\n",
    "    {{\"module\": \"os\", \"alias\": null}},\n",
    "    {{\"module\": \"pandas\", \"alias\": \"pd\"}}\n",
    "  ],\n",
    "  \"global_vars\": [\n",
    "    {{\"name\": \"logger\", \"value\": \"logging.getLogger(__name__)\"}}\n",
    "  ],\n",
    "  \"functions\": [\n",
    "    {{\n",
    "      \"name\": \"function_name\",\n",
    "      \"docstring\": \"Function docstring\",\n",
    "      \"parameters\": [\n",
    "        {{\"name\": \"param1\", \"type\": \"str\", \"description\": \"Description of param1\"}}\n",
    "      ],\n",
    "      \"returns\": \"str\",\n",
    "      \"relationships\": {{\n",
    "        \"calls_functions\": [\"other_function\", \"third_function\"],\n",
    "        \"instantiates_classes\": [\"SomeClass\"],\n",
    "        \"accesses_attributes\": [\"object.attribute\"],\n",
    "        \"called_by\": [\"main\"]\n",
    "      }}\n",
    "    }}\n",
    "  ],\n",
    "  \"classes\": [\n",
    "    {{\n",
    "      \"name\": \"ClassName\",\n",
    "      \"docstring\": \"Class docstring\",\n",
    "      \"bases\": [\"BaseClass\"],\n",
    "      \"methods\": [\n",
    "        {{\n",
    "          \"name\": \"method_name\",\n",
    "          \"docstring\": \"Method docstring\",\n",
    "          \"parameters\": [\n",
    "            {{\"name\": \"self\", \"type\": null, \"description\": \"Instance reference\"}},\n",
    "            {{\"name\": \"param1\", \"type\": \"str\", \"description\": \"Description of param1\"}}\n",
    "          ],\n",
    "          \"returns\": \"bool\",\n",
    "          \"relationships\": {{\n",
    "            \"calls_functions\": [\"some_function\"],\n",
    "            \"instantiates_classes\": [],\n",
    "            \"accesses_attributes\": [\"self.attribute\"],\n",
    "            \"called_by\": []\n",
    "          }}\n",
    "        }}\n",
    "      ],\n",
    "      \"relationships\": {{\n",
    "        \"inherits_from\": [\"BaseClass\"],\n",
    "        \"used_by_functions\": [\"function_name\"],\n",
    "        \"instantiated_by\": [\"function_name\"]\n",
    "      }}\n",
    "    }}\n",
    "  ],\n",
    "  \"relationships\": {{\n",
    "    \"dependencies\": {{\n",
    "      \"imports\": [\"os\", \"pandas\"],\n",
    "      \"from_imports\": [\"logging.getLogger\"]\n",
    "    }},\n",
    "    \"entry_points\": [\"main\"]\n",
    "  }}\n",
    "}}\n",
    "```\n",
    "\n",
    "Here's the code to document:\n",
    "\n",
    "```python\n",
    "{code}\n",
    "```\n",
    "\n",
    "Focus especially on capturing the relationships between functions and classes to help understand how the code works together.\n",
    "\"\"\"\n",
    "\n",
    "        system_message = SystemMessage(content=\"You are a Python expert who specializes in extracting API documentation and code relationships from code.\")\n",
    "        human_message = HumanMessage(content=prompt)\n",
    "        \n",
    "        try:\n",
    "            response = self.model.invoke([system_message, human_message])\n",
    "            content = response.content\n",
    "            \n",
    "            # Try to extract JSON from the response\n",
    "            json_match = re.search(r'```json\\s*(.*?)\\s*```', content, re.DOTALL)\n",
    "            if json_match:\n",
    "                json_str = json_match.group(1)\n",
    "            else:\n",
    "                # If no JSON code block, try to find any JSON object\n",
    "                json_match = re.search(r'({[\\s\\S]*})', content)\n",
    "                if json_match:\n",
    "                    json_str = json_match.group(1)\n",
    "                else:\n",
    "                    json_str = content\n",
    "            \n",
    "            return json.loads(json_str)\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error getting API doc from LLM for {module_name}: {e}\")\n",
    "            # Return a minimal structure\n",
    "            return {\n",
    "                \"name\": module_name,\n",
    "                \"docstring\": \"Documentation extraction failed.\",\n",
    "                \"imports\": [],\n",
    "                \"global_vars\": [],\n",
    "                \"functions\": [],\n",
    "                \"classes\": [],\n",
    "                \"relationships\": {\n",
    "                    \"dependencies\": {\n",
    "                        \"imports\": [],\n",
    "                        \"from_imports\": []\n",
    "                    },\n",
    "                    \"entry_points\": []\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    def generate_all_module_docs(self, code_contents):\n",
    "        \"\"\"Generate API documentation for all modules.\"\"\"\n",
    "        module_docs = {}\n",
    "        \n",
    "        for module_name, code in code_contents.items():\n",
    "            try:\n",
    "                module_doc = self.generate_module_api_doc(module_name, code)\n",
    "                module_docs[module_name] = module_doc\n",
    "                logger.info(f\"Generated enhanced API documentation for {module_name}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error generating API doc for {module_name}: {e}\")\n",
    "        \n",
    "        return module_docs\n",
    "    \n",
    "    def try_generate_dependency_graph(self, module_docs):\n",
    "        \"\"\"Try to generate a dependency graph visualization for all modules.\"\"\"\n",
    "        try:\n",
    "            # Check if matplotlib and networkx are available\n",
    "            try:\n",
    "                import matplotlib.pyplot as plt\n",
    "                import networkx as nx\n",
    "            except ImportError:\n",
    "                logger.warning(\"matplotlib or networkx not available, skipping graph generation\")\n",
    "                return None\n",
    "            \n",
    "            # Create a directed graph\n",
    "            G = nx.DiGraph()\n",
    "            \n",
    "            # Add nodes for each module\n",
    "            for module_name in module_docs.keys():\n",
    "                G.add_node(module_name, type='module')\n",
    "            \n",
    "            # Add edges for dependencies between modules\n",
    "            for module_name, doc in module_docs.items():\n",
    "                # For each function in this module\n",
    "                for func in doc.get(\"functions\", []):\n",
    "                    # For each function call\n",
    "                    for called_func in func.get(\"relationships\", {}).get(\"calls_functions\", []):\n",
    "                        # If the function contains a dot, it might be a cross-module call\n",
    "                        if \".\" in called_func:\n",
    "                            parts = called_func.split(\".\")\n",
    "                            if len(parts) == 2:\n",
    "                                potential_module = parts[0]\n",
    "                                # Check if this is one of our modules\n",
    "                                if potential_module in module_docs:\n",
    "                                    G.add_edge(module_name, potential_module, \n",
    "                                            label=f\"{func['name']} -> {called_func}\")\n",
    "                                    \n",
    "                # Add edges based on imports if we can determine they're our modules\n",
    "                for imp in doc.get(\"imports\", []):\n",
    "                    module = imp.get(\"module\")\n",
    "                    if module in module_docs:\n",
    "                        G.add_edge(module_name, module, label=\"imports\")\n",
    "            \n",
    "            # Check if we have any edges\n",
    "            if not G.edges():\n",
    "                # Add edges based on function similarities\n",
    "                self._add_similarity_edges(G, module_docs)\n",
    "            \n",
    "            # Create the visualization\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            pos = nx.spring_layout(G)\n",
    "            nx.draw(G, pos, with_labels=True, node_color='lightblue', \n",
    "                    font_weight='bold', node_size=2000, arrows=True)\n",
    "            \n",
    "            # Add edge labels\n",
    "            edge_labels = {(u, v): d.get('label', '') for u, v, d in G.edges(data=True)}\n",
    "            nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "            \n",
    "            return G\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating dependency graph: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _add_similarity_edges(self, G, module_docs):\n",
    "        \"\"\"Add edges based on function and class name similarities.\"\"\"\n",
    "        # Create a dictionary of all function names to their modules\n",
    "        function_to_module = {}\n",
    "        for module_name, doc in module_docs.items():\n",
    "            for func in doc.get(\"functions\", []):\n",
    "                function_to_module[func[\"name\"]] = module_name\n",
    "        \n",
    "        # Look for similar function names across modules\n",
    "        for module_name, doc in module_docs.items():\n",
    "            for func in doc.get(\"functions\", []):\n",
    "                for called_func in func.get(\"relationships\", {}).get(\"calls_functions\", []):\n",
    "                    # If the function appears in another module\n",
    "                    if called_func in function_to_module and function_to_module[called_func] != module_name:\n",
    "                        target_module = function_to_module[called_func]\n",
    "                        G.add_edge(module_name, target_module, \n",
    "                                label=f\"{func['name']} -> {called_func}\")\n",
    "    \n",
    "    def format_api_docs_for_llm(self, module_docs):\n",
    "        \"\"\"Format API documentation for use in LLM prompt, including relationship information.\"\"\"\n",
    "        formatted_docs = []\n",
    "        \n",
    "        for module_name, doc in module_docs.items():\n",
    "            module_text = [f\"MODULE: {module_name}_code.py\"]\n",
    "            \n",
    "            # Add module docstring\n",
    "            module_text.append(f\"Description: {doc['docstring']}\")\n",
    "            module_text.append(\"\")\n",
    "            \n",
    "            # Add imports\n",
    "            if doc[\"imports\"]:\n",
    "                module_text.append(\"Imports:\")\n",
    "                for imp in doc[\"imports\"]:\n",
    "                    if \"name\" in imp:\n",
    "                        from_txt = f\"from {imp['module']} \" if imp['module'] else \"from \"\n",
    "                        as_txt = f\" as {imp['alias']}\" if imp['alias'] else \"\"\n",
    "                        module_text.append(f\"  {from_txt}import {imp['name']}{as_txt}\")\n",
    "                    else:\n",
    "                        as_txt = f\" as {imp['alias']}\" if imp['alias'] else \"\"\n",
    "                        module_text.append(f\"  import {imp['module']}{as_txt}\")\n",
    "                module_text.append(\"\")\n",
    "            \n",
    "            # Add global variables\n",
    "            if doc[\"global_vars\"]:\n",
    "                module_text.append(\"Global Variables:\")\n",
    "                for var in doc[\"global_vars\"]:\n",
    "                    module_text.append(f\"  {var['name']} = {var['value']}\")\n",
    "                module_text.append(\"\")\n",
    "            \n",
    "            # Add classes\n",
    "            if doc[\"classes\"]:\n",
    "                module_text.append(\"Classes:\")\n",
    "                for cls in doc[\"classes\"]:\n",
    "                    bases = f\"({', '.join(cls['bases'])})\" if cls['bases'] else \"\"\n",
    "                    module_text.append(f\"  class {cls['name']}{bases}:\")\n",
    "                    module_text.append(f\"    \\\"{cls['docstring']}\\\"\")\n",
    "                    \n",
    "                    # Add class relationships\n",
    "                    if cls.get(\"relationships\"):\n",
    "                        module_text.append(\"    Relationships:\")\n",
    "                        inherits = cls[\"relationships\"].get(\"inherits_from\", [])\n",
    "                        if inherits:\n",
    "                            module_text.append(f\"      Inherits from: {', '.join(inherits)}\")\n",
    "                        \n",
    "                        used_by = cls[\"relationships\"].get(\"used_by_functions\", [])\n",
    "                        if used_by:\n",
    "                            module_text.append(f\"      Used by functions: {', '.join(used_by)}\")\n",
    "                        \n",
    "                        inst_by = cls[\"relationships\"].get(\"instantiated_by\", [])\n",
    "                        if inst_by:\n",
    "                            module_text.append(f\"      Instantiated by: {', '.join(inst_by)}\")\n",
    "                        \n",
    "                        module_text.append(\"\")\n",
    "                    \n",
    "                    if cls[\"methods\"]:\n",
    "                        module_text.append(\"    Methods:\")\n",
    "                        for method in cls[\"methods\"]:\n",
    "                            params = []\n",
    "                            for p in method[\"parameters\"]:\n",
    "                                param_type = f\": {p['type']}\" if p['type'] else \"\"\n",
    "                                params.append(f\"{p['name']}{param_type}\")\n",
    "                            \n",
    "                            returns = f\" -> {method['returns']}\" if method['returns'] else \"\"\n",
    "                            module_text.append(f\"      def {method['name']}({', '.join(params)}){returns}:\")\n",
    "                            module_text.append(f\"        \\\"{method['docstring']}\\\"\")\n",
    "                            \n",
    "                            # Add method relationships\n",
    "                            if method.get(\"relationships\"):\n",
    "                                module_text.append(\"        Relationships:\")\n",
    "                                calls = method[\"relationships\"].get(\"calls_functions\", [])\n",
    "                                if calls:\n",
    "                                    module_text.append(f\"          Calls functions: {', '.join(calls)}\")\n",
    "                                \n",
    "                                instantiates = method[\"relationships\"].get(\"instantiates_classes\", [])\n",
    "                                if instantiates:\n",
    "                                    module_text.append(f\"          Instantiates classes: {', '.join(instantiates)}\")\n",
    "                                \n",
    "                                accesses = method[\"relationships\"].get(\"accesses_attributes\", [])\n",
    "                                if accesses:\n",
    "                                    module_text.append(f\"          Accesses attributes: {', '.join(accesses)}\")\n",
    "                                \n",
    "                                called_by = method[\"relationships\"].get(\"called_by\", [])\n",
    "                                if called_by:\n",
    "                                    module_text.append(f\"          Called by: {', '.join(called_by)}\")\n",
    "                                \n",
    "                                module_text.append(\"\")\n",
    "                            \n",
    "                            # Add parameter descriptions\n",
    "                            if any(p[\"description\"] != \"Parameter description not available.\" for p in method[\"parameters\"]):\n",
    "                                module_text.append(\"        Parameters:\")\n",
    "                                for p in method[\"parameters\"]:\n",
    "                                    if p[\"description\"] != \"Parameter description not available.\":\n",
    "                                        module_text.append(f\"          {p['name']}: {p['description']}\")\n",
    "                            \n",
    "                            module_text.append(\"\")\n",
    "                    \n",
    "                    module_text.append(\"\")\n",
    "            \n",
    "            # Add functions\n",
    "            if doc[\"functions\"]:\n",
    "                module_text.append(\"Functions:\")\n",
    "                for func in doc[\"functions\"]:\n",
    "                    params = []\n",
    "                    for p in func[\"parameters\"]:\n",
    "                        param_type = f\": {p['type']}\" if p['type'] else \"\"\n",
    "                        params.append(f\"{p['name']}{param_type}\")\n",
    "                    \n",
    "                    returns = f\" -> {func['returns']}\" if func['returns'] else \"\"\n",
    "                    module_text.append(f\"  def {func['name']}({', '.join(params)}){returns}:\")\n",
    "                    module_text.append(f\"    \\\"{func['docstring']}\\\"\")\n",
    "                    \n",
    "                    # Add function relationships\n",
    "                    if func.get(\"relationships\"):\n",
    "                        module_text.append(\"    Relationships:\")\n",
    "                        calls = func[\"relationships\"].get(\"calls_functions\", [])\n",
    "                        if calls:\n",
    "                            module_text.append(f\"      Calls functions: {', '.join(calls)}\")\n",
    "                        \n",
    "                        instantiates = func[\"relationships\"].get(\"instantiates_classes\", [])\n",
    "                        if instantiates:\n",
    "                            module_text.append(f\"      Instantiates classes: {', '.join(instantiates)}\")\n",
    "                        \n",
    "                        accesses = func[\"relationships\"].get(\"accesses_attributes\", [])\n",
    "                        if accesses:\n",
    "                            module_text.append(f\"      Accesses attributes: {', '.join(accesses)}\")\n",
    "                        \n",
    "                        called_by = func[\"relationships\"].get(\"called_by\", [])\n",
    "                        if called_by:\n",
    "                            module_text.append(f\"      Called by: {', '.join(called_by)}\")\n",
    "                        \n",
    "                        module_text.append(\"\")\n",
    "                    \n",
    "                    # Add parameter descriptions\n",
    "                    if any(p[\"description\"] != \"Parameter description not available.\" for p in func[\"parameters\"]):\n",
    "                        module_text.append(\"    Parameters:\")\n",
    "                        for p in func[\"parameters\"]:\n",
    "                            if p[\"description\"] != \"Parameter description not available.\":\n",
    "                                module_text.append(f\"      {p['name']}: {p['description']}\")\n",
    "                    \n",
    "                    module_text.append(\"\")\n",
    "            \n",
    "            # Add module-level relationships\n",
    "            if doc.get(\"relationships\"):\n",
    "                module_text.append(\"Module Relationships:\")\n",
    "                \n",
    "                # Dependencies\n",
    "                deps = doc[\"relationships\"].get(\"dependencies\", {})\n",
    "                imports = deps.get(\"imports\", [])\n",
    "                if imports:\n",
    "                    module_text.append(f\"  Imports modules: {', '.join(imports)}\")\n",
    "                \n",
    "                from_imports = deps.get(\"from_imports\", [])\n",
    "                if from_imports:\n",
    "                    module_text.append(f\"  Imports from: {', '.join(from_imports)}\")\n",
    "                \n",
    "                # Entry points\n",
    "                entry_points = doc[\"relationships\"].get(\"entry_points\", [])\n",
    "                if entry_points:\n",
    "                    module_text.append(f\"  Entry points: {', '.join(entry_points)}\")\n",
    "                \n",
    "                module_text.append(\"\")\n",
    "            \n",
    "            formatted_docs.append(\"\\n\".join(module_text))\n",
    "        \n",
    "        return \"\\n\\n\" + \"\\n\\n\".join(formatted_docs) + \"\\n\"\n",
    "\n",
    "class EnhancedCodeIntegrator:\n",
    "    \"\"\"Class to integrate code modules based on enhanced API documentation with relationships.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, doc_generator):\n",
    "        self.model = model\n",
    "        self.doc_generator = doc_generator\n",
    "    \n",
    "    def create_integration_prompt(self, api_docs):\n",
    "        \"\"\"Create a prompt for the LLM to integrate the code with relationship awareness.\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "I have multiple Python modules that need to be integrated into a cohesive solution.\n",
    "Below is the ENHANCED API documentation for each module, which includes detailed relationship information\n",
    "showing which functions call other functions, which classes are instantiated, and other dependencies.\n",
    "Each module is stored in a separate file with the naming pattern of \"US_XXX_code.py\" where XXX is the user story ID.\n",
    "\n",
    "{api_docs}\n",
    "\n",
    "Your task is to:\n",
    "\n",
    "1. Create a single integrated Python file that coordinates functionality from all these modules\n",
    "2. Design the integrated solution to import modules correctly using their filenames (e.g., \"import US_142_code\" NOT \"import US_142\")\n",
    "3. Create proper references to functions and classes from each module with correct module prefixes\n",
    "4. Make sure to import all necessary standard and third-party libraries needed by the solution\n",
    "5. Ensure proper sequencing based on the function call relationships documented above\n",
    "6. Include a main execution block that coordinates the overall flow\n",
    "7. Write clear comments to explain how the integration works, especially noting important function relationships\n",
    "8. Add detailed documentation explaining which functions call which other functions and their dependencies\n",
    "\n",
    "IMPORTANT: Each module should be imported using its full filename (e.g., \"import US_142_code\" not \"import US_142\").\n",
    "When referring to functions, classes, or variables from these modules, use the proper module prefix\n",
    "(e.g., \"US_142_code.process_file()\" not \"US_142.process_file()\").\n",
    "\n",
    "Your integrated solution should include:\n",
    "1. A detailed module docstring explaining the overall architecture and how the modules interact\n",
    "2. Comments for each section explaining which components depend on each other\n",
    "3. A function relationship map in comments to help developers understand the code flow\n",
    "4. A main execution function that coordinates the execution flow based on the identified relationships\n",
    "\n",
    "Format your response as a single Python file with all necessary imports, functions, \n",
    "and a main execution block. Add helpful comments to explain your integration strategy.\n",
    "\n",
    "Return only the final integrated Python code without explanation or other text.\n",
    "\"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def validate_integrated_code(self, code, module_names):\n",
    "        \"\"\"Validate that the integrated code properly imports all modules with correct names.\"\"\"\n",
    "        # Check if modules are imported with _code suffix\n",
    "        proper_imports = True\n",
    "        module_import_checks = []\n",
    "        \n",
    "        for module_name in module_names:\n",
    "            module_import_name = f\"{module_name}_code\"\n",
    "            if f\"import {module_name}\" in code and f\"import {module_import_name}\" not in code:\n",
    "                proper_imports = False\n",
    "                module_import_checks.append((module_name, False))\n",
    "            else:\n",
    "                module_import_checks.append((module_name, True))\n",
    "        \n",
    "        # Check for any functions or classes referenced without proper module prefix\n",
    "        improper_references = []\n",
    "        \n",
    "        for module_name in module_names:\n",
    "            # Look for patterns like \"ModuleName.function\" instead of \"ModuleName_code.function\"\n",
    "            pattern = fr\"{module_name}\\.[a-zA-Z0-9_]+\"\n",
    "            matches = re.findall(pattern, code)\n",
    "            if matches:\n",
    "                improper_references.extend(matches)\n",
    "        \n",
    "        return {\n",
    "            \"proper_imports\": proper_imports,\n",
    "            \"module_import_checks\": module_import_checks,\n",
    "            \"improper_references\": improper_references\n",
    "        }\n",
    "    \n",
    "    def fix_integrated_code(self, code, validation_result):\n",
    "        \"\"\"Fix issues with the integrated code based on validation results.\"\"\"\n",
    "        fixed_code = code\n",
    "        \n",
    "        # Fix improper imports\n",
    "        for module_name, is_proper in validation_result[\"module_import_checks\"]:\n",
    "            if not is_proper:\n",
    "                # Replace \"import ModuleName\" with \"import ModuleName_code\"\n",
    "                fixed_code = re.sub(\n",
    "                    fr\"import\\s+{module_name}(?!_code)\",\n",
    "                    f\"import {module_name}_code\",\n",
    "                    fixed_code\n",
    "                )\n",
    "                \n",
    "                # Replace \"from ModuleName import\" with \"from ModuleName_code import\"\n",
    "                fixed_code = re.sub(\n",
    "                    fr\"from\\s+{module_name}(?!_code)\\s+import\",\n",
    "                    f\"from {module_name}_code import\",\n",
    "                    fixed_code\n",
    "                )\n",
    "        \n",
    "        # Fix improper references\n",
    "        for ref in validation_result[\"improper_references\"]:\n",
    "            module_name = ref.split('.')[0]\n",
    "            fixed_code = fixed_code.replace(ref, ref.replace(f\"{module_name}.\", f\"{module_name}_code.\"))\n",
    "        \n",
    "        return fixed_code\n",
    "    \n",
    "    def generate_integrated_code(self, module_docs):\n",
    "        \"\"\"Generate integrated code based on enhanced API documentation with relationships.\"\"\"\n",
    "        # Format API docs for the LLM\n",
    "        api_docs_text = self.doc_generator.format_api_docs_for_llm(module_docs)\n",
    "        \n",
    "        # Create the prompt\n",
    "        prompt = self.create_integration_prompt(api_docs_text)\n",
    "        \n",
    "        # Send to LLM\n",
    "        system_message = SystemMessage(content=\"\"\"You are a Python expert who specializes in integrating multiple code modules \n",
    "into cohesive solutions. You excel at understanding module dependencies and creating orchestration code.\"\"\")\n",
    "        human_message = HumanMessage(content=prompt)\n",
    "        \n",
    "        logger.info(\"Sending enhanced API documentation to LLM for integration\")\n",
    "        response = self.model.invoke([system_message, human_message])\n",
    "        \n",
    "        # Extract code from response\n",
    "        content = response.content\n",
    "        \n",
    "        # Check if the response is wrapped in code blocks\n",
    "        if \"```python\" in content and \"```\" in content.split(\"```python\", 1)[1]:\n",
    "            # Extract code between the markers\n",
    "            code = content.split(\"```python\", 1)[1].split(\"```\", 1)[0].strip()\n",
    "        elif \"```\" in content and content.count(\"```\") >= 2:\n",
    "            # Extract code between the markers\n",
    "            parts = content.split(\"```\", 2)\n",
    "            code = parts[1]\n",
    "            if code.startswith(\"python\"):\n",
    "                code = code[6:]\n",
    "            code = code.strip()\n",
    "        else:\n",
    "            # If not wrapped in code blocks, return as is\n",
    "            code = content\n",
    "        \n",
    "        # Validate and fix the code\n",
    "        validation_result = self.validate_integrated_code(code, module_docs.keys())\n",
    "        \n",
    "        if not validation_result[\"proper_imports\"] or validation_result[\"improper_references\"]:\n",
    "            logger.info(\"Fixing issues in the integrated code\")\n",
    "            code = self.fix_integrated_code(code, validation_result)\n",
    "        \n",
    "        return code\n",
    "    \n",
    "    def generate_init_file(self, output_dir, module_docs):\n",
    "        \"\"\"Generate an __init__.py file to make importing modules easier.\"\"\"\n",
    "        init_content = ['\"\"\"Package initialization file with module relationships documented.\"\"\"\\n']\n",
    "        \n",
    "        # Add imports for all modules\n",
    "        for module_name in module_docs.keys():\n",
    "            # Import the module\n",
    "            init_content.append(f\"import {module_name}_code\")\n",
    "            \n",
    "            # Create shorter aliases for convenience\n",
    "            init_content.append(f\"{module_name} = {module_name}_code\")\n",
    "        \n",
    "        # Add module relationship documentation\n",
    "        init_content.append(\"\\n# Module relationships:\")\n",
    "        for module_name, doc in module_docs.items():\n",
    "            # Document entry points\n",
    "            entry_points = doc.get(\"relationships\", {}).get(\"entry_points\", [])\n",
    "            if entry_points:\n",
    "                init_content.append(f\"# {module_name}_code entry points: {', '.join(entry_points)}\")\n",
    "            \n",
    "            # Document function calls between modules\n",
    "            calls_found = False\n",
    "            for func in doc.get(\"functions\", []):\n",
    "                for called_func in func.get(\"relationships\", {}).get(\"calls_functions\", []):\n",
    "                    if \".\" in called_func:\n",
    "                        parts = called_func.split(\".\")\n",
    "                        if len(parts) == 2 and parts[0] in module_docs:\n",
    "                            if not calls_found:\n",
    "                                init_content.append(f\"# {module_name}_code function dependencies:\")\n",
    "                                calls_found = True\n",
    "                            init_content.append(f\"#   {func['name']} -> {called_func}\")\n",
    "            \n",
    "            if not calls_found:\n",
    "                init_content.append(f\"# {module_name}_code: No external function calls identified\")\n",
    "        \n",
    "        # Write the file\n",
    "        init_path = os.path.join(output_dir, \"__init__.py\")\n",
    "        with open(init_path, 'w') as f:\n",
    "            f.write(\"\\n\".join(init_content))\n",
    "        \n",
    "        logger.info(f\"Created enhanced __init__.py file at {init_path}\")\n",
    "\n",
    "def save_modules_with_proper_names(output_dir, code_contents):\n",
    "    \"\"\"Save individual modules with proper names based on user story IDs.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for module_name, code in code_contents.items():\n",
    "        file_name = f\"{module_name}_code.py\"\n",
    "        file_path = os.path.join(output_dir, file_name)\n",
    "        \n",
    "        with open(file_path, 'w') as f:\n",
    "            f.write(code)\n",
    "        \n",
    "        logger.info(f\"Saved module {module_name} to {file_path}\")\n",
    "\n",
    "def create_relationship_documentation(output_dir, module_docs):\n",
    "    \"\"\"Create a RELATIONSHIPS.md file documenting the relationships between all components.\"\"\"\n",
    "    content = [\n",
    "        \"# Module Relationship Documentation\",\n",
    "        \"\",\n",
    "        \"This document provides detailed information about the relationships between modules, functions, and classes.\",\n",
    "        \"\",\n",
    "        \"## Overview\",\n",
    "        \"\"\n",
    "    ]\n",
    "    \n",
    "    # Create a list of all modules\n",
    "    content.append(\"### Modules\")\n",
    "    for module_name in module_docs.keys():\n",
    "        content.append(f\"- {module_name}_code.py\")\n",
    "    content.append(\"\")\n",
    "    \n",
    "    # Document module-level relationships\n",
    "    content.append(\"## Module Dependencies\")\n",
    "    content.append(\"\")\n",
    "    \n",
    "    for module_name, doc in module_docs.items():\n",
    "        content.append(f\"### {module_name}_code.py\")\n",
    "        content.append(f\"*{doc['docstring']}*\")\n",
    "        content.append(\"\")\n",
    "        \n",
    "        # Dependencies\n",
    "        deps = doc.get(\"relationships\", {}).get(\"dependencies\", {})\n",
    "        imports = deps.get(\"imports\", [])\n",
    "        if imports:\n",
    "            content.append(\"**Imports modules:**\")\n",
    "            for imp in imports:\n",
    "                content.append(f\"- {imp}\")\n",
    "            content.append(\"\")\n",
    "        \n",
    "        # Entry points\n",
    "        entry_points = doc.get(\"relationships\", {}).get(\"entry_points\", [])\n",
    "        if entry_points:\n",
    "            content.append(\"**Entry points:**\")\n",
    "            for ep in entry_points:\n",
    "                content.append(f\"- {ep}\")\n",
    "            content.append(\"\")\n",
    "        \n",
    "        # Functions\n",
    "        if doc.get(\"functions\"):\n",
    "            content.append(\"**Functions:**\")\n",
    "            for func in doc[\"functions\"]:\n",
    "                # Add function with its relationships\n",
    "                # Safely extract the docstring summary\n",
    "                docstring_summary = get_docstring_summary(func.get('docstring'))\n",
    "                content.append(f\"- `{func['name']}`: {docstring_summary}\")\n",
    "                \n",
    "                # Function calls\n",
    "                calls = func.get(\"relationships\", {}).get(\"calls_functions\", [])\n",
    "                if calls:\n",
    "                    content.append(f\"  - Calls: {', '.join([f'`{c}`' for c in calls])}\")\n",
    "                \n",
    "                # Function instantiations\n",
    "                instantiates = func.get(\"relationships\", {}).get(\"instantiates_classes\", [])\n",
    "                if instantiates:\n",
    "                    content.append(f\"  - Instantiates: {', '.join([f'`{c}`' for c in instantiates])}\")\n",
    "                \n",
    "                # Called by\n",
    "                called_by = func.get(\"relationships\", {}).get(\"called_by\", [])\n",
    "                if called_by:\n",
    "                    content.append(f\"  - Called by: {', '.join([f'`{c}`' for c in called_by])}\")\n",
    "            \n",
    "            content.append(\"\")\n",
    "        \n",
    "        # Classes\n",
    "        if doc.get(\"classes\"):\n",
    "            content.append(\"**Classes:**\")\n",
    "            for cls in doc[\"classes\"]:\n",
    "                # Add class with its relationships\n",
    "                docstring_summary = get_docstring_summary(cls.get('docstring'))\n",
    "                content.append(f\"- `{cls['name']}`: {docstring_summary}\")\n",
    "                \n",
    "                # Inheritance\n",
    "                inherits = cls.get(\"relationships\", {}).get(\"inherits_from\", [])\n",
    "                if inherits:\n",
    "                    content.append(f\"  - Inherits from: {', '.join([f'`{c}`' for c in inherits])}\")\n",
    "                \n",
    "                # Used by\n",
    "                used_by = cls.get(\"relationships\", {}).get(\"used_by_functions\", [])\n",
    "                if used_by:\n",
    "                    content.append(f\"  - Used by: {', '.join([f'`{c}`' for c in used_by])}\")\n",
    "                \n",
    "                # Instantiated by\n",
    "                inst_by = cls.get(\"relationships\", {}).get(\"instantiated_by\", [])\n",
    "                if inst_by:\n",
    "                    content.append(f\"  - Instantiated by: {', '.join([f'`{c}`' for c in inst_by])}\")\n",
    "            \n",
    "            content.append(\"\")\n",
    "    \n",
    "    # Create function call graph section\n",
    "    content.append(\"## Function Call Graph\")\n",
    "    content.append(\"\")\n",
    "    content.append(\"This section shows which functions call other functions across all modules.\")\n",
    "    content.append(\"\")\n",
    "    \n",
    "    # Build the function call graph\n",
    "    call_graph = defaultdict(list)\n",
    "    \n",
    "    for module_name, doc in module_docs.items():\n",
    "        for func in doc.get(\"functions\", []):\n",
    "            func_full_name = f\"{module_name}_code.{func['name']}\"\n",
    "            for called_func in func.get(\"relationships\", {}).get(\"calls_functions\", []):\n",
    "                if \".\" in called_func:\n",
    "                    call_graph[func_full_name].append(called_func)\n",
    "                else:\n",
    "                    # It's in the same module\n",
    "                    call_graph[func_full_name].append(f\"{module_name}_code.{called_func}\")\n",
    "    \n",
    "    # Print call graph\n",
    "    for caller, callees in sorted(call_graph.items()):\n",
    "        if callees:\n",
    "            content.append(f\"- `{caller}` calls:\")\n",
    "            for callee in sorted(callees):\n",
    "                content.append(f\"  - `{callee}`\")\n",
    "            content.append(\"\")\n",
    "    \n",
    "    # Write to file\n",
    "    rel_path = os.path.join(output_dir, \"RELATIONSHIPS.md\")\n",
    "    with open(rel_path, 'w') as f:\n",
    "        f.write(\"\\n\".join(content))\n",
    "    \n",
    "    logger.info(f\"Created detailed relationship documentation at {rel_path}\")\n",
    "\n",
    "def create_setup_py(output_dir, module_name=\"integrated_solution\"):\n",
    "    \"\"\"Create a setup.py file to make the package installable.\"\"\"\n",
    "    setup_content = f'''\"\"\"\n",
    "Setup script for {module_name} package.\n",
    "This package combines multiple modules with their relationships preserved.\n",
    "\"\"\"\n",
    "\n",
    "from setuptools import setup, find_packages\n",
    "\n",
    "setup(\n",
    "    name=\"{module_name}\",\n",
    "    version=\"0.1.0\",\n",
    "    packages=find_packages(),\n",
    "    author=\"AI Code Generator\",\n",
    "    author_email=\"ai@example.com\",\n",
    "    description=\"Integrated solution generated from multiple modules with relationship awareness\",\n",
    "    classifiers=[\n",
    "        \"Programming Language :: Python :: 3\",\n",
    "        \"License :: OSI Approved :: MIT License\",\n",
    "        \"Operating System :: OS Independent\",\n",
    "    ],\n",
    "    python_requires=\">=3.6\",\n",
    ")\n",
    "'''\n",
    "    \n",
    "    setup_path = os.path.join(output_dir, \"setup.py\")\n",
    "    with open(setup_path, 'w') as f:\n",
    "        f.write(setup_content)\n",
    "    \n",
    "    logger.info(f\"Created setup.py file at {setup_path}\")\n",
    "\n",
    "def create_readme(output_dir, module_docs):\n",
    "    \"\"\"Create a README.md file with information about the integrated solution.\"\"\"\n",
    "    readme_content = [\n",
    "        \"# Relationship-Enhanced Integrated Solution\",\n",
    "        \"\",\n",
    "        \"This is an automatically generated integrated solution that combines functionality from multiple modules,\",\n",
    "        \"with enhanced documentation of relationships between functions and classes.\",\n",
    "        \"\",\n",
    "        \"## Architecture Overview\",\n",
    "        \"\",\n",
    "        \"The solution consists of the following modules, each with distinct responsibilities:\",\n",
    "        \"\"\n",
    "    ]\n",
    "    \n",
    "    # Add module descriptions\n",
    "    for module_name, doc in module_docs.items():\n",
    "        readme_content.append(f\"### {module_name}_code\")\n",
    "        readme_content.append(f\"{doc['docstring']}\")\n",
    "        \n",
    "        # Add entry points\n",
    "        entry_points = doc.get(\"relationships\", {}).get(\"entry_points\", [])\n",
    "        if entry_points:\n",
    "            readme_content.append(\"\\nEntry Points:\")\n",
    "            for ep in entry_points:\n",
    "                readme_content.append(f\"- `{ep}`\")\n",
    "        \n",
    "        # Add functions with their relationships\n",
    "        if doc[\"functions\"]:\n",
    "            readme_content.append(\"\\nKey Functions:\")\n",
    "            for func in doc[\"functions\"]:\n",
    "                # Only include functions that have relationships or are entry points\n",
    "                has_relationships = (\n",
    "                    func.get(\"relationships\", {}).get(\"calls_functions\") or \n",
    "                    func.get(\"relationships\", {}).get(\"instantiates_classes\") or\n",
    "                    func.get(\"relationships\", {}).get(\"called_by\")\n",
    "                )\n",
    "                \n",
    "                is_entry_point = func[\"name\"] in entry_points\n",
    "                \n",
    "                if has_relationships or is_entry_point:\n",
    "                    # Safely get docstring summary\n",
    "                    docstring_summary = get_docstring_summary(func.get('docstring'))\n",
    "                    readme_content.append(f\"- `{func['name']}`: {docstring_summary}\")\n",
    "                    \n",
    "                    # Add relationship info\n",
    "                    if has_relationships:\n",
    "                        rel = func.get(\"relationships\", {})\n",
    "                        calls = rel.get(\"calls_functions\", [])\n",
    "                        if calls:\n",
    "                            readme_content.append(f\"  - Calls: {', '.join(calls)}\")\n",
    "                        \n",
    "                        called_by = rel.get(\"called_by\", [])\n",
    "                        if called_by:\n",
    "                            readme_content.append(f\"  - Called by: {', '.join(called_by)}\")\n",
    "                        \n",
    "                        instantiates = rel.get(\"instantiates_classes\", [])\n",
    "                        if instantiates:\n",
    "                            readme_content.append(f\"  - Instantiates: {', '.join(instantiates)}\")\n",
    "        \n",
    "        readme_content.append(\"\")\n",
    "    \n",
    "    # Add integration information\n",
    "    readme_content.extend([\n",
    "        \"## Integration Strategy\",\n",
    "        \"\",\n",
    "        \"The integration follows these principles:\",\n",
    "        \"\",\n",
    "        \"1. **Dependency-Based Execution**: Functions are called in an order that respects their dependencies\",\n",
    "        \"2. **Module Isolation**: Each module maintains its own namespace to prevent conflicts\",\n",
    "        \"3. **Coordinated Execution**: The main execution orchestrates the flow across modules\",\n",
    "        \"\",\n",
    "        \"## Documentation\",\n",
    "        \"\",\n",
    "        \"For more detailed information about the relationships between components, see:\",\n",
    "        \"\",\n",
    "        \"- `RELATIONSHIPS.md`: Detailed documentation of all module and function relationships\",\n",
    "        \"- `integrated_solution.py`: The main integration file with relationship comments\",\n",
    "        \"- `__init__.py`: Contains module relationship information\"\n",
    "    ])\n",
    "    \n",
    "    readme_path = os.path.join(output_dir, \"README.md\")\n",
    "    with open(readme_path, 'w') as f:\n",
    "        f.write(\"\\n\".join(readme_content))\n",
    "    \n",
    "    logger.info(f\"Created enhanced README.md file at {readme_path}\")\n",
    "\n",
    "def fixed_relationship_enhanced_code_integrator():\n",
    "    \"\"\"\n",
    "    Agent that generates enhanced API documentation with relationship details for code modules and uses that\n",
    "    to create an integrated solution with proper module imports.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check Azure OpenAI configuration\n",
    "        check_openai_config()\n",
    "        \n",
    "        # Initialize the model\n",
    "        model = AzureChatOpenAI(\n",
    "            azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "            api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "            api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "            deployment_name=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"],\n",
    "            temperature=0.1  # Low temperature for more deterministic output\n",
    "        )\n",
    "        \n",
    "        # Find the latest code_generation folder\n",
    "        latest_folder = find_latest_code_generation_folder()\n",
    "        logger.info(f\"Found latest code generation folder: {latest_folder}\")\n",
    "        \n",
    "        # Create output directory\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        output_dir = os.path.join(os.path.dirname(latest_folder), f\"relationship_enhanced_solution_{timestamp}\")\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Find all code files\n",
    "        code_files = find_code_files(latest_folder)\n",
    "        logger.info(f\"Found {len(code_files)} code files to integrate\")\n",
    "        \n",
    "        if not code_files:\n",
    "            logger.error(\"No code files found to integrate\")\n",
    "            return\n",
    "        \n",
    "        # Read all code files\n",
    "        code_contents = read_code_files(code_files)\n",
    "        \n",
    "        # Save modules with proper names\n",
    "        save_modules_with_proper_names(output_dir, code_contents)\n",
    "        \n",
    "        # Generate enhanced API documentation with relationships\n",
    "        doc_generator = EnhancedAPIDocGenerator(model)\n",
    "        module_docs = doc_generator.generate_all_module_docs(code_contents)\n",
    "        \n",
    "        # Save enhanced API documentation\n",
    "        api_docs_path = os.path.join(output_dir, \"enhanced_api_documentation.json\")\n",
    "        with open(api_docs_path, 'w') as f:\n",
    "            json.dump(module_docs, f, indent=2)\n",
    "        logger.info(f\"Saved enhanced API documentation to {api_docs_path}\")\n",
    "        \n",
    "        # Create detailed relationship documentation\n",
    "        create_relationship_documentation(output_dir, module_docs)\n",
    "        \n",
    "        # Try to generate dependency graph\n",
    "        try:\n",
    "            # Try to import required libraries\n",
    "            try:\n",
    "                import matplotlib.pyplot as plt\n",
    "                import networkx as nx\n",
    "                \n",
    "                # Try to generate the graph\n",
    "                dependency_graph = doc_generator.try_generate_dependency_graph(module_docs)\n",
    "                if dependency_graph:\n",
    "                    graph_path = os.path.join(output_dir, \"module_dependencies.png\")\n",
    "                    plt.savefig(graph_path)\n",
    "                    logger.info(f\"Saved dependency graph visualization to {graph_path}\")\n",
    "            except ImportError:\n",
    "                logger.warning(\"matplotlib or networkx not available, skipping graph generation\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not generate dependency graph: {e}\")\n",
    "        \n",
    "        # Generate integrated code\n",
    "        integrator = EnhancedCodeIntegrator(model, doc_generator)\n",
    "        integrated_code = integrator.generate_integrated_code(module_docs)\n",
    "        \n",
    "        # Add header\n",
    "        header = f'''\"\"\"\n",
    "Relationship-Enhanced Integrated Solution\n",
    "This file was automatically generated by the Relationship-Enhanced Code Integrator.\n",
    "Generated on: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "\n",
    "This code serves as an integration layer that coordinates all the individual modules.\n",
    "Each module's code is stored in separate files named by their user story IDs with \"_code.py\" suffix.\n",
    "The integration is based on detailed analysis of function and class relationships between modules.\n",
    "\"\"\"\n",
    "\n",
    "'''\n",
    "        integrated_code = header + integrated_code\n",
    "        \n",
    "        # Save integrated code\n",
    "        integrated_code_path = os.path.join(output_dir, \"integrated_solution.py\")\n",
    "        with open(integrated_code_path, 'w') as f:\n",
    "            f.write(integrated_code)\n",
    "        \n",
    "        # Create enhanced __init__.py file\n",
    "        integrator.generate_init_file(output_dir, module_docs)\n",
    "        \n",
    "        # Create enhanced README.md\n",
    "        create_readme(output_dir, module_docs)\n",
    "        \n",
    "        # Create setup.py\n",
    "        create_setup_py(output_dir)\n",
    "        \n",
    "        logger.info(f\"Successfully created relationship-enhanced integrated solution: {integrated_code_path}\")\n",
    "        print(f\"Relationship-enhanced integrated solution created at: {output_dir}\")\n",
    "        \n",
    "        return output_dir\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in relationship-enhanced code integrator: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fixed_relationship_enhanced_code_integrator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Integrated Code Generation and Integration System\n",
    "\n",
    "This script combines two functionalities:\n",
    "1. Code Generation: Generates Python code based on technical specifications in an Excel file\n",
    "2. Code Integration: Integrates the generated code modules into a cohesive solution with relationship awareness\n",
    "\"\"\"\n",
    "\n",
    "# Combine all imports from both scripts\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from typing import TypedDict, Annotated, List, Dict, Tuple, Optional, Set, Any\n",
    "import operator\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage\n",
    "from IPython.display import Image, display\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import ast\n",
    "import textwrap\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Check and setup Azure OpenAI configuration\n",
    "def check_openai_config():\n",
    "    \"\"\"Check if Azure OpenAI config is set in environment variables.\"\"\"\n",
    "    required_vars = [\n",
    "        \"AZURE_OPENAI_API_KEY\",\n",
    "        \"AZURE_OPENAI_ENDPOINT\",\n",
    "        \"AZURE_OPENAI_API_VERSION\",\n",
    "        \"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"\n",
    "    ]\n",
    "    \n",
    "    missing = [var for var in required_vars if not os.environ.get(var)]\n",
    "    if missing:\n",
    "        # Check if we can find them in the current file\n",
    "        logger.info(\"Looking for OpenAI configuration in current environment...\")\n",
    "        \n",
    "        # Try to use default values\n",
    "        if \"AZURE_OPENAI_API_KEY\" not in os.environ:\n",
    "            os.environ[\"AZURE_OPENAI_API_KEY\"] = \"0bf3daeba1814d03b5d62e1da4077478\"\n",
    "        \n",
    "        if \"AZURE_OPENAI_ENDPOINT\" not in os.environ:\n",
    "            os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://openaisk123.openai.azure.com/\"\n",
    "        \n",
    "        if \"AZURE_OPENAI_API_VERSION\" not in os.environ:\n",
    "            os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-08-01-preview\"\n",
    "        \n",
    "        if \"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\" not in os.environ:\n",
    "            os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"] = \"gpt-4o\"\n",
    "    \n",
    "    # Verify all variables are set\n",
    "    missing = [var for var in required_vars if not os.environ.get(var)]\n",
    "    if missing:\n",
    "        raise EnvironmentError(f\"Missing Azure OpenAI configuration: {', '.join(missing)}\")\n",
    "    \n",
    "    logger.info(\"Azure OpenAI configuration verified\")\n",
    "\n",
    "# Initialize Azure OpenAI configuration\n",
    "check_openai_config()\n",
    "\n",
    "# Define prompts for code generation\n",
    "developer_prompt = \"\"\"\n",
    "Role: Python Developer\n",
    "Task: Generate complete, production-ready Python code based on the requirements specification.\n",
    "\n",
    "Requirements:\n",
    "{requirements}\n",
    "\n",
    "Your code must include:\n",
    "1. All necessary imports and dependencies\n",
    "2. Complete implementation with:\n",
    "   - Well-structured classes and functions\n",
    "   - Configuration management (using dataclasses or similar)\n",
    "   - Comprehensive error handling and validation\n",
    "   - Type hints throughout\n",
    "   - Logging with appropriate levels\n",
    "   - Unit tests where applicable\n",
    "3. Clear documentation:\n",
    "   - Module docstrings\n",
    "   - Function/method docstrings with parameters and return values\n",
    "   - Inline comments for complex logic\n",
    "\n",
    "Focus on implementing EVERY aspect mentioned in the requirements. Do not leave any required functionality unimplemented.\n",
    "\n",
    "## Output Format\n",
    "Your response should be the complete, production-ready Python code without surrounding explanations.\n",
    "DO NOT enclose your code in triple backticks (``` or ''').\n",
    "Simply output the pure Python code directly:\n",
    "\n",
    "# Your Python code here\n",
    "\"\"\"\n",
    "\n",
    "validator_prompt = \"\"\"\n",
    "Role: Senior Code Reviewer\n",
    "Task: Perform a thorough validation of the provided Python code against the requirements.\n",
    "\n",
    "Requirements:\n",
    "{Requirements}\n",
    "\n",
    "Validation Process:\n",
    "1. Carefully compare the code against EACH requirement in the specification\n",
    "2. For each requirement, determine if it has been fully, partially, or not implemented\n",
    "3. Identify any missing functionality, edge cases, or requirements\n",
    "4. Evaluate code quality, error handling, security, and performance\n",
    "\n",
    "Validation Checklist:\n",
    "1. Code Completeness:\n",
    "   - All imports and dependencies present\n",
    "   - Full implementation of required functionality (check EACH requirement)\n",
    "   - No placeholder code or TODOs\n",
    "\n",
    "2. Code Quality:\n",
    "   - Follows PEP 8 standards\n",
    "   - Clear variable/function naming\n",
    "   - Appropriate modularization\n",
    "   - Avoids code duplication\n",
    "   - Maintainable architecture\n",
    "\n",
    "3. Technical Implementation:\n",
    "   - Proper error handling with specific exceptions\n",
    "   - Complete type annotations\n",
    "   - Correct algorithm implementation\n",
    "   - Efficient resource usage\n",
    "   - Security considerations addressed\n",
    "\n",
    "4. Documentation:\n",
    "   - Comprehensive docstrings\n",
    "   - Clear inline comments where needed\n",
    "\n",
    "## Output Format\n",
    "Return your validation report as a structured JSON object with the following format:\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"validation_report\": {{\n",
    "    \"overall_assessment\": \"Pass/Fail\",\n",
    "    \"issues_found\": [\n",
    "      \"Issue 1 description\",\n",
    "      \"Issue 2 description\",\n",
    "      \"...\"\n",
    "    ],\n",
    "    \"suggested_improvements\": [\n",
    "      {{\n",
    "        \"description\": \"Improvement 1\",\n",
    "        \"priority\": \"high/medium/low\"\n",
    "      }},\n",
    "      \"...\"\n",
    "    ],\n",
    "    \"implementation_vs_requirements\": {{\n",
    "      \"match\": true/false,\n",
    "      \"details\": [\n",
    "        {{\n",
    "          \"requirement_section\": \"Requirement name/section\",\n",
    "          \"status\": \"Implemented/Partially Implemented/Not Implemented\",\n",
    "          \"notes\": \"Notes about implementation\"\n",
    "        }},\n",
    "        \"...\"\n",
    "      ]\n",
    "    }}\n",
    "  }}\n",
    "}}\n",
    "\n",
    "Be strict in your assessment. If ANY requirement is not fully implemented, the overall assessment should be \"Fail\".\n",
    "\"\"\"\n",
    "\n",
    "corrector_prompt = \"\"\"\n",
    "Role: Senior Python Developer\n",
    "Task: Refactor and fix the code based on the validation feedback.\n",
    "Original Requirements:\n",
    "{requirements}\n",
    "Validation Feedback:\n",
    "{ValidationFeedback}\n",
    "Correction Instructions:\n",
    "\n",
    "Address ALL issues identified in the validation feedback\n",
    "Pay particular attention to any requirements marked as \"Not Implemented\" or \"Partially Implemented\"\n",
    "Maintain the original architectural approach unless fundamentally flawed\n",
    "Ensure complete implementation of ALL requirements from the original specification\n",
    "Add or improve:\n",
    "\n",
    "Error handling for all edge cases\n",
    "Type hints throughout the codebase\n",
    "Documentation (docstrings and comments)\n",
    "Logging for important operations\n",
    "Performance optimizations where possible\n",
    "\n",
    "Important: Make sure you implement EVERY feature mentioned in the requirements that was flagged as missing or incomplete in the validation feedback.\n",
    "Output Format\n",
    "Your response should be the complete, corrected, production-ready Python code without explanations.\n",
    "DO NOT enclose your code in triple backticks (``` or ''').\n",
    "Simply output the pure Python code directly:\n",
    "Your corrected Python code here\n",
    "\"\"\"\n",
    "\n",
    "# State management for code generation process\n",
    "class CodeGenerationState(TypedDict):\n",
    "    \"\"\"State management for code generation process\"\"\"\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "    current_code: str\n",
    "    validation_status: bool\n",
    "    error_messages: list[str]\n",
    "    is_valid: bool  # Using is_valid to match the notebook's conditional edge structure\n",
    "    user_story_id: str  # Added to track user story ID for folder naming\n",
    "\n",
    "def extract_user_story_id(user_story_text):\n",
    "    \"\"\"\n",
    "    Extract user story ID from the text that contains 'User Story ID: XXX'\n",
    "    \n",
    "    Args:\n",
    "        user_story_text (str): The full user story text\n",
    "        \n",
    "    Returns:\n",
    "        str: The extracted user story ID or 'unknown_id' if not found\n",
    "    \"\"\"\n",
    "    # Look for \"User Story ID: XXX\" pattern\n",
    "    match = re.search(r'User\\s+Story\\s+ID\\s*:\\s*(\\d+)', user_story_text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return f\"US_{match.group(1)}\"\n",
    "    \n",
    "    # Alternative pattern - look for \"userstory1\" or similar patterns at the start of a line\n",
    "    match = re.search(r'^(?:(?:user)?story|us)(\\d+)', user_story_text, re.IGNORECASE | re.MULTILINE)\n",
    "    if match:\n",
    "        return f\"US_{match.group(1)}\"\n",
    "    \n",
    "    # If no ID is found, generate a fallback ID based on a hash of the content\n",
    "    logger.warning(\"No user story ID found in text, using fallback ID\")\n",
    "    import hashlib\n",
    "    hash_id = hashlib.md5(user_story_text.encode()).hexdigest()[:8]\n",
    "    return f\"Unknown_ID_{hash_id}\"\n",
    "\n",
    "def read_tech_specs_from_excel(excel_file_path):\n",
    "    \"\"\"\n",
    "    Read technical specifications from Excel file.\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries, each containing:\n",
    "        - 'user_story_id': ID of the user story\n",
    "        - 'tech_spec': Technical specification\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(excel_file_path)\n",
    "        \n",
    "        # Find the user story column and tech spec column\n",
    "        user_story_col = None\n",
    "        tech_spec_col = None\n",
    "        \n",
    "        # Determine column names - assuming first row has column headers\n",
    "        col_names = df.columns.tolist()\n",
    "        \n",
    "        # Find user story column\n",
    "        for col in col_names:\n",
    "            if 'user' in str(col).lower() and 'story' in str(col).lower():\n",
    "                user_story_col = col\n",
    "                break\n",
    "        \n",
    "        # Find tech spec column\n",
    "        for col in col_names:\n",
    "            if ('tech' in str(col).lower() and 'spec' in str(col).lower()) or 'requirement' in str(col).lower():\n",
    "                tech_spec_col = col\n",
    "                break\n",
    "        \n",
    "        # If we didn't find the right columns, default to the first two\n",
    "        if user_story_col is None and len(col_names) > 0:\n",
    "            user_story_col = col_names[0]\n",
    "        \n",
    "        if tech_spec_col is None and len(col_names) > 1:\n",
    "            tech_spec_col = col_names[1]\n",
    "        \n",
    "        logger.info(f\"Using columns: User Story = '{user_story_col}', Tech Spec = '{tech_spec_col}'\")\n",
    "        \n",
    "        # Extract tech specs\n",
    "        tech_specs = []\n",
    "        \n",
    "        # Skip the first row if it's empty (which appears to be the case)\n",
    "        start_row = 1 if df.iloc[0].isna().all() else 0\n",
    "        \n",
    "        for idx, row in df.iloc[start_row:].iterrows():\n",
    "            if pd.isna(row[user_story_col]) or pd.isna(row[tech_spec_col]):\n",
    "                logger.warning(f\"Skipping row {idx} due to missing data\")\n",
    "                continue\n",
    "                \n",
    "            user_story_text = str(row[user_story_col])\n",
    "            tech_spec_text = str(row[tech_spec_col])\n",
    "            \n",
    "            # Extract user story ID using the helper function\n",
    "            user_story_id = extract_user_story_id(user_story_text)\n",
    "            \n",
    "            tech_specs.append({\n",
    "                'user_story_id': user_story_id,\n",
    "                'tech_spec': tech_spec_text\n",
    "            })\n",
    "        \n",
    "        logger.info(f\"Successfully extracted {len(tech_specs)} tech specs from Excel file\")\n",
    "        return tech_specs\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error reading Excel file: {e}\")\n",
    "        raise\n",
    "\n",
    "class CodeGenerator:\n",
    "    \"\"\"Main class for generating, validating, and correcting code\"\"\"\n",
    "    \n",
    "    def __init__(self, model, base_output_dir=None, system_developer=\"\", system_validator=\"\", system_corrector=\"\"):\n",
    "        self.system_developer = system_developer\n",
    "        self.system_validator = system_validator\n",
    "        self.system_corrector = system_corrector\n",
    "        \n",
    "        # Create output base directory\n",
    "        self.base_output_dir = base_output_dir or f\"code_generation_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        os.makedirs(self.base_output_dir, exist_ok=True)\n",
    "        \n",
    "        # Initialize graph\n",
    "        graph = StateGraph(CodeGenerationState)\n",
    "        \n",
    "        # Add nodes\n",
    "        graph.add_node(\"developer\", self.developer)\n",
    "        graph.add_node(\"validator\", self.validator)\n",
    "        graph.add_node(\"correction\", self.correction)\n",
    "        \n",
    "        # Add edges\n",
    "        graph.add_edge(\"developer\", \"validator\")\n",
    "        \n",
    "        # Add conditional edges (matching notebook pattern)\n",
    "        graph.add_conditional_edges(\n",
    "            \"validator\", \n",
    "            lambda state: state[\"is_valid\"],\n",
    "            {\n",
    "                True: END,\n",
    "                False: \"correction\"\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        graph.add_edge(\"correction\", END)\n",
    "        \n",
    "        # Set entry point\n",
    "        graph.set_entry_point(\"developer\")\n",
    "        self.graph = graph.compile()\n",
    "        self.model = model\n",
    "        \n",
    "        # Try to display graph visualization if possible\n",
    "        try:\n",
    "            display(Image(self.graph.get_graph().draw_mermaid_png()))\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error displaying graph: {e}\")\n",
    "            pass\n",
    "\n",
    "    def get_output_dir(self, user_story_id):\n",
    "        \"\"\"Create and return a user story specific output directory\"\"\"\n",
    "        # Create user story specific directory if it doesn't exist\n",
    "        user_story_dir = os.path.join(self.base_output_dir, user_story_id)\n",
    "        os.makedirs(user_story_dir, exist_ok=True)\n",
    "        return user_story_dir\n",
    "\n",
    "    def extract_code(self, text):\n",
    "        \"\"\"Extract code from between triple backticks or triple single quotes\"\"\"\n",
    "        pattern = r\"```(?:python)?\\\\s*(.*?)```\"\n",
    "        matches = re.findall(pattern, text, re.DOTALL)\n",
    "        if matches:\n",
    "            return matches[0].strip()\n",
    "            \n",
    "        # Try with triple single quotes\n",
    "        pattern = r\"'''(?:python)?\\\\s*(.*?)'''\"\n",
    "        matches = re.findall(pattern, text, re.DOTALL)\n",
    "        if matches:\n",
    "            return matches[0].strip()\n",
    "            \n",
    "        return text  # Return original if no code blocks found\n",
    "\n",
    "    def save_code_attempt(self, code: str, user_story_id: str, status: str = \"initial\") -> str:\n",
    "        \"\"\"Save code attempt and return directory path\"\"\"\n",
    "        # Get user story specific output directory\n",
    "        output_dir = self.get_output_dir(user_story_id)\n",
    "        \n",
    "        attempt_dir = os.path.join(output_dir, f\"attempt_{status}\")\n",
    "        os.makedirs(attempt_dir, exist_ok=True)\n",
    "        \n",
    "        # Save code\n",
    "        code_file = os.path.join(attempt_dir, \"code.py\")\n",
    "        with open(code_file, 'w') as f:\n",
    "            f.write(code)\n",
    "        \n",
    "        logger.info(f\"Saved code attempt to {code_file}\")\n",
    "        return attempt_dir\n",
    "\n",
    "    def developer(self, state: CodeGenerationState):\n",
    "        \"\"\"Generate initial code\"\"\"\n",
    "        messages = state['messages']\n",
    "        user_story_id = state.get('user_story_id', 'default_id')\n",
    "        logger.info(f\"Processing user story ID: {user_story_id}\")\n",
    "        print(f\"developer - User Story ID: {user_story_id}\")\n",
    "        \n",
    "        if self.system_developer:\n",
    "            # Note: Using exact case from the prompt template\n",
    "            formatted_prompt = self.system_developer.format(\n",
    "                requirements=messages[0].content,  # Changed from Requirements to requirements\n",
    "                TechnicalSpecifications=messages[0].content\n",
    "            )\n",
    "            messages = [SystemMessage(content=formatted_prompt)] + messages\n",
    "        \n",
    "        message = self.model.invoke(messages)\n",
    "        \n",
    "        # Extract code from response\n",
    "        response_text = getattr(message, \"content\", \"\")\n",
    "        code_only = self.extract_code(response_text)\n",
    "        \n",
    "        # Save code\n",
    "        self.save_code_attempt(code_only, user_story_id)\n",
    "        \n",
    "        return {\n",
    "            'messages': [message],\n",
    "            'current_code': code_only,\n",
    "            'validation_status': None,\n",
    "            'error_messages': [],\n",
    "            'is_valid': False,\n",
    "            'user_story_id': user_story_id\n",
    "        }\n",
    "\n",
    "    def validator(self, state: CodeGenerationState):\n",
    "        \"\"\"Validate generated code\"\"\"\n",
    "        messages = state.get('messages', [])\n",
    "        current_code = state.get('current_code', '')\n",
    "        user_story_id = state.get('user_story_id', 'default_id')\n",
    "        \n",
    "        print(f\"validate - User Story ID: {user_story_id}\")\n",
    "        \n",
    "        if self.system_validator:\n",
    "            original_message = state[\"messages\"][0].content if state[\"messages\"] else \"\"\n",
    "            # Note: Using exact case from the prompt template\n",
    "            formatted_prompt = self.system_validator.format(\n",
    "                Requirements=original_message,\n",
    "                TechnicalSpecifications=original_message\n",
    "            )\n",
    "            messages = [SystemMessage(content=formatted_prompt)] + messages\n",
    "        \n",
    "        message = self.model.invoke(messages)\n",
    "        response_text = getattr(message, \"content\", \"\").lower()\n",
    "        \n",
    "        # Attempt to determine if validation passed by extracting JSON\n",
    "        is_valid = False\n",
    "        try:\n",
    "            # Try to extract JSON from the message\n",
    "            json_pattern = r\"```json\\s*(.*?)\\s*```\"\n",
    "            match = re.search(json_pattern, message.content, re.DOTALL)\n",
    "            if match:\n",
    "                validation_json = json.loads(match.group(1))\n",
    "                is_valid = (validation_json.get(\"validation_report\", {}).get(\"overall_assessment\", \"\").lower() == \"pass\")\n",
    "        except:\n",
    "            # Fallback to the original logic if JSON extraction fails\n",
    "            is_valid = \"pass\" in response_text and \"correctly implements\" in response_text\n",
    "        \n",
    "        # Save validation results to JSON if possible\n",
    "        try:\n",
    "            json_pattern = r\"```json\\s*(.*?)\\s*```\"\n",
    "            match = re.search(json_pattern, message.content, re.DOTALL)\n",
    "            if match:\n",
    "                validation_json = json.loads(match.group(1))\n",
    "                output_dir = self.get_output_dir(user_story_id)\n",
    "                json_path = os.path.join(output_dir, \"validation_results.json\")\n",
    "                with open(json_path, 'w') as f:\n",
    "                    json.dump(validation_json, f, indent=2)\n",
    "                logger.info(f\"Saved validation results to {json_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to save validation results: {e}\")\n",
    "        \n",
    "        if is_valid:\n",
    "            self.save_code_attempt(current_code, user_story_id, \"validated_pass\")\n",
    "        else:\n",
    "            self.save_code_attempt(current_code, user_story_id, \"validated_fail\")\n",
    "            \n",
    "        return {\n",
    "            'messages': [message],\n",
    "            'current_code': current_code,\n",
    "            'is_valid': is_valid,\n",
    "            'error_messages': [] if is_valid else [\"Validation failed\"],\n",
    "            'user_story_id': user_story_id\n",
    "        }\n",
    "\n",
    "    def correction(self, state: CodeGenerationState):\n",
    "        \"\"\"Correct code based on validation feedback\"\"\"\n",
    "        messages = state['messages']\n",
    "        user_story_id = state.get('user_story_id', 'default_id')\n",
    "        \n",
    "        print(f\"correction - User Story ID: {user_story_id}\")\n",
    "        \n",
    "        if self.system_corrector:\n",
    "            # Get original requirements from the first human message in the chain\n",
    "            original_requirements = \"\"\n",
    "            for msg in state['messages']:\n",
    "                if isinstance(msg, HumanMessage) and msg.content:\n",
    "                    original_requirements = msg.content\n",
    "                    break\n",
    "            \n",
    "            # Get validation feedback from the most recent message\n",
    "            validation_feedback = messages[0].content if messages else \"\"\n",
    "            \n",
    "            # Note: Using exact case from the prompt template\n",
    "            formatted_prompt = self.system_corrector.format(\n",
    "                requirements=original_requirements,  # Changed from Requirements to requirements\n",
    "                ValidationFeedback=validation_feedback\n",
    "            )\n",
    "            messages = [SystemMessage(content=formatted_prompt)] + messages\n",
    "        \n",
    "        message = self.model.invoke(messages)\n",
    "        response_text = getattr(message, \"content\", \"\")\n",
    "        code_only = self.extract_code(response_text)\n",
    "        \n",
    "        # Save corrected code\n",
    "        self.save_code_attempt(code_only, user_story_id, \"correction\")\n",
    "        \n",
    "        return {\n",
    "            'messages': [message],\n",
    "            'current_code': code_only,\n",
    "            'is_valid': False,\n",
    "            'error_messages': [],\n",
    "            'user_story_id': user_story_id\n",
    "        }\n",
    "\n",
    "def process_tech_specs(excel_file_path=\"tech.xlsx\"):\n",
    "    \"\"\"\n",
    "    Process tech specs from an Excel file\n",
    "    \n",
    "    Args:\n",
    "        excel_file_path: Path to Excel file with tech specs\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the output directory\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read tech specs from Excel\n",
    "        tech_specs = read_tech_specs_from_excel(excel_file_path)\n",
    "        \n",
    "        if not tech_specs:\n",
    "            logger.error(\"No tech specs found in Excel file\")\n",
    "            return None\n",
    "        \n",
    "        # Model initialization\n",
    "        model = AzureChatOpenAI(\n",
    "            azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "            api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "            api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "            deployment_name=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"]\n",
    "        )\n",
    "        \n",
    "        # Create a base output directory\n",
    "        base_output_dir = f\"code_generation_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        \n",
    "        # Initialize code generator with the base directory\n",
    "        code_gen = CodeGenerator(\n",
    "            model=model, \n",
    "            base_output_dir=base_output_dir,\n",
    "            system_developer=developer_prompt,\n",
    "            system_validator=validator_prompt,\n",
    "            system_corrector=corrector_prompt\n",
    "        )\n",
    "        \n",
    "        # Process each tech spec\n",
    "        for idx, spec in enumerate(tech_specs):\n",
    "            user_story_id = spec['user_story_id']\n",
    "            tech_spec = spec['tech_spec']\n",
    "            \n",
    "            logger.info(f\"Processing tech spec for user story ID: {user_story_id} ({idx+1}/{len(tech_specs)})\")\n",
    "            \n",
    "            # Setup initial message\n",
    "            messages = [HumanMessage(content=tech_spec)]\n",
    "            \n",
    "            # Set up the input state\n",
    "            initial_state = {\n",
    "                \"messages\": messages,\n",
    "                \"current_code\": \"\",\n",
    "                \"validation_status\": None,\n",
    "                \"error_messages\": [],\n",
    "                \"is_valid\": False,\n",
    "                \"user_story_id\": user_story_id\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                # Run the graph\n",
    "                result = code_gen.graph.invoke(initial_state)\n",
    "                \n",
    "                # Log success\n",
    "                logger.info(f\"Successfully processed tech spec for user story ID: {user_story_id}\")\n",
    "                \n",
    "                # Extract final code\n",
    "                if 'current_code' in result and result['current_code']:\n",
    "                    final_status = \"final_corrected\" if not result.get('is_valid', False) else \"final_validated\"\n",
    "                    code_gen.save_code_attempt(result['current_code'], user_story_id, final_status)\n",
    "            \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing tech spec for user story ID {user_story_id}: {e}\")\n",
    "                continue\n",
    "            \n",
    "        logger.info(f\"Completed processing all tech specs. Output directory: {base_output_dir}\")\n",
    "        return base_output_dir\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in process_tech_specs: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Code Integration Functionality\n",
    "\n",
    "def find_latest_code_generation_folder(base_dir=None):\n",
    "    \"\"\"Find the latest code_generation folder based on creation time.\"\"\"\n",
    "    if base_dir is None:\n",
    "        base_dir = os.getcwd()  # Current working directory\n",
    "    \n",
    "    code_gen_folders = [d for d in os.listdir(base_dir) if d.startswith(\"code_generation_\") and os.path.isdir(os.path.join(base_dir, d))]\n",
    "    if not code_gen_folders:\n",
    "        raise FileNotFoundError(\"No code_generation folders found\")\n",
    "    \n",
    "    # Sort by creation time, most recent first\n",
    "    code_gen_folders.sort(key=lambda d: os.path.getctime(os.path.join(base_dir, d)), reverse=True)\n",
    "    return os.path.join(base_dir, code_gen_folders[0])\n",
    "\n",
    "def find_code_files(base_folder):\n",
    "    \"\"\"\n",
    "    Find all code files in subfolders.\n",
    "    Prioritize files in this order:\n",
    "    1. final_corrected\n",
    "    2. final_validated\n",
    "    3. correction\n",
    "    4. validated_pass\n",
    "    5. initial (fallback)\n",
    "    \"\"\"\n",
    "    code_files = []\n",
    "    \n",
    "    # Priority order for folder names\n",
    "    priority_folders = [\"final_corrected\", \"final_validated\", \"correction\", \"validated_pass\", \"initial\"]\n",
    "    \n",
    "    # First, get all user story folders\n",
    "    user_story_folders = [f for f in os.listdir(base_folder) \n",
    "                         if os.path.isdir(os.path.join(base_folder, f))]\n",
    "    \n",
    "    for user_folder in user_story_folders:\n",
    "        user_path = os.path.join(base_folder, user_folder)\n",
    "        \n",
    "        # Check each priority folder type\n",
    "        found = False\n",
    "        for priority in priority_folders:\n",
    "            attempt_path = os.path.join(user_path, f\"attempt_{priority}\")\n",
    "            code_file = os.path.join(attempt_path, \"code.py\")\n",
    "            \n",
    "            if os.path.exists(code_file):\n",
    "                code_files.append((user_folder, code_file))\n",
    "                found = True\n",
    "                logger.info(f\"Using '{priority}' code for {user_folder}\")\n",
    "                break\n",
    "        \n",
    "        if not found:\n",
    "            logger.warning(f\"No code files found at all for {user_folder}\")\n",
    "    \n",
    "    return code_files\n",
    "\n",
    "def read_code_files(code_files):\n",
    "    \"\"\"Read code files and return a dictionary mapping module names to code content.\"\"\"\n",
    "    code_contents = {}\n",
    "    \n",
    "    for module_name, file_path in code_files:\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                content = f.read()\n",
    "                code_contents[module_name] = content\n",
    "                logger.info(f\"Read {len(content)} bytes from {file_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading {file_path}: {e}\")\n",
    "    \n",
    "    return code_contents\n",
    "\n",
    "def get_docstring_summary(docstring):\n",
    "    \"\"\"Extract the first sentence of a docstring or return a default message.\"\"\"\n",
    "    if not docstring:\n",
    "        return \"No documentation available\"\n",
    "    \n",
    "    # Try to get the first sentence\n",
    "    if '.' in docstring:\n",
    "        return docstring.split('.')[0].strip()\n",
    "    \n",
    "    return docstring.strip()\n",
    "\n",
    "class RelationshipVisitor(ast.NodeVisitor):\n",
    "    \"\"\"AST visitor that extracts relationships between functions, classes, and variables.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.defined_names = set()  # All defined names in the module\n",
    "        self.function_calls = defaultdict(set)  # Mapping of function name to the set of function names it calls\n",
    "        self.class_instantiations = defaultdict(set)  # Mapping of function name to the set of class names it instantiates\n",
    "        self.attribute_accesses = defaultdict(set)  # Mapping of function/method name to the attributes it accesses\n",
    "        self.imports = []  # List of import statements\n",
    "        self.global_vars = []  # List of global variables\n",
    "        self.functions = []  # List of functions\n",
    "        self.classes = []  # List of classes\n",
    "        \n",
    "        # Track current context (function or class being processed)\n",
    "        self.current_function = None\n",
    "        self.current_class = None\n",
    "        self.current_method = None\n",
    "        \n",
    "        # Track known external names\n",
    "        self.external_modules = set()\n",
    "        \n",
    "    def visit_Import(self, node):\n",
    "        \"\"\"Process import statements.\"\"\"\n",
    "        for name in node.names:\n",
    "            import_name = name.name\n",
    "            alias = name.asname or import_name\n",
    "            self.imports.append({\n",
    "                \"module\": import_name,\n",
    "                \"alias\": name.asname\n",
    "            })\n",
    "            self.defined_names.add(alias)\n",
    "            self.external_modules.add(alias)\n",
    "        self.generic_visit(node)\n",
    "    \n",
    "    def visit_ImportFrom(self, node):\n",
    "        \"\"\"Process from ... import ... statements.\"\"\"\n",
    "        module = node.module or \"\"\n",
    "        for name in node.names:\n",
    "            import_name = name.name\n",
    "            alias = name.asname or import_name\n",
    "            self.imports.append({\n",
    "                \"module\": module,\n",
    "                \"name\": import_name,\n",
    "                \"alias\": name.asname\n",
    "            })\n",
    "            self.defined_names.add(alias)\n",
    "        self.generic_visit(node)\n",
    "    \n",
    "    def visit_ClassDef(self, node):\n",
    "        \"\"\"Process class definitions.\"\"\"\n",
    "        class_name = node.name\n",
    "        self.defined_names.add(class_name)\n",
    "        \n",
    "        # Extract base classes\n",
    "        bases = []\n",
    "        for base in node.bases:\n",
    "            if isinstance(base, ast.Name):\n",
    "                bases.append(base.id)\n",
    "            else:\n",
    "                try:\n",
    "                    bases.append(ast.unparse(base))\n",
    "                except:\n",
    "                    bases.append(str(base))\n",
    "        \n",
    "        # Extract docstring\n",
    "        docstring = None\n",
    "        if (node.body and isinstance(node.body[0], ast.Expr) and \n",
    "            isinstance(node.body[0].value, ast.Str)):\n",
    "            docstring = node.body[0].value.s.strip()\n",
    "        \n",
    "        # Save the current class context\n",
    "        prev_class = self.current_class\n",
    "        self.current_class = class_name\n",
    "        \n",
    "        # Process the class body\n",
    "        methods = []\n",
    "        for child in node.body:\n",
    "            if isinstance(child, ast.FunctionDef):\n",
    "                # This is a method\n",
    "                method_info = self.process_function(child, is_method=True)\n",
    "                if method_info:\n",
    "                    methods.append(method_info)\n",
    "        \n",
    "        # Add class info\n",
    "        self.classes.append({\n",
    "            \"name\": class_name,\n",
    "            \"docstring\": docstring or \"No documentation available.\",\n",
    "            \"bases\": bases,\n",
    "            \"methods\": methods,\n",
    "            \"relationships\": {\n",
    "                \"inherits_from\": bases,\n",
    "                \"used_by_functions\": [],  # Will be filled later\n",
    "                \"instantiated_by\": []  # Will be filled later\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        # Restore previous class context\n",
    "        self.current_class = prev_class\n",
    "    \n",
    "    def process_function(self, node, is_method=False):\n",
    "        \"\"\"Process function or method definition.\"\"\"\n",
    "        func_name = node.name\n",
    "        \n",
    "        # Skip if it's a special method (like __init__) - we'll still process its body though\n",
    "        skip_adding = False\n",
    "        if is_method and func_name.startswith('__') and func_name.endswith('__'):\n",
    "            skip_adding = True\n",
    "        \n",
    "        # For methods, the full name includes the class name\n",
    "        full_name = f\"{self.current_class}.{func_name}\" if is_method and self.current_class else func_name\n",
    "        \n",
    "        # Extract docstring\n",
    "        docstring = None\n",
    "        if (node.body and isinstance(node.body[0], ast.Expr) and \n",
    "            isinstance(node.body[0].value, ast.Str)):\n",
    "            docstring = node.body[0].value.s.strip()\n",
    "        \n",
    "        # Extract parameters\n",
    "        parameters = []\n",
    "        for arg in node.args.args:\n",
    "            param_name = arg.arg\n",
    "            param_type = None\n",
    "            if arg.annotation:\n",
    "                try:\n",
    "                    param_type = ast.unparse(arg.annotation)\n",
    "                except:\n",
    "                    param_type = str(arg.annotation)\n",
    "            \n",
    "            parameters.append({\n",
    "                \"name\": param_name,\n",
    "                \"type\": param_type,\n",
    "                \"description\": \"Parameter description not available.\"\n",
    "            })\n",
    "        \n",
    "        # Extract return type\n",
    "        returns = None\n",
    "        if node.returns:\n",
    "            try:\n",
    "                returns = ast.unparse(node.returns)\n",
    "            except:\n",
    "                returns = str(node.returns)\n",
    "        \n",
    "        # Save the current function context\n",
    "        prev_function = self.current_function\n",
    "        prev_method = self.current_method\n",
    "        \n",
    "        if is_method:\n",
    "            self.current_method = full_name\n",
    "        else:\n",
    "            self.current_function = full_name\n",
    "            self.defined_names.add(func_name)\n",
    "        \n",
    "        # Visit the function body to capture calls and relationships\n",
    "        self.generic_visit(node)\n",
    "        \n",
    "        # Create the function info object\n",
    "        func_info = {\n",
    "            \"name\": func_name,\n",
    "            \"docstring\": docstring or \"No documentation available.\",\n",
    "            \"parameters\": parameters,\n",
    "            \"returns\": returns,\n",
    "            \"relationships\": {\n",
    "                \"calls_functions\": list(self.function_calls.get(full_name, set())),\n",
    "                \"instantiates_classes\": list(self.class_instantiations.get(full_name, set())),\n",
    "                \"accesses_attributes\": list(self.attribute_accesses.get(full_name, set())),\n",
    "                \"called_by\": []  # Will be filled later\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Restore previous function context\n",
    "        self.current_function = prev_function\n",
    "        self.current_method = prev_method\n",
    "        \n",
    "        # Add to functions list if not a method or not a special method\n",
    "        if not skip_adding:\n",
    "            if not is_method:\n",
    "                self.functions.append(func_info)\n",
    "            return func_info\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def visit_FunctionDef(self, node):\n",
    "        \"\"\"Process function definitions.\"\"\"\n",
    "        self.process_function(node)\n",
    "    \n",
    "    def visit_Call(self, node):\n",
    "        \"\"\"Process function calls.\"\"\"\n",
    "        # Determine the current context\n",
    "        current_context = self.current_method if self.current_method else self.current_function\n",
    "        \n",
    "        if current_context:\n",
    "            # Function call\n",
    "            if isinstance(node.func, ast.Name):\n",
    "                func_name = node.func.id\n",
    "                self.function_calls[current_context].add(func_name)\n",
    "            \n",
    "            # Method call (obj.method())\n",
    "            elif isinstance(node.func, ast.Attribute) and isinstance(node.func.value, ast.Name):\n",
    "                obj_name = node.func.value.id\n",
    "                method_name = node.func.attr\n",
    "                \n",
    "                # Could be a module.function() call\n",
    "                if obj_name in self.external_modules:\n",
    "                    full_call = f\"{obj_name}.{method_name}\"\n",
    "                else:\n",
    "                    # Could be a class instantiation (ClassName())\n",
    "                    for cls in self.classes:\n",
    "                        if cls[\"name\"] == obj_name:\n",
    "                            self.class_instantiations[current_context].add(obj_name)\n",
    "                            break\n",
    "                    \n",
    "                    full_call = f\"{obj_name}.{method_name}\"\n",
    "                \n",
    "                self.function_calls[current_context].add(full_call)\n",
    "                self.attribute_accesses[current_context].add(f\"{obj_name}.{method_name}\")\n",
    "        \n",
    "        self.generic_visit(node)\n",
    "    \n",
    "    def visit_Assign(self, node):\n",
    "        \"\"\"Process assignments.\"\"\"\n",
    "        # Only process global assignments\n",
    "        if not self.current_function and not self.current_method:\n",
    "            for target in node.targets:\n",
    "                if isinstance(target, ast.Name):\n",
    "                    var_name = target.id\n",
    "                    try:\n",
    "                        var_value = ast.unparse(node.value)\n",
    "                    except:\n",
    "                        var_value = str(node.value)\n",
    "                    \n",
    "                    # Check if it's a class instantiation\n",
    "                    if isinstance(node.value, ast.Call) and isinstance(node.value.func, ast.Name):\n",
    "                        class_name = node.value.func.id\n",
    "                        # Check if it's one of our known classes\n",
    "                        for cls in self.classes:\n",
    "                            if cls[\"name\"] == class_name:\n",
    "                                self.class_instantiations[\"global\"].add(class_name)\n",
    "                                break\n",
    "                    \n",
    "                    self.global_vars.append({\n",
    "                        \"name\": var_name,\n",
    "                        \"value\": var_value\n",
    "                    })\n",
    "                    self.defined_names.add(var_name)\n",
    "        \n",
    "        self.generic_visit(node)\n",
    "    \n",
    "    def post_process(self):\n",
    "        \"\"\"Build reverse relationships after processing.\"\"\"\n",
    "        # For each function call, update the called_by relationship\n",
    "        for caller, callees in self.function_calls.items():\n",
    "            for callee in callees:\n",
    "                # Find the actual function record\n",
    "                for func in self.functions:\n",
    "                    if func[\"name\"] == callee:\n",
    "                        if caller not in func[\"relationships\"][\"called_by\"]:\n",
    "                            func[\"relationships\"][\"called_by\"].append(caller)\n",
    "        \n",
    "        # For each class instantiation, update the instantiated_by relationship\n",
    "        for instantiator, classes in self.class_instantiations.items():\n",
    "            for class_name in classes:\n",
    "                # Find the actual class record\n",
    "                for cls in self.classes:\n",
    "                    if cls[\"name\"] == class_name:\n",
    "                        if instantiator not in cls[\"relationships\"][\"instantiated_by\"]:\n",
    "                            cls[\"relationships\"][\"instantiated_by\"].append(instantiator)\n",
    "        \n",
    "        # For each class, update the used_by_functions relationship\n",
    "        for cls in self.classes:\n",
    "            class_name = cls[\"name\"]\n",
    "            for func in self.functions:\n",
    "                # If function instantiates this class\n",
    "                if class_name in func[\"relationships\"][\"instantiates_classes\"]:\n",
    "                    if func[\"name\"] not in cls[\"relationships\"][\"used_by_functions\"]:\n",
    "                        cls[\"relationships\"][\"used_by_functions\"].append(func[\"name\"])\n",
    "                \n",
    "                # If function accesses any attributes related to this class\n",
    "                for attr in func[\"relationships\"][\"accesses_attributes\"]:\n",
    "                    if attr.startswith(f\"{class_name}.\"):\n",
    "                        if func[\"name\"] not in cls[\"relationships\"][\"used_by_functions\"]:\n",
    "                            cls[\"relationships\"][\"used_by_functions\"].append(func[\"name\"])\n",
    "\n",
    "class EnhancedAPIDocGenerator:\n",
    "    \"\"\"Class to generate enhanced API documentation with relationship information.\"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def generate_module_api_doc(self, module_name, code):\n",
    "        \"\"\"Generate enhanced API documentation for a module.\"\"\"\n",
    "        try:\n",
    "            # Parse the AST\n",
    "            tree = ast.parse(code)\n",
    "            \n",
    "            # Visit the AST to extract entities and relationships\n",
    "            visitor = RelationshipVisitor()\n",
    "            visitor.visit(tree)\n",
    "            visitor.post_process()\n",
    "            \n",
    "            # Extract module docstring\n",
    "            module_docstring = None\n",
    "            if (tree.body and isinstance(tree.body[0], ast.Expr) and \n",
    "                isinstance(tree.body[0].value, ast.Str)):\n",
    "                module_docstring = tree.body[0].value.s.strip()\n",
    "            \n",
    "            # Create module doc\n",
    "            module_doc = {\n",
    "                \"name\": module_name,\n",
    "                \"docstring\": module_docstring or \"No module documentation available.\",\n",
    "                \"imports\": visitor.imports,\n",
    "                \"global_vars\": visitor.global_vars,\n",
    "                \"functions\": visitor.functions,\n",
    "                \"classes\": visitor.classes,\n",
    "                \"relationships\": {\n",
    "                    \"dependencies\": self._analyze_module_dependencies(visitor),\n",
    "                    \"entry_points\": self._identify_entry_points(visitor)\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            return module_doc\n",
    "            \n",
    "        except SyntaxError as e:\n",
    "            logger.error(f\"Syntax error in module {module_name}: {e}\")\n",
    "            return self._fallback_api_doc_generation(module_name, code)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error parsing module {module_name}: {e}\")\n",
    "            return self._fallback_api_doc_generation(module_name, code)\n",
    "    \n",
    "    def _analyze_module_dependencies(self, visitor):\n",
    "        \"\"\"Analyze module level dependencies.\"\"\"\n",
    "        dependencies = {\n",
    "            \"imports\": [imp.get(\"module\") for imp in visitor.imports if \"module\" in imp],\n",
    "            \"from_imports\": [f\"{imp.get('module')}.{imp.get('name')}\" for imp in visitor.imports if \"name\" in imp],\n",
    "        }\n",
    "        return dependencies\n",
    "    \n",
    "    def _identify_entry_points(self, visitor):\n",
    "        \"\"\"Identify potential entry points in the module.\"\"\"\n",
    "        # Entry points are functions that are not called by other functions\n",
    "        entry_points = []\n",
    "        \n",
    "        for func in visitor.functions:\n",
    "            if not func[\"relationships\"][\"called_by\"]:\n",
    "                # This function is not called by others\n",
    "                entry_points.append(func[\"name\"])\n",
    "        \n",
    "        # Also look for if __name__ == \"__main__\" block\n",
    "        # This is a simplification - in a real implementation, we'd need to parse the AST for this\n",
    "        \n",
    "        return entry_points\n",
    "    \n",
    "    def _fallback_api_doc_generation(self, module_name, code):\n",
    "        \"\"\"Use the LLM as a fallback for API doc generation when parsing fails.\"\"\"\n",
    "        logger.info(f\"Using LLM to extract enhanced API documentation for {module_name}\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "Generate a detailed API documentation for the following Python code module.\n",
    "Extract all functions, classes, methods, and their parameters, return types, and docstrings.\n",
    "MOST IMPORTANTLY, also extract the relationships between functions and classes:\n",
    "- What functions call other functions\n",
    "- What functions instantiate classes\n",
    "- What classes inherit from other classes\n",
    "- What functions are entry points (not called by others)\n",
    "\n",
    "Format the response as a JSON object with the structure shown in the example.\n",
    "\n",
    "Example structure:\n",
    "```json\n",
    "{{\n",
    "  \"name\": \"module_name\",\n",
    "  \"docstring\": \"Module docstring\",\n",
    "  \"imports\": [\n",
    "    {{\"module\": \"os\", \"alias\": null}},\n",
    "    {{\"module\": \"pandas\", \"alias\": \"pd\"}}\n",
    "  ],\n",
    "  \"global_vars\": [\n",
    "    {{\"name\": \"logger\", \"value\": \"logging.getLogger(__name__)\"}}\n",
    "  ],\n",
    "  \"functions\": [\n",
    "    {{\n",
    "      \"name\": \"function_name\",\n",
    "      \"docstring\": \"Function docstring\",\n",
    "      \"parameters\": [\n",
    "        {{\"name\": \"param1\", \"type\": \"str\", \"description\": \"Description of param1\"}}\n",
    "      ],\n",
    "      \"returns\": \"str\",\n",
    "      \"relationships\": {{\n",
    "        \"calls_functions\": [\"other_function\", \"third_function\"],\n",
    "        \"instantiates_classes\": [\"SomeClass\"],\n",
    "        \"accesses_attributes\": [\"object.attribute\"],\n",
    "        \"called_by\": [\"main\"]\n",
    "      }}\n",
    "    }}\n",
    "  ],\n",
    "  \"classes\": [\n",
    "    {{\n",
    "      \"name\": \"ClassName\",\n",
    "      \"docstring\": \"Class docstring\",\n",
    "      \"bases\": [\"BaseClass\"],\n",
    "      \"methods\": [\n",
    "        {{\n",
    "          \"name\": \"method_name\",\n",
    "          \"docstring\": \"Method docstring\",\n",
    "          \"parameters\": [\n",
    "            {{\"name\": \"self\", \"type\": null, \"description\": \"Instance reference\"}},\n",
    "            {{\"name\": \"param1\", \"type\": \"str\", \"description\": \"Description of param1\"}}\n",
    "          ],\n",
    "          \"returns\": \"bool\",\n",
    "          \"relationships\": {{\n",
    "            \"calls_functions\": [\"some_function\"],\n",
    "            \"instantiates_classes\": [],\n",
    "            \"accesses_attributes\": [\"self.attribute\"],\n",
    "            \"called_by\": []\n",
    "          }}\n",
    "        }}\n",
    "      ],\n",
    "      \"relationships\": {{\n",
    "        \"inherits_from\": [\"BaseClass\"],\n",
    "        \"used_by_functions\": [\"function_name\"],\n",
    "        \"instantiated_by\": [\"function_name\"]\n",
    "      }}\n",
    "    }}\n",
    "  ],\n",
    "  \"relationships\": {{\n",
    "    \"dependencies\": {{\n",
    "      \"imports\": [\"os\", \"pandas\"],\n",
    "      \"from_imports\": [\"logging.getLogger\"]\n",
    "    }},\n",
    "    \"entry_points\": [\"main\"]\n",
    "  }}\n",
    "}}\n",
    "```\n",
    "\n",
    "Here's the code to document:\n",
    "\n",
    "```python\n",
    "{code}\n",
    "```\n",
    "\n",
    "Focus especially on capturing the relationships between functions and classes to help understand how the code works together.\n",
    "\"\"\"\n",
    "\n",
    "        system_message = SystemMessage(content=\"You are a Python expert who specializes in extracting API documentation and code relationships from code.\")\n",
    "        human_message = HumanMessage(content=prompt)\n",
    "        \n",
    "        try:\n",
    "            response = self.model.invoke([system_message, human_message])\n",
    "            content = response.content\n",
    "            \n",
    "            # Try to extract JSON from the response\n",
    "            json_match = re.search(r'```json\\s*(.*?)\\s*```', content, re.DOTALL)\n",
    "            if json_match:\n",
    "                json_str = json_match.group(1)\n",
    "            else:\n",
    "                # If no JSON code block, try to find any JSON object\n",
    "                json_match = re.search(r'({[\\s\\S]*})', content)\n",
    "                if json_match:\n",
    "                    json_str = json_match.group(1)\n",
    "                else:\n",
    "                    json_str = content\n",
    "            \n",
    "            return json.loads(json_str)\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error getting API doc from LLM for {module_name}: {e}\")\n",
    "            # Return a minimal structure\n",
    "            return {\n",
    "                \"name\": module_name,\n",
    "                \"docstring\": \"Documentation extraction failed.\",\n",
    "                \"imports\": [],\n",
    "                \"global_vars\": [],\n",
    "                \"functions\": [],\n",
    "                \"classes\": [],\n",
    "                \"relationships\": {\n",
    "                    \"dependencies\": {\n",
    "                        \"imports\": [],\n",
    "                        \"from_imports\": []\n",
    "                    },\n",
    "                    \"entry_points\": []\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    def generate_all_module_docs(self, code_contents):\n",
    "        \"\"\"Generate API documentation for all modules.\"\"\"\n",
    "        module_docs = {}\n",
    "        \n",
    "        for module_name, code in code_contents.items():\n",
    "            try:\n",
    "                module_doc = self.generate_module_api_doc(module_name, code)\n",
    "                module_docs[module_name] = module_doc\n",
    "                logger.info(f\"Generated enhanced API documentation for {module_name}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error generating API doc for {module_name}: {e}\")\n",
    "        \n",
    "        return module_docs\n",
    "    \n",
    "    def try_generate_dependency_graph(self, module_docs):\n",
    "        \"\"\"Try to generate a dependency graph visualization for all modules.\"\"\"\n",
    "        try:\n",
    "            # Check if matplotlib and networkx are available\n",
    "            try:\n",
    "                import matplotlib.pyplot as plt\n",
    "                import networkx as nx\n",
    "            except ImportError:\n",
    "                logger.warning(\"matplotlib or networkx not available, skipping graph generation\")\n",
    "                return None\n",
    "            \n",
    "            # Create a directed graph\n",
    "            G = nx.DiGraph()\n",
    "            \n",
    "            # Add nodes for each module\n",
    "            for module_name in module_docs.keys():\n",
    "                G.add_node(module_name, type='module')\n",
    "            \n",
    "            # Add edges for dependencies between modules\n",
    "            for module_name, doc in module_docs.items():\n",
    "                # For each function in this module\n",
    "                for func in doc.get(\"functions\", []):\n",
    "                    # For each function call\n",
    "                    for called_func in func.get(\"relationships\", {}).get(\"calls_functions\", []):\n",
    "                        # If the function contains a dot, it might be a cross-module call\n",
    "                        if \".\" in called_func:\n",
    "                            parts = called_func.split(\".\")\n",
    "                            if len(parts) == 2:\n",
    "                                potential_module = parts[0]\n",
    "                                # Check if this is one of our modules\n",
    "                                if potential_module in module_docs:\n",
    "                                    G.add_edge(module_name, potential_module, \n",
    "                                            label=f\"{func['name']} -> {called_func}\")\n",
    "                                    \n",
    "                # Add edges based on imports if we can determine they're our modules\n",
    "                for imp in doc.get(\"imports\", []):\n",
    "                    module = imp.get(\"module\")\n",
    "                    if module in module_docs:\n",
    "                        G.add_edge(module_name, module, label=\"imports\")\n",
    "            \n",
    "            # Check if we have any edges\n",
    "            if not G.edges():\n",
    "                # Add edges based on function similarities\n",
    "                self._add_similarity_edges(G, module_docs)\n",
    "            \n",
    "            # Create the visualization\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            pos = nx.spring_layout(G)\n",
    "            nx.draw(G, pos, with_labels=True, node_color='lightblue', \n",
    "                    font_weight='bold', node_size=2000, arrows=True)\n",
    "            \n",
    "            # Add edge labels\n",
    "            edge_labels = {(u, v): d.get('label', '') for u, v, d in G.edges(data=True)}\n",
    "            nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "            \n",
    "            return G\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating dependency graph: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _add_similarity_edges(self, G, module_docs):\n",
    "        \"\"\"Add edges based on function and class name similarities.\"\"\"\n",
    "        # Create a dictionary of all function names to their modules\n",
    "        function_to_module = {}\n",
    "        for module_name, doc in module_docs.items():\n",
    "            for func in doc.get(\"functions\", []):\n",
    "                function_to_module[func[\"name\"]] = module_name\n",
    "        \n",
    "        # Look for similar function names across modules\n",
    "        for module_name, doc in module_docs.items():\n",
    "            for func in doc.get(\"functions\", []):\n",
    "                for called_func in func.get(\"relationships\", {}).get(\"calls_functions\", []):\n",
    "                    # If the function appears in another module\n",
    "                    if called_func in function_to_module and function_to_module[called_func] != module_name:\n",
    "                        target_module = function_to_module[called_func]\n",
    "                        G.add_edge(module_name, target_module, \n",
    "                                label=f\"{func['name']} -> {called_func}\")\n",
    "    \n",
    "    def format_api_docs_for_llm(self, module_docs):\n",
    "        \"\"\"Format API documentation for use in LLM prompt, including relationship information.\"\"\"\n",
    "        formatted_docs = []\n",
    "        \n",
    "        for module_name, doc in module_docs.items():\n",
    "            module_text = [f\"MODULE: {module_name}_code.py\"]\n",
    "            \n",
    "            # Add module docstring\n",
    "            module_text.append(f\"Description: {doc['docstring']}\")\n",
    "            module_text.append(\"\")\n",
    "            \n",
    "            # Add imports\n",
    "            if doc[\"imports\"]:\n",
    "                module_text.append(\"Imports:\")\n",
    "                for imp in doc[\"imports\"]:\n",
    "                    if \"name\" in imp:\n",
    "                        from_txt = f\"from {imp['module']} \" if imp['module'] else \"from \"\n",
    "                        as_txt = f\" as {imp['alias']}\" if imp['alias'] else \"\"\n",
    "                        module_text.append(f\"  {from_txt}import {imp['name']}{as_txt}\")\n",
    "                    else:\n",
    "                        as_txt = f\" as {imp['alias']}\" if imp['alias'] else \"\"\n",
    "                        module_text.append(f\"  import {imp['module']}{as_txt}\")\n",
    "                module_text.append(\"\")\n",
    "            \n",
    "            # Add global variables\n",
    "            if doc[\"global_vars\"]:\n",
    "                module_text.append(\"Global Variables:\")\n",
    "                for var in doc[\"global_vars\"]:\n",
    "                    module_text.append(f\"  {var['name']} = {var['value']}\")\n",
    "                module_text.append(\"\")\n",
    "            \n",
    "            # Add classes\n",
    "            if doc[\"classes\"]:\n",
    "                module_text.append(\"Classes:\")\n",
    "                for cls in doc[\"classes\"]:\n",
    "                    bases = f\"({', '.join(cls['bases'])})\" if cls['bases'] else \"\"\n",
    "                    module_text.append(f\"  class {cls['name']}{bases}:\")\n",
    "                    module_text.append(f\"    \\\"{cls['docstring']}\\\"\")\n",
    "                    \n",
    "                    # Add class relationships\n",
    "                    if cls.get(\"relationships\"):\n",
    "                        module_text.append(\"    Relationships:\")\n",
    "                        inherits = cls[\"relationships\"].get(\"inherits_from\", [])\n",
    "                        if inherits:\n",
    "                            module_text.append(f\"      Inherits from: {', '.join(inherits)}\")\n",
    "                        \n",
    "                        used_by = cls[\"relationships\"].get(\"used_by_functions\", [])\n",
    "                        if used_by:\n",
    "                            module_text.append(f\"      Used by functions: {', '.join(used_by)}\")\n",
    "                        \n",
    "                        inst_by = cls[\"relationships\"].get(\"instantiated_by\", [])\n",
    "                        if inst_by:\n",
    "                            module_text.append(f\"      Instantiated by: {', '.join(inst_by)}\")\n",
    "                        \n",
    "                        module_text.append(\"\")\n",
    "                    \n",
    "                    if cls[\"methods\"]:\n",
    "                        module_text.append(\"    Methods:\")\n",
    "                        for method in cls[\"methods\"]:\n",
    "                            params = []\n",
    "                            for p in method[\"parameters\"]:\n",
    "                                param_type = f\": {p['type']}\" if p['type'] else \"\"\n",
    "                                params.append(f\"{p['name']}{param_type}\")\n",
    "                            \n",
    "                            returns = f\" -> {method['returns']}\" if method['returns'] else \"\"\n",
    "                            module_text.append(f\"      def {method['name']}({', '.join(params)}){returns}:\")\n",
    "                            module_text.append(f\"        \\\"{method['docstring']}\\\"\")\n",
    "                            \n",
    "                            # Add method relationships\n",
    "                            if method.get(\"relationships\"):\n",
    "                                module_text.append(\"        Relationships:\")\n",
    "                                calls = method[\"relationships\"].get(\"calls_functions\", [])\n",
    "                                if calls:\n",
    "                                    module_text.append(f\"          Calls functions: {', '.join(calls)}\")\n",
    "                                \n",
    "                                instantiates = method[\"relationships\"].get(\"instantiates_classes\", [])\n",
    "                                if instantiates:\n",
    "                                    module_text.append(f\"          Instantiates classes: {', '.join(instantiates)}\")\n",
    "                                \n",
    "                                accesses = method[\"relationships\"].get(\"accesses_attributes\", [])\n",
    "                                if accesses:\n",
    "                                    module_text.append(f\"          Accesses attributes: {', '.join(accesses)}\")\n",
    "                                \n",
    "                                called_by = method[\"relationships\"].get(\"called_by\", [])\n",
    "                                if called_by:\n",
    "                                    module_text.append(f\"          Called by: {', '.join(called_by)}\")\n",
    "                                \n",
    "                                module_text.append(\"\")\n",
    "                            \n",
    "                            # Add parameter descriptions\n",
    "                            if any(p[\"description\"] != \"Parameter description not available.\" for p in method[\"parameters\"]):\n",
    "                                module_text.append(\"        Parameters:\")\n",
    "                                for p in method[\"parameters\"]:\n",
    "                                    if p[\"description\"] != \"Parameter description not available.\":\n",
    "                                        module_text.append(f\"          {p['name']}: {p['description']}\")\n",
    "                            \n",
    "                            module_text.append(\"\")\n",
    "                    \n",
    "                    module_text.append(\"\")\n",
    "            \n",
    "            # Add functions\n",
    "            if doc[\"functions\"]:\n",
    "                module_text.append(\"Functions:\")\n",
    "                for func in doc[\"functions\"]:\n",
    "                    params = []\n",
    "                    for p in func[\"parameters\"]:\n",
    "                        param_type = f\": {p['type']}\" if p['type'] else \"\"\n",
    "                        params.append(f\"{p['name']}{param_type}\")\n",
    "                    \n",
    "                    returns = f\" -> {func['returns']}\" if func['returns'] else \"\"\n",
    "                    module_text.append(f\"  def {func['name']}({', '.join(params)}){returns}:\")\n",
    "                    module_text.append(f\"    \\\"{func['docstring']}\\\"\")\n",
    "                    \n",
    "                    # Add function relationships\n",
    "                    if func.get(\"relationships\"):\n",
    "                        module_text.append(\"    Relationships:\")\n",
    "                        calls = func[\"relationships\"].get(\"calls_functions\", [])\n",
    "                        if calls:\n",
    "                            module_text.append(f\"      Calls functions: {', '.join(calls)}\")\n",
    "                        \n",
    "                        instantiates = func[\"relationships\"].get(\"instantiates_classes\", [])\n",
    "                        if instantiates:\n",
    "                            module_text.append(f\"      Instantiates classes: {', '.join(instantiates)}\")\n",
    "                        \n",
    "                        accesses = func[\"relationships\"].get(\"accesses_attributes\", [])\n",
    "                        if accesses:\n",
    "                            module_text.append(f\"      Accesses attributes: {', '.join(accesses)}\")\n",
    "                        \n",
    "                        called_by = func[\"relationships\"].get(\"called_by\", [])\n",
    "                        if called_by:\n",
    "                            module_text.append(f\"      Called by: {', '.join(called_by)}\")\n",
    "                        \n",
    "                        module_text.append(\"\")\n",
    "                    \n",
    "                    # Add parameter descriptions\n",
    "                    if any(p[\"description\"] != \"Parameter description not available.\" for p in func[\"parameters\"]):\n",
    "                        module_text.append(\"    Parameters:\")\n",
    "                        for p in func[\"parameters\"]:\n",
    "                            if p[\"description\"] != \"Parameter description not available.\":\n",
    "                                module_text.append(f\"      {p['name']}: {p['description']}\")\n",
    "                    \n",
    "                    module_text.append(\"\")\n",
    "            \n",
    "            # Add module-level relationships\n",
    "            if doc.get(\"relationships\"):\n",
    "                module_text.append(\"Module Relationships:\")\n",
    "                \n",
    "                # Dependencies\n",
    "                deps = doc[\"relationships\"].get(\"dependencies\", {})\n",
    "                imports = deps.get(\"imports\", [])\n",
    "                if imports:\n",
    "                    module_text.append(f\"  Imports modules: {', '.join(imports)}\")\n",
    "                \n",
    "                from_imports = deps.get(\"from_imports\", [])\n",
    "                if from_imports:\n",
    "                    module_text.append(f\"  Imports from: {', '.join(from_imports)}\")\n",
    "                \n",
    "                # Entry points\n",
    "                entry_points = doc[\"relationships\"].get(\"entry_points\", [])\n",
    "                if entry_points:\n",
    "                    module_text.append(f\"  Entry points: {', '.join(entry_points)}\")\n",
    "                \n",
    "                module_text.append(\"\")\n",
    "            \n",
    "            formatted_docs.append(\"\\n\".join(module_text))\n",
    "        \n",
    "        return \"\\n\\n\" + \"\\n\\n\".join(formatted_docs) + \"\\n\"\n",
    "\n",
    "class EnhancedCodeIntegrator:\n",
    "    \"\"\"Class to integrate code modules based on enhanced API documentation with relationships.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, doc_generator):\n",
    "        self.model = model\n",
    "        self.doc_generator = doc_generator\n",
    "    \n",
    "    def create_integration_prompt(self, api_docs):\n",
    "        \"\"\"Create a prompt for the LLM to integrate the code with relationship awareness.\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "I have multiple Python modules that need to be integrated into a cohesive solution.\n",
    "Below is the ENHANCED API documentation for each module, which includes detailed relationship information\n",
    "showing which functions call other functions, which classes are instantiated, and other dependencies.\n",
    "Each module is stored in a separate file with the naming pattern of \"US_XXX_code.py\" where XXX is the user story ID.\n",
    "\n",
    "{api_docs}\n",
    "\n",
    "Your task is to:\n",
    "\n",
    "1. Create a single integrated Python file that coordinates functionality from all these modules\n",
    "2. Design the integrated solution to import modules correctly using their filenames (e.g., \"import US_142_code\" NOT \"import US_142\")\n",
    "3. Create proper references to functions and classes from each module with correct module prefixes\n",
    "4. Make sure to import all necessary standard and third-party libraries needed by the solution\n",
    "5. Ensure proper sequencing based on the function call relationships documented above\n",
    "6. Include a main execution block that coordinates the overall flow\n",
    "7. Write clear comments to explain how the integration works, especially noting important function relationships\n",
    "8. Add detailed documentation explaining which functions call which other functions and their dependencies\n",
    "\n",
    "IMPORTANT: Each module should be imported using its full filename (e.g., \"import US_142_code\" not \"import US_142\").\n",
    "When referring to functions, classes, or variables from these modules, use the proper module prefix\n",
    "(e.g., \"US_142_code.process_file()\" not \"US_142.process_file()\").\n",
    "\n",
    "Your integrated solution should include:\n",
    "1. A detailed module docstring explaining the overall architecture and how the modules interact\n",
    "2. Comments for each section explaining which components depend on each other\n",
    "3. A function relationship map in comments to help developers understand the code flow\n",
    "4. A main execution function that coordinates the execution flow based on the identified relationships\n",
    "\n",
    "Format your response as a single Python file with all necessary imports, functions, \n",
    "and a main execution block. Add helpful comments to explain your integration strategy.\n",
    "\n",
    "Return only the final integrated Python code without explanation or other text.\n",
    "\"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def validate_integrated_code(self, code, module_names):\n",
    "        \"\"\"Validate that the integrated code properly imports all modules with correct names.\"\"\"\n",
    "        # Check if modules are imported with _code suffix\n",
    "        proper_imports = True\n",
    "        module_import_checks = []\n",
    "        \n",
    "        for module_name in module_names:\n",
    "            module_import_name = f\"{module_name}_code\"\n",
    "            if f\"import {module_name}\" in code and f\"import {module_import_name}\" not in code:\n",
    "                proper_imports = False\n",
    "                module_import_checks.append((module_name, False))\n",
    "            else:\n",
    "                module_import_checks.append((module_name, True))\n",
    "        \n",
    "        # Check for any functions or classes referenced without proper module prefix\n",
    "        improper_references = []\n",
    "        \n",
    "        for module_name in module_names:\n",
    "            # Look for patterns like \"ModuleName.function\" instead of \"ModuleName_code.function\"\n",
    "            pattern = fr\"{module_name}\\.[a-zA-Z0-9_]+\"\n",
    "            matches = re.findall(pattern, code)\n",
    "            if matches:\n",
    "                improper_references.extend(matches)\n",
    "        \n",
    "        return {\n",
    "            \"proper_imports\": proper_imports,\n",
    "            \"module_import_checks\": module_import_checks,\n",
    "            \"improper_references\": improper_references\n",
    "        }\n",
    "    \n",
    "    def fix_integrated_code(self, code, validation_result):\n",
    "        \"\"\"Fix issues with the integrated code based on validation results.\"\"\"\n",
    "        fixed_code = code\n",
    "        \n",
    "        # Fix improper imports\n",
    "        for module_name, is_proper in validation_result[\"module_import_checks\"]:\n",
    "            if not is_proper:\n",
    "                # Replace \"import ModuleName\" with \"import ModuleName_code\"\n",
    "                fixed_code = re.sub(\n",
    "                    fr\"import\\s+{module_name}(?!_code)\",\n",
    "                    f\"import {module_name}_code\",\n",
    "                    fixed_code\n",
    "                )\n",
    "                \n",
    "                # Replace \"from ModuleName import\" with \"from ModuleName_code import\"\n",
    "                fixed_code = re.sub(\n",
    "                    fr\"from\\s+{module_name}(?!_code)\\s+import\",\n",
    "                    f\"from {module_name}_code import\",\n",
    "                    fixed_code\n",
    "                )\n",
    "        \n",
    "        # Fix improper references\n",
    "        for ref in validation_result[\"improper_references\"]:\n",
    "            module_name = ref.split('.')[0]\n",
    "            fixed_code = fixed_code.replace(ref, ref.replace(f\"{module_name}.\", f\"{module_name}_code.\"))\n",
    "        \n",
    "        return fixed_code\n",
    "    \n",
    "    def generate_integrated_code(self, module_docs):\n",
    "        \"\"\"Generate integrated code based on enhanced API documentation with relationships.\"\"\"\n",
    "        # Format API docs for the LLM\n",
    "        api_docs_text = self.doc_generator.format_api_docs_for_llm(module_docs)\n",
    "        \n",
    "        # Create the prompt\n",
    "        prompt = self.create_integration_prompt(api_docs_text)\n",
    "        \n",
    "        # Send to LLM\n",
    "        system_message = SystemMessage(content=\"\"\"You are a Python expert who specializes in integrating multiple code modules \n",
    "into cohesive solutions. You excel at understanding module dependencies and creating orchestration code.\"\"\")\n",
    "        human_message = HumanMessage(content=prompt)\n",
    "        \n",
    "        logger.info(\"Sending enhanced API documentation to LLM for integration\")\n",
    "        response = self.model.invoke([system_message, human_message])\n",
    "        \n",
    "        # Extract code from response\n",
    "        content = response.content\n",
    "        \n",
    "        # Check if the response is wrapped in code blocks\n",
    "        if \"```python\" in content and \"```\" in content.split(\"```python\", 1)[1]:\n",
    "            # Extract code between the markers\n",
    "            code = content.split(\"```python\", 1)[1].split(\"```\", 1)[0].strip()\n",
    "        elif \"```\" in content and content.count(\"```\") >= 2:\n",
    "            # Extract code between the markers\n",
    "            parts = content.split(\"```\", 2)\n",
    "            code = parts[1]\n",
    "            if code.startswith(\"python\"):\n",
    "                code = code[6:]\n",
    "            code = code.strip()\n",
    "        else:\n",
    "            # If not wrapped in code blocks, return as is\n",
    "            code = content\n",
    "        \n",
    "        # Validate and fix the code\n",
    "        validation_result = self.validate_integrated_code(code, module_docs.keys())\n",
    "        \n",
    "        if not validation_result[\"proper_imports\"] or validation_result[\"improper_references\"]:\n",
    "            logger.info(\"Fixing issues in the integrated code\")\n",
    "            code = self.fix_integrated_code(code, validation_result)\n",
    "        \n",
    "        return code\n",
    "    \n",
    "    def generate_init_file(self, output_dir, module_docs):\n",
    "        \"\"\"Generate an __init__.py file to make importing modules easier.\"\"\"\n",
    "        init_content = ['\"\"\"Package initialization file with module relationships documented.\"\"\"\\n']\n",
    "        \n",
    "        # Add imports for all modules\n",
    "        for module_name in module_docs.keys():\n",
    "            # Import the module\n",
    "            init_content.append(f\"import {module_name}_code\")\n",
    "            \n",
    "            # Create shorter aliases for convenience\n",
    "            init_content.append(f\"{module_name} = {module_name}_code\")\n",
    "        \n",
    "        # Add module relationship documentation\n",
    "        init_content.append(\"\\n# Module relationships:\")\n",
    "        for module_name, doc in module_docs.items():\n",
    "            # Document entry points\n",
    "            entry_points = doc.get(\"relationships\", {}).get(\"entry_points\", [])\n",
    "            if entry_points:\n",
    "                init_content.append(f\"# {module_name}_code entry points: {', '.join(entry_points)}\")\n",
    "            \n",
    "            # Document function calls between modules\n",
    "            calls_found = False\n",
    "            for func in doc.get(\"functions\", []):\n",
    "                for called_func in func.get(\"relationships\", {}).get(\"calls_functions\", []):\n",
    "                    if \".\" in called_func:\n",
    "                        parts = called_func.split(\".\")\n",
    "                        if len(parts) == 2 and parts[0] in module_docs:\n",
    "                            if not calls_found:\n",
    "                                init_content.append(f\"# {module_name}_code function dependencies:\")\n",
    "                                calls_found = True\n",
    "                            init_content.append(f\"#   {func['name']} -> {called_func}\")\n",
    "            \n",
    "            if not calls_found:\n",
    "                init_content.append(f\"# {module_name}_code: No external function calls identified\")\n",
    "        \n",
    "        # Write the file\n",
    "        init_path = os.path.join(output_dir, \"__init__.py\")\n",
    "        with open(init_path, 'w') as f:\n",
    "            f.write(\"\\n\".join(init_content))\n",
    "        \n",
    "        logger.info(f\"Created enhanced __init__.py file at {init_path}\")\n",
    "\n",
    "def save_modules_with_proper_names(output_dir, code_contents):\n",
    "    \"\"\"Save individual modules with proper names based on user story IDs.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for module_name, code in code_contents.items():\n",
    "        file_name = f\"{module_name}_code.py\"\n",
    "        file_path = os.path.join(output_dir, file_name)\n",
    "        \n",
    "        with open(file_path, 'w') as f:\n",
    "            f.write(code)\n",
    "        \n",
    "        logger.info(f\"Saved module {module_name} to {file_path}\")\n",
    "\n",
    "def create_relationship_documentation(output_dir, module_docs):\n",
    "    \"\"\"Create a RELATIONSHIPS.md file documenting the relationships between all components.\"\"\"\n",
    "    content = [\n",
    "        \"# Module Relationship Documentation\",\n",
    "        \"\",\n",
    "        \"This document provides detailed information about the relationships between modules, functions, and classes.\",\n",
    "        \"\",\n",
    "        \"## Overview\",\n",
    "        \"\"\n",
    "    ]\n",
    "    \n",
    "    # Create a list of all modules\n",
    "    content.append(\"### Modules\")\n",
    "    for module_name in module_docs.keys():\n",
    "        content.append(f\"- {module_name}_code.py\")\n",
    "    content.append(\"\")\n",
    "    \n",
    "    # Document module-level relationships\n",
    "    content.append(\"## Module Dependencies\")\n",
    "    content.append(\"\")\n",
    "    \n",
    "    for module_name, doc in module_docs.items():\n",
    "        content.append(f\"### {module_name}_code.py\")\n",
    "        content.append(f\"*{doc['docstring']}*\")\n",
    "        content.append(\"\")\n",
    "        \n",
    "        # Dependencies\n",
    "        deps = doc.get(\"relationships\", {}).get(\"dependencies\", {})\n",
    "        imports = deps.get(\"imports\", [])\n",
    "        if imports:\n",
    "            content.append(\"**Imports modules:**\")\n",
    "            for imp in imports:\n",
    "                content.append(f\"- {imp}\")\n",
    "            content.append(\"\")\n",
    "        \n",
    "        # Entry points\n",
    "        entry_points = doc.get(\"relationships\", {}).get(\"entry_points\", [])\n",
    "        if entry_points:\n",
    "            content.append(\"**Entry points:**\")\n",
    "            for ep in entry_points:\n",
    "                content.append(f\"- {ep}\")\n",
    "            content.append(\"\")\n",
    "        \n",
    "        # Functions\n",
    "        if doc.get(\"functions\"):\n",
    "            content.append(\"**Functions:**\")\n",
    "            for func in doc[\"functions\"]:\n",
    "                # Add function with its relationships\n",
    "                # Safely extract the docstring summary\n",
    "                docstring_summary = get_docstring_summary(func.get('docstring'))\n",
    "                content.append(f\"- `{func['name']}`: {docstring_summary}\")\n",
    "                \n",
    "                # Function calls\n",
    "                calls = func.get(\"relationships\", {}).get(\"calls_functions\", [])\n",
    "                if calls:\n",
    "                    content.append(f\"  - Calls: {', '.join([f'`{c}`' for c in calls])}\")\n",
    "                \n",
    "                # Function instantiations\n",
    "                instantiates = func.get(\"relationships\", {}).get(\"instantiates_classes\", [])\n",
    "                if instantiates:\n",
    "                    content.append(f\"  - Instantiates: {', '.join([f'`{c}`' for c in instantiates])}\")\n",
    "                \n",
    "                # Called by\n",
    "                called_by = func.get(\"relationships\", {}).get(\"called_by\", [])\n",
    "                if called_by:\n",
    "                    content.append(f\"  - Called by: {', '.join([f'`{c}`' for c in called_by])}\")\n",
    "            \n",
    "            content.append(\"\")\n",
    "        \n",
    "        # Classes\n",
    "        if doc.get(\"classes\"):\n",
    "            content.append(\"**Classes:**\")\n",
    "            for cls in doc[\"classes\"]:\n",
    "                # Add class with its relationships\n",
    "                docstring_summary = get_docstring_summary(cls.get('docstring'))\n",
    "                content.append(f\"- `{cls['name']}`: {docstring_summary}\")\n",
    "                \n",
    "                # Inheritance\n",
    "                inherits = cls.get(\"relationships\", {}).get(\"inherits_from\", [])\n",
    "                if inherits:\n",
    "                    content.append(f\"  - Inherits from: {', '.join([f'`{c}`' for c in inherits])}\")\n",
    "                \n",
    "                # Used by\n",
    "                used_by = cls.get(\"relationships\", {}).get(\"used_by_functions\", [])\n",
    "                if used_by:\n",
    "                    content.append(f\"  - Used by: {', '.join([f'`{c}`' for c in used_by])}\")\n",
    "                \n",
    "                # Instantiated by\n",
    "                inst_by = cls.get(\"relationships\", {}).get(\"instantiated_by\", [])\n",
    "                if inst_by:\n",
    "                    content.append(f\"  - Instantiated by: {', '.join([f'`{c}`' for c in inst_by])}\")\n",
    "            \n",
    "            content.append(\"\")\n",
    "    \n",
    "    # Create function call graph section\n",
    "    content.append(\"## Function Call Graph\")\n",
    "    content.append(\"\")\n",
    "    content.append(\"This section shows which functions call other functions across all modules.\")\n",
    "    content.append(\"\")\n",
    "    \n",
    "    # Build the function call graph\n",
    "    call_graph = defaultdict(list)\n",
    "    \n",
    "    for module_name, doc in module_docs.items():\n",
    "        for func in doc.get(\"functions\", []):\n",
    "            func_full_name = f\"{module_name}_code.{func['name']}\"\n",
    "            for called_func in func.get(\"relationships\", {}).get(\"calls_functions\", []):\n",
    "                if \".\" in called_func:\n",
    "                    call_graph[func_full_name].append(called_func)\n",
    "                else:\n",
    "                    # It's in the same module\n",
    "                    call_graph[func_full_name].append(f\"{module_name}_code.{called_func}\")\n",
    "    \n",
    "    # Print call graph\n",
    "    for caller, callees in sorted(call_graph.items()):\n",
    "        if callees:\n",
    "            content.append(f\"- `{caller}` calls:\")\n",
    "            for callee in sorted(callees):\n",
    "                content.append(f\"  - `{callee}`\")\n",
    "            content.append(\"\")\n",
    "    \n",
    "    # Write to file\n",
    "    rel_path = os.path.join(output_dir, \"RELATIONSHIPS.md\")\n",
    "    with open(rel_path, 'w') as f:\n",
    "        f.write(\"\\n\".join(content))\n",
    "    \n",
    "    logger.info(f\"Created detailed relationship documentation at {rel_path}\")\n",
    "\n",
    "def create_setup_py(output_dir, module_name=\"integrated_solution\"):\n",
    "    \"\"\"Create a setup.py file to make the package installable.\"\"\"\n",
    "    setup_content = f'''\"\"\"\n",
    "Setup script for {module_name} package.\n",
    "This package combines multiple modules with their relationships preserved.\n",
    "\"\"\"\n",
    "\n",
    "from setuptools import setup, find_packages\n",
    "\n",
    "setup(\n",
    "    name=\"{module_name}\",\n",
    "    version=\"0.1.0\",\n",
    "    packages=find_packages(),\n",
    "    author=\"AI Code Generator\",\n",
    "    author_email=\"ai@example.com\",\n",
    "    description=\"Integrated solution generated from multiple modules with relationship awareness\",\n",
    "    classifiers=[\n",
    "        \"Programming Language :: Python :: 3\",\n",
    "        \"License :: OSI Approved :: MIT License\",\n",
    "        \"Operating System :: OS Independent\",\n",
    "    ],\n",
    "    python_requires=\">=3.6\",\n",
    ")\n",
    "'''\n",
    "    \n",
    "    setup_path = os.path.join(output_dir, \"setup.py\")\n",
    "    with open(setup_path, 'w') as f:\n",
    "        f.write(setup_content)\n",
    "    \n",
    "    logger.info(f\"Created setup.py file at {setup_path}\")\n",
    "\n",
    "def create_readme(output_dir, module_docs):\n",
    "    \"\"\"Create a README.md file with information about the integrated solution.\"\"\"\n",
    "    readme_content = [\n",
    "        \"# Relationship-Enhanced Integrated Solution\",\n",
    "        \"\",\n",
    "        \"This is an automatically generated integrated solution that combines functionality from multiple modules,\",\n",
    "        \"with enhanced documentation of relationships between functions and classes.\",\n",
    "        \"\",\n",
    "        \"## Architecture Overview\",\n",
    "        \"\",\n",
    "        \"The solution consists of the following modules, each with distinct responsibilities:\",\n",
    "        \"\"\n",
    "    ]\n",
    "    \n",
    "    # Add module descriptions\n",
    "    for module_name, doc in module_docs.items():\n",
    "        readme_content.append(f\"### {module_name}_code\")\n",
    "        readme_content.append(f\"{doc['docstring']}\")\n",
    "        \n",
    "        # Add entry points\n",
    "        entry_points = doc.get(\"relationships\", {}).get(\"entry_points\", [])\n",
    "        if entry_points:\n",
    "            readme_content.append(\"\\nEntry Points:\")\n",
    "            for ep in entry_points:\n",
    "                readme_content.append(f\"- `{ep}`\")\n",
    "        \n",
    "        # Add functions with their relationships\n",
    "        if doc[\"functions\"]:\n",
    "            readme_content.append(\"\\nKey Functions:\")\n",
    "            for func in doc[\"functions\"]:\n",
    "                # Only include functions that have relationships or are entry points\n",
    "                has_relationships = (\n",
    "                    func.get(\"relationships\", {}).get(\"calls_functions\") or \n",
    "                    func.get(\"relationships\", {}).get(\"instantiates_classes\") or\n",
    "                    func.get(\"relationships\", {}).get(\"called_by\")\n",
    "                )\n",
    "                \n",
    "                is_entry_point = func[\"name\"] in entry_points\n",
    "                \n",
    "                if has_relationships or is_entry_point:\n",
    "                    # Safely get docstring summary\n",
    "                    docstring_summary = get_docstring_summary(func.get('docstring'))\n",
    "                    readme_content.append(f\"- `{func['name']}`: {docstring_summary}\")\n",
    "                    \n",
    "                    # Add relationship info\n",
    "                    if has_relationships:\n",
    "                        rel = func.get(\"relationships\", {})\n",
    "                        calls = rel.get(\"calls_functions\", [])\n",
    "                        if calls:\n",
    "                            readme_content.append(f\"  - Calls: {', '.join(calls)}\")\n",
    "                        \n",
    "                        called_by = rel.get(\"called_by\", [])\n",
    "                        if called_by:\n",
    "                            readme_content.append(f\"  - Called by: {', '.join(called_by)}\")\n",
    "                        \n",
    "                        instantiates = rel.get(\"instantiates_classes\", [])\n",
    "                        if instantiates:\n",
    "                            readme_content.append(f\"  - Instantiates: {', '.join(instantiates)}\")\n",
    "        \n",
    "        readme_content.append(\"\")\n",
    "    \n",
    "    # Add integration information\n",
    "    readme_content.extend([\n",
    "        \"## Integration Strategy\",\n",
    "        \"\",\n",
    "        \"The integration follows these principles:\",\n",
    "        \"\",\n",
    "        \"1. **Dependency-Based Execution**: Functions are called in an order that respects their dependencies\",\n",
    "        \"2. **Module Isolation**: Each module maintains its own namespace to prevent conflicts\",\n",
    "        \"3. **Coordinated Execution**: The main execution orchestrates the flow across modules\",\n",
    "        \"\",\n",
    "        \"## Documentation\",\n",
    "        \"\",\n",
    "        \"For more detailed information about the relationships between components, see:\",\n",
    "        \"\",\n",
    "        \"- `RELATIONSHIPS.md`: Detailed documentation of all module and function relationships\",\n",
    "        \"- `integrated_solution.py`: The main integration file with relationship comments\",\n",
    "        \"- `__init__.py`: Contains module relationship information\"\n",
    "    ])\n",
    "    \n",
    "    readme_path = os.path.join(output_dir, \"README.md\")\n",
    "    with open(readme_path, 'w') as f:\n",
    "        f.write(\"\\n\".join(readme_content))\n",
    "    \n",
    "    logger.info(f\"Created enhanced README.md file at {readme_path}\")\n",
    "\n",
    "def fixed_relationship_enhanced_code_integrator(code_generation_folder):\n",
    "    \"\"\"\n",
    "    Agent that generates enhanced API documentation with relationship details for code modules and uses that\n",
    "    to create an integrated solution with proper module imports.\n",
    "    \n",
    "    Args:\n",
    "        code_generation_folder: Path to folder containing the generated code\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the output directory\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize the model\n",
    "        model = AzureChatOpenAI(\n",
    "            azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "            api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "            api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "            deployment_name=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"],\n",
    "            temperature=0.1  # Low temperature for more deterministic output\n",
    "        )\n",
    "        \n",
    "        # Create output directory\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        output_dir = os.path.join(os.path.dirname(code_generation_folder), f\"relationship_enhanced_solution_{timestamp}\")\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Find all code files\n",
    "        code_files = find_code_files(code_generation_folder)\n",
    "        logger.info(f\"Found {len(code_files)} code files to integrate\")\n",
    "        \n",
    "        if not code_files:\n",
    "            logger.error(\"No code files found to integrate\")\n",
    "            return None\n",
    "        \n",
    "        # Read all code files\n",
    "        code_contents = read_code_files(code_files)\n",
    "        \n",
    "        # Save modules with proper names\n",
    "        save_modules_with_proper_names(output_dir, code_contents)\n",
    "        \n",
    "        # Generate enhanced API documentation with relationships\n",
    "        doc_generator = EnhancedAPIDocGenerator(model)\n",
    "        module_docs = doc_generator.generate_all_module_docs(code_contents)\n",
    "        \n",
    "        # Save enhanced API documentation\n",
    "        api_docs_path = os.path.join(output_dir, \"enhanced_api_documentation.json\")\n",
    "        with open(api_docs_path, 'w') as f:\n",
    "            json.dump(module_docs, f, indent=2)\n",
    "        logger.info(f\"Saved enhanced API documentation to {api_docs_path}\")\n",
    "        \n",
    "        # Create detailed relationship documentation\n",
    "        create_relationship_documentation(output_dir, module_docs)\n",
    "        \n",
    "        # Try to generate dependency graph\n",
    "        try:\n",
    "            # Try to import required libraries\n",
    "            try:\n",
    "                import matplotlib.pyplot as plt\n",
    "                import networkx as nx\n",
    "                \n",
    "                # Try to generate the graph\n",
    "                dependency_graph = doc_generator.try_generate_dependency_graph(module_docs)\n",
    "                if dependency_graph:\n",
    "                    graph_path = os.path.join(output_dir, \"module_dependencies.png\")\n",
    "                    plt.savefig(graph_path)\n",
    "                    logger.info(f\"Saved dependency graph visualization to {graph_path}\")\n",
    "            except ImportError:\n",
    "                logger.warning(\"matplotlib or networkx not available, skipping graph generation\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not generate dependency graph: {e}\")\n",
    "        \n",
    "        # Generate integrated code\n",
    "        integrator = EnhancedCodeIntegrator(model, doc_generator)\n",
    "        integrated_code = integrator.generate_integrated_code(module_docs)\n",
    "        \n",
    "        # Add header\n",
    "        header = f'''\"\"\"\n",
    "Relationship-Enhanced Integrated Solution\n",
    "This file was automatically generated by the Relationship-Enhanced Code Integrator.\n",
    "Generated on: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "\n",
    "This code serves as an integration layer that coordinates all the individual modules.\n",
    "Each module's code is stored in separate files named by their user story IDs with \"_code.py\" suffix.\n",
    "The integration is based on detailed analysis of function and class relationships between modules.\n",
    "\"\"\"\n",
    "\n",
    "'''\n",
    "        integrated_code = header + integrated_code\n",
    "        \n",
    "        # Save integrated code\n",
    "        integrated_code_path = os.path.join(output_dir, \"integrated_solution.py\")\n",
    "        with open(integrated_code_path, 'w') as f:\n",
    "            f.write(integrated_code)\n",
    "        \n",
    "        # Create enhanced __init__.py file\n",
    "        integrator.generate_init_file(output_dir, module_docs)\n",
    "        \n",
    "        # Create enhanced README.md\n",
    "        create_readme(output_dir, module_docs)\n",
    "        \n",
    "        # Create setup.py\n",
    "        create_setup_py(output_dir)\n",
    "        \n",
    "        logger.info(f\"Successfully created relationship-enhanced integrated solution: {integrated_code_path}\")\n",
    "        print(f\"Relationship-enhanced integrated solution created at: {output_dir}\")\n",
    "        \n",
    "        return output_dir\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in relationship-enhanced code integrator: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "def main(excel_file_path=\"tech.xlsx\"):\n",
    "    \"\"\"\n",
    "    Main function to run both code generation and integration in sequence.\n",
    "    \n",
    "    Args:\n",
    "        excel_file_path: Path to Excel file with technical specifications\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"STARTING INTEGRATED CODE GENERATION AND INTEGRATION SYSTEM\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Step 1: Generate code based on tech specs\n",
    "        print(\"\\nSTEP 1: Generating code based on technical specifications...\")\n",
    "        code_generation_dir = process_tech_specs(excel_file_path)\n",
    "        \n",
    "        if not code_generation_dir:\n",
    "            print(\"Code generation failed or no specs were found. Exiting.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nCode generation completed successfully. Output directory: {code_generation_dir}\")\n",
    "        \n",
    "        # Step 2: Integrate the generated code with relationship awareness\n",
    "        print(\"\\nSTEP 2: Integrating generated code with relationship analysis...\")\n",
    "        integration_dir = fixed_relationship_enhanced_code_integrator(code_generation_dir)\n",
    "        \n",
    "        if not integration_dir:\n",
    "            print(\"Code integration failed. Exiting.\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"PROCESS COMPLETED SUCCESSFULLY\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"\\nGenerated code: {code_generation_dir}\")\n",
    "        print(f\"Integrated solution: {integration_dir}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError in main process: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
